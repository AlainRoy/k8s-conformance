I0816 13:07:58.115074      15 test_context.go:358] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-739526127
I0816 13:07:58.115232      15 e2e.go:224] Starting e2e run "dde9b4dc-c026-11e9-99f6-8a077000b195" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1565960877 - Will randomize all specs
Will run 201 of 1946 specs

Aug 16 13:07:58.240: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
Aug 16 13:07:58.242: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Aug 16 13:07:58.255: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Aug 16 13:07:58.278: INFO: 0 / 0 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Aug 16 13:07:58.278: INFO: expected 0 pod replicas in namespace 'kube-system', 0 are Running and Ready.
Aug 16 13:07:58.278: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Aug 16 13:07:58.285: INFO: e2e test version: v1.13.0
Aug 16 13:07:58.285: INFO: kube-apiserver version: v1.13.6
S
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:07:58.285: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename hostpath
Aug 16 13:07:58.345: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
Aug 16 13:07:58.354: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-nqc62" to be "success or failure"
Aug 16 13:07:58.365: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 10.949487ms
Aug 16 13:08:00.368: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014334503s
Aug 16 13:08:02.372: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017864003s
STEP: Saw pod success
Aug 16 13:08:02.372: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Aug 16 13:08:02.375: INFO: Trying to get logs from node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Aug 16 13:08:02.408: INFO: Waiting for pod pod-host-path-test to disappear
Aug 16 13:08:02.411: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:08:02.411: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-nqc62" for this suite.
Aug 16 13:08:08.435: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:08:08.465: INFO: namespace: e2e-tests-hostpath-nqc62, resource: bindings, ignored listing per whitelist
Aug 16 13:08:08.554: INFO: namespace e2e-tests-hostpath-nqc62 deletion completed in 6.138544985s

• [SLOW TEST:10.268 seconds]
[sig-storage] HostPath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:08:08.554: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Aug 16 13:08:08.617: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Aug 16 13:08:08.626: INFO: Waiting for terminating namespaces to be deleted...
Aug 16 13:08:08.629: INFO: 
Logging pods the kubelet thinks is on node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 before test
Aug 16 13:08:08.633: INFO: sonobuoy-e2e-job-09d0aca292374f31 from sonobuoy started at 2019-08-16 13:07:46 +0000 UTC (2 container statuses recorded)
Aug 16 13:08:08.633: INFO: 	Container e2e ready: true, restart count 0
Aug 16 13:08:08.633: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 16 13:08:08.633: INFO: canal-node-1-13-6-6x8bh from vke-system started at 2019-08-16 13:07:21 +0000 UTC (3 container statuses recorded)
Aug 16 13:08:08.633: INFO: 	Container calico-node ready: true, restart count 0
Aug 16 13:08:08.633: INFO: 	Container flannel ready: true, restart count 0
Aug 16 13:08:08.633: INFO: 	Container install-calico-cni ready: true, restart count 0
Aug 16 13:08:08.633: INFO: sonobuoy from sonobuoy started at 2019-08-16 13:07:41 +0000 UTC (1 container statuses recorded)
Aug 16 13:08:08.633: INFO: 	Container kube-sonobuoy ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node worker-72b80c6a-c026-11e9-bfed-069795ba99e0
Aug 16 13:08:08.658: INFO: Pod sonobuoy requesting resource cpu=0m on Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0
Aug 16 13:08:08.658: INFO: Pod sonobuoy-e2e-job-09d0aca292374f31 requesting resource cpu=0m on Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0
Aug 16 13:08:08.658: INFO: Pod canal-node-1-13-6-6x8bh requesting resource cpu=250m on Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e482d644-c026-11e9-99f6-8a077000b195.15bb6921a2ae5cb9], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-2fmvx/filler-pod-e482d644-c026-11e9-99f6-8a077000b195 to worker-72b80c6a-c026-11e9-bfed-069795ba99e0]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e482d644-c026-11e9-99f6-8a077000b195.15bb6921cfe742e3], Reason = [Pulling], Message = [pulling image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e482d644-c026-11e9-99f6-8a077000b195.15bb692201304271], Reason = [Pulled], Message = [Successfully pulled image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e482d644-c026-11e9-99f6-8a077000b195.15bb692204bc7379], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e482d644-c026-11e9-99f6-8a077000b195.15bb692211443876], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15bb69221a937461], Reason = [FailedScheduling], Message = [0/4 nodes are available: 1 Insufficient cpu, 3 node(s) had taints that the pod didn't tolerate.]
STEP: removing the label node off the node worker-72b80c6a-c026-11e9-bfed-069795ba99e0
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:08:11.708: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-2fmvx" for this suite.
Aug 16 13:08:17.732: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:08:17.834: INFO: namespace: e2e-tests-sched-pred-2fmvx, resource: bindings, ignored listing per whitelist
Aug 16 13:08:17.843: INFO: namespace e2e-tests-sched-pred-2fmvx deletion completed in 6.1256603s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:9.289 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:08:17.843: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-ea0c7a36-c026-11e9-99f6-8a077000b195
STEP: Creating a pod to test consume configMaps
Aug 16 13:08:17.963: INFO: Waiting up to 5m0s for pod "pod-configmaps-ea0d1ec8-c026-11e9-99f6-8a077000b195" in namespace "e2e-tests-configmap-b6tbj" to be "success or failure"
Aug 16 13:08:17.968: INFO: Pod "pod-configmaps-ea0d1ec8-c026-11e9-99f6-8a077000b195": Phase="Pending", Reason="", readiness=false. Elapsed: 5.326871ms
Aug 16 13:08:19.978: INFO: Pod "pod-configmaps-ea0d1ec8-c026-11e9-99f6-8a077000b195": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015325828s
STEP: Saw pod success
Aug 16 13:08:19.978: INFO: Pod "pod-configmaps-ea0d1ec8-c026-11e9-99f6-8a077000b195" satisfied condition "success or failure"
Aug 16 13:08:19.984: INFO: Trying to get logs from node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 pod pod-configmaps-ea0d1ec8-c026-11e9-99f6-8a077000b195 container configmap-volume-test: <nil>
STEP: delete the pod
Aug 16 13:08:20.014: INFO: Waiting for pod pod-configmaps-ea0d1ec8-c026-11e9-99f6-8a077000b195 to disappear
Aug 16 13:08:20.019: INFO: Pod pod-configmaps-ea0d1ec8-c026-11e9-99f6-8a077000b195 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:08:20.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-b6tbj" for this suite.
Aug 16 13:08:26.035: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:08:26.124: INFO: namespace: e2e-tests-configmap-b6tbj, resource: bindings, ignored listing per whitelist
Aug 16 13:08:26.148: INFO: namespace e2e-tests-configmap-b6tbj deletion completed in 6.125509403s

• [SLOW TEST:8.305 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:08:26.148: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-z87bz in namespace e2e-tests-proxy-zdrrg
I0816 13:08:26.235301      15 runners.go:184] Created replication controller with name: proxy-service-z87bz, namespace: e2e-tests-proxy-zdrrg, replica count: 1
I0816 13:08:27.285557      15 runners.go:184] proxy-service-z87bz Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0816 13:08:28.285722      15 runners.go:184] proxy-service-z87bz Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0816 13:08:29.285855      15 runners.go:184] proxy-service-z87bz Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0816 13:08:30.285990      15 runners.go:184] proxy-service-z87bz Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0816 13:08:31.286101      15 runners.go:184] proxy-service-z87bz Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0816 13:08:32.286223      15 runners.go:184] proxy-service-z87bz Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug 16 13:08:32.296: INFO: setup took 6.090459335s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Aug 16 13:08:32.306: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr:162/proxy/: bar (200; 9.5549ms)
Aug 16 13:08:32.309: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr:1080/proxy/rewri... (200; 12.466268ms)
Aug 16 13:08:32.309: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/http:proxy-service-z87bz-pjgfr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/http:proxy-service-z87bz-pjgfr:1080/proxy/... (200; 12.271338ms)
Aug 16 13:08:32.310: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/https:proxy-service-z87bz-pjgfr:462/proxy/: tls qux (200; 14.029293ms)
Aug 16 13:08:32.310: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/http:proxy-service-z87bz-pjgfr:162/proxy/: bar (200; 13.81423ms)
Aug 16 13:08:32.310: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr/proxy/rewriteme"... (200; 13.762898ms)
Aug 16 13:08:32.310: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/http:proxy-service-z87bz-pjgfr:160/proxy/: foo (200; 13.817471ms)
Aug 16 13:08:32.315: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/proxy-service-z87bz:portname2/proxy/: bar (200; 18.001533ms)
Aug 16 13:08:32.315: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr:160/proxy/: foo (200; 18.143371ms)
Aug 16 13:08:32.315: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/http:proxy-service-z87bz:portname1/proxy/: foo (200; 18.469884ms)
Aug 16 13:08:32.315: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/http:proxy-service-z87bz:portname2/proxy/: bar (200; 18.452198ms)
Aug 16 13:08:32.315: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/https:proxy-service-z87bz-pjgfr:460/proxy/: tls baz (200; 18.858641ms)
Aug 16 13:08:32.315: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/proxy-service-z87bz:portname1/proxy/: foo (200; 18.81514ms)
Aug 16 13:08:32.316: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/https:proxy-service-z87bz:tlsportname1/proxy/: tls baz (200; 19.789793ms)
Aug 16 13:08:32.316: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/https:proxy-service-z87bz:tlsportname2/proxy/: tls qux (200; 19.666344ms)
Aug 16 13:08:32.316: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/https:proxy-service-z87bz-pjgfr:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/https:proxy-service-z87bz-pjgfr:443/proxy/... (200; 20.154582ms)
Aug 16 13:08:32.321: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/https:proxy-service-z87bz-pjgfr:460/proxy/: tls baz (200; 4.493557ms)
Aug 16 13:08:32.323: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr/proxy/rewriteme"... (200; 6.558171ms)
Aug 16 13:08:32.323: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/https:proxy-service-z87bz-pjgfr:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/https:proxy-service-z87bz-pjgfr:443/proxy/... (200; 6.876071ms)
Aug 16 13:08:32.323: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr:1080/proxy/rewri... (200; 6.886184ms)
Aug 16 13:08:32.323: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/http:proxy-service-z87bz-pjgfr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/http:proxy-service-z87bz-pjgfr:1080/proxy/... (200; 7.234753ms)
Aug 16 13:08:32.323: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/https:proxy-service-z87bz-pjgfr:462/proxy/: tls qux (200; 7.096702ms)
Aug 16 13:08:32.324: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/http:proxy-service-z87bz-pjgfr:160/proxy/: foo (200; 7.486156ms)
Aug 16 13:08:32.324: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr:160/proxy/: foo (200; 7.584321ms)
Aug 16 13:08:32.324: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/http:proxy-service-z87bz-pjgfr:162/proxy/: bar (200; 7.49136ms)
Aug 16 13:08:32.324: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr:162/proxy/: bar (200; 7.866947ms)
Aug 16 13:08:32.326: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/http:proxy-service-z87bz:portname1/proxy/: foo (200; 9.554881ms)
Aug 16 13:08:32.326: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/https:proxy-service-z87bz:tlsportname2/proxy/: tls qux (200; 9.689806ms)
Aug 16 13:08:32.326: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/https:proxy-service-z87bz:tlsportname1/proxy/: tls baz (200; 9.985423ms)
Aug 16 13:08:32.327: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/proxy-service-z87bz:portname2/proxy/: bar (200; 10.186336ms)
Aug 16 13:08:32.327: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/http:proxy-service-z87bz:portname2/proxy/: bar (200; 10.297535ms)
Aug 16 13:08:32.327: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/proxy-service-z87bz:portname1/proxy/: foo (200; 10.704257ms)
Aug 16 13:08:32.332: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr:160/proxy/: foo (200; 5.2739ms)
Aug 16 13:08:32.333: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr/proxy/rewriteme"... (200; 5.503837ms)
Aug 16 13:08:32.333: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/http:proxy-service-z87bz-pjgfr:160/proxy/: foo (200; 5.714727ms)
Aug 16 13:08:32.333: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/http:proxy-service-z87bz-pjgfr:162/proxy/: bar (200; 5.714229ms)
Aug 16 13:08:32.334: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/http:proxy-service-z87bz-pjgfr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/http:proxy-service-z87bz-pjgfr:1080/proxy/... (200; 6.86105ms)
Aug 16 13:08:32.334: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr:162/proxy/: bar (200; 7.142338ms)
Aug 16 13:08:32.335: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/https:proxy-service-z87bz-pjgfr:462/proxy/: tls qux (200; 7.52335ms)
Aug 16 13:08:32.335: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr:1080/proxy/rewri... (200; 7.698065ms)
Aug 16 13:08:32.335: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/https:proxy-service-z87bz-pjgfr:460/proxy/: tls baz (200; 7.96595ms)
Aug 16 13:08:32.335: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/https:proxy-service-z87bz-pjgfr:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/https:proxy-service-z87bz-pjgfr:443/proxy/... (200; 8.095364ms)
Aug 16 13:08:32.335: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/proxy-service-z87bz:portname2/proxy/: bar (200; 8.349534ms)
Aug 16 13:08:32.337: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/proxy-service-z87bz:portname1/proxy/: foo (200; 9.488743ms)
Aug 16 13:08:32.337: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/https:proxy-service-z87bz:tlsportname2/proxy/: tls qux (200; 9.632937ms)
Aug 16 13:08:32.338: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/http:proxy-service-z87bz:portname1/proxy/: foo (200; 10.768313ms)
Aug 16 13:08:32.338: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/https:proxy-service-z87bz:tlsportname1/proxy/: tls baz (200; 11.2253ms)
Aug 16 13:08:32.338: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/http:proxy-service-z87bz:portname2/proxy/: bar (200; 10.978617ms)
Aug 16 13:08:32.342: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr/proxy/rewriteme"... (200; 3.347164ms)
Aug 16 13:08:32.343: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/http:proxy-service-z87bz-pjgfr:160/proxy/: foo (200; 4.890276ms)
Aug 16 13:08:32.343: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr:160/proxy/: foo (200; 4.909788ms)
Aug 16 13:08:32.346: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr:1080/proxy/rewri... (200; 6.734612ms)
Aug 16 13:08:32.346: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/https:proxy-service-z87bz-pjgfr:460/proxy/: tls baz (200; 7.081656ms)
Aug 16 13:08:32.346: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/https:proxy-service-z87bz-pjgfr:462/proxy/: tls qux (200; 7.166509ms)
Aug 16 13:08:32.346: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr:162/proxy/: bar (200; 7.503273ms)
Aug 16 13:08:32.346: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/http:proxy-service-z87bz-pjgfr:162/proxy/: bar (200; 7.677838ms)
Aug 16 13:08:32.346: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/https:proxy-service-z87bz-pjgfr:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/https:proxy-service-z87bz-pjgfr:443/proxy/... (200; 7.622787ms)
Aug 16 13:08:32.346: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/http:proxy-service-z87bz-pjgfr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/http:proxy-service-z87bz-pjgfr:1080/proxy/... (200; 7.352016ms)
Aug 16 13:08:32.348: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/proxy-service-z87bz:portname2/proxy/: bar (200; 9.545088ms)
Aug 16 13:08:32.348: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/proxy-service-z87bz:portname1/proxy/: foo (200; 9.20825ms)
Aug 16 13:08:32.350: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/http:proxy-service-z87bz:portname1/proxy/: foo (200; 10.863247ms)
Aug 16 13:08:32.350: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/https:proxy-service-z87bz:tlsportname2/proxy/: tls qux (200; 11.0154ms)
Aug 16 13:08:32.350: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/https:proxy-service-z87bz:tlsportname1/proxy/: tls baz (200; 10.942498ms)
Aug 16 13:08:32.350: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/http:proxy-service-z87bz:portname2/proxy/: bar (200; 11.306075ms)
Aug 16 13:08:32.359: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/https:proxy-service-z87bz-pjgfr:460/proxy/: tls baz (200; 8.331575ms)
Aug 16 13:08:32.359: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/http:proxy-service-z87bz-pjgfr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/http:proxy-service-z87bz-pjgfr:1080/proxy/... (200; 8.516377ms)
Aug 16 13:08:32.359: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr:1080/proxy/rewri... (200; 8.743673ms)
Aug 16 13:08:32.359: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/http:proxy-service-z87bz-pjgfr:160/proxy/: foo (200; 8.946598ms)
Aug 16 13:08:32.359: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/https:proxy-service-z87bz-pjgfr:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/https:proxy-service-z87bz-pjgfr:443/proxy/... (200; 9.155732ms)
Aug 16 13:08:32.359: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/https:proxy-service-z87bz:tlsportname1/proxy/: tls baz (200; 9.00713ms)
Aug 16 13:08:32.360: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr:160/proxy/: foo (200; 8.95345ms)
Aug 16 13:08:32.360: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr/proxy/rewriteme"... (200; 8.991393ms)
Aug 16 13:08:32.360: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/proxy-service-z87bz:portname2/proxy/: bar (200; 9.4183ms)
Aug 16 13:08:32.360: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr:162/proxy/: bar (200; 9.354419ms)
Aug 16 13:08:32.360: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/https:proxy-service-z87bz-pjgfr:462/proxy/: tls qux (200; 9.227143ms)
Aug 16 13:08:32.360: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/http:proxy-service-z87bz-pjgfr:162/proxy/: bar (200; 10.042514ms)
Aug 16 13:08:32.360: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/http:proxy-service-z87bz:portname2/proxy/: bar (200; 10.104236ms)
Aug 16 13:08:32.360: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/http:proxy-service-z87bz:portname1/proxy/: foo (200; 10.128248ms)
Aug 16 13:08:32.360: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/https:proxy-service-z87bz:tlsportname2/proxy/: tls qux (200; 10.127921ms)
Aug 16 13:08:32.361: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/proxy-service-z87bz:portname1/proxy/: foo (200; 10.059893ms)
Aug 16 13:08:32.364: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/http:proxy-service-z87bz-pjgfr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/http:proxy-service-z87bz-pjgfr:1080/proxy/... (200; 3.38715ms)
Aug 16 13:08:32.366: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/http:proxy-service-z87bz-pjgfr:160/proxy/: foo (200; 5.167326ms)
Aug 16 13:08:32.368: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr/proxy/rewriteme"... (200; 7.274448ms)
Aug 16 13:08:32.369: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/http:proxy-service-z87bz-pjgfr:162/proxy/: bar (200; 7.952332ms)
Aug 16 13:08:32.369: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr:1080/proxy/rewri... (200; 8.418634ms)
Aug 16 13:08:32.369: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr:162/proxy/: bar (200; 8.290262ms)
Aug 16 13:08:32.369: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/https:proxy-service-z87bz-pjgfr:460/proxy/: tls baz (200; 8.570098ms)
Aug 16 13:08:32.369: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/https:proxy-service-z87bz-pjgfr:462/proxy/: tls qux (200; 8.703433ms)
Aug 16 13:08:32.370: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/https:proxy-service-z87bz-pjgfr:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/https:proxy-service-z87bz-pjgfr:443/proxy/... (200; 8.554577ms)
Aug 16 13:08:32.370: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr:160/proxy/: foo (200; 8.830896ms)
Aug 16 13:08:32.371: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/https:proxy-service-z87bz:tlsportname1/proxy/: tls baz (200; 10.283992ms)
Aug 16 13:08:32.371: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/https:proxy-service-z87bz:tlsportname2/proxy/: tls qux (200; 10.502001ms)
Aug 16 13:08:32.371: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/http:proxy-service-z87bz:portname1/proxy/: foo (200; 10.589685ms)
Aug 16 13:08:32.371: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/proxy-service-z87bz:portname1/proxy/: foo (200; 10.75198ms)
Aug 16 13:08:32.372: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/http:proxy-service-z87bz:portname2/proxy/: bar (200; 10.720484ms)
Aug 16 13:08:32.372: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/proxy-service-z87bz:portname2/proxy/: bar (200; 11.085608ms)
Aug 16 13:08:32.376: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/https:proxy-service-z87bz-pjgfr:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/https:proxy-service-z87bz-pjgfr:443/proxy/... (200; 3.650939ms)
Aug 16 13:08:32.380: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/https:proxy-service-z87bz:tlsportname1/proxy/: tls baz (200; 7.90148ms)
Aug 16 13:08:32.380: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/http:proxy-service-z87bz-pjgfr:160/proxy/: foo (200; 7.860544ms)
Aug 16 13:08:32.383: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr:1080/proxy/rewri... (200; 10.445807ms)
Aug 16 13:08:32.385: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr:162/proxy/: bar (200; 9.146386ms)
Aug 16 13:08:32.385: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/https:proxy-service-z87bz-pjgfr:462/proxy/: tls qux (200; 11.885596ms)
Aug 16 13:08:32.385: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr/proxy/rewriteme"... (200; 13.031185ms)
Aug 16 13:08:32.386: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/http:proxy-service-z87bz-pjgfr:162/proxy/: bar (200; 10.148139ms)
Aug 16 13:08:32.386: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr:160/proxy/: foo (200; 10.321687ms)
Aug 16 13:08:32.386: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/http:proxy-service-z87bz:portname1/proxy/: foo (200; 13.476694ms)
Aug 16 13:08:32.386: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/http:proxy-service-z87bz-pjgfr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/http:proxy-service-z87bz-pjgfr:1080/proxy/... (200; 10.630134ms)
Aug 16 13:08:32.386: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/https:proxy-service-z87bz:tlsportname2/proxy/: tls qux (200; 13.555066ms)
Aug 16 13:08:32.386: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/https:proxy-service-z87bz-pjgfr:460/proxy/: tls baz (200; 13.30975ms)
Aug 16 13:08:32.387: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/http:proxy-service-z87bz:portname2/proxy/: bar (200; 13.938791ms)
Aug 16 13:08:32.387: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/proxy-service-z87bz:portname2/proxy/: bar (200; 11.224991ms)
Aug 16 13:08:32.387: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/proxy-service-z87bz:portname1/proxy/: foo (200; 13.157018ms)
Aug 16 13:08:32.390: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr:1080/proxy/rewri... (200; 3.247511ms)
Aug 16 13:08:32.392: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/http:proxy-service-z87bz-pjgfr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/http:proxy-service-z87bz-pjgfr:1080/proxy/... (200; 4.55656ms)
Aug 16 13:08:32.394: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr/proxy/rewriteme"... (200; 6.574089ms)
Aug 16 13:08:32.394: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr:162/proxy/: bar (200; 7.261642ms)
Aug 16 13:08:32.395: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/http:proxy-service-z87bz-pjgfr:160/proxy/: foo (200; 7.172553ms)
Aug 16 13:08:32.395: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/http:proxy-service-z87bz-pjgfr:162/proxy/: bar (200; 7.822663ms)
Aug 16 13:08:32.395: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr:160/proxy/: foo (200; 7.285981ms)
Aug 16 13:08:32.395: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/https:proxy-service-z87bz-pjgfr:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/https:proxy-service-z87bz-pjgfr:443/proxy/... (200; 7.501347ms)
Aug 16 13:08:32.395: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/https:proxy-service-z87bz-pjgfr:460/proxy/: tls baz (200; 7.652123ms)
Aug 16 13:08:32.395: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/https:proxy-service-z87bz-pjgfr:462/proxy/: tls qux (200; 7.668502ms)
Aug 16 13:08:32.395: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/proxy-service-z87bz:portname2/proxy/: bar (200; 8.038893ms)
Aug 16 13:08:32.397: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/http:proxy-service-z87bz:portname2/proxy/: bar (200; 9.359137ms)
Aug 16 13:08:32.397: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/https:proxy-service-z87bz:tlsportname1/proxy/: tls baz (200; 9.433627ms)
Aug 16 13:08:32.397: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/https:proxy-service-z87bz:tlsportname2/proxy/: tls qux (200; 9.652501ms)
Aug 16 13:08:32.397: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/http:proxy-service-z87bz:portname1/proxy/: foo (200; 9.911581ms)
Aug 16 13:08:32.397: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/proxy-service-z87bz:portname1/proxy/: foo (200; 9.898525ms)
Aug 16 13:08:32.406: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr:1080/proxy/rewri... (200; 8.637811ms)
Aug 16 13:08:32.409: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/http:proxy-service-z87bz-pjgfr:162/proxy/: bar (200; 11.609495ms)
Aug 16 13:08:32.409: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/https:proxy-service-z87bz-pjgfr:462/proxy/: tls qux (200; 11.935051ms)
Aug 16 13:08:32.410: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/https:proxy-service-z87bz-pjgfr:460/proxy/: tls baz (200; 12.555777ms)
Aug 16 13:08:32.422: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/http:proxy-service-z87bz-pjgfr:160/proxy/: foo (200; 24.453016ms)
Aug 16 13:08:32.423: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/http:proxy-service-z87bz-pjgfr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/http:proxy-service-z87bz-pjgfr:1080/proxy/... (200; 25.611283ms)
Aug 16 13:08:32.427: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr:160/proxy/: foo (200; 29.526736ms)
Aug 16 13:08:32.429: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/https:proxy-service-z87bz:tlsportname1/proxy/: tls baz (200; 31.146848ms)
Aug 16 13:08:32.430: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/proxy-service-z87bz:portname1/proxy/: foo (200; 32.230505ms)
Aug 16 13:08:32.431: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/https:proxy-service-z87bz-pjgfr:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/https:proxy-service-z87bz-pjgfr:443/proxy/... (200; 33.5339ms)
Aug 16 13:08:32.431: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/http:proxy-service-z87bz:portname1/proxy/: foo (200; 33.541029ms)
Aug 16 13:08:32.431: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr:162/proxy/: bar (200; 33.526932ms)
Aug 16 13:08:32.432: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/http:proxy-service-z87bz:portname2/proxy/: bar (200; 33.79011ms)
Aug 16 13:08:32.432: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/https:proxy-service-z87bz:tlsportname2/proxy/: tls qux (200; 34.043084ms)
Aug 16 13:08:32.432: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/proxy-service-z87bz:portname2/proxy/: bar (200; 34.63347ms)
Aug 16 13:08:32.433: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr/proxy/rewriteme"... (200; 34.915483ms)
Aug 16 13:08:32.445: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/https:proxy-service-z87bz-pjgfr:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/https:proxy-service-z87bz-pjgfr:443/proxy/... (200; 12.467951ms)
Aug 16 13:08:32.446: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr:162/proxy/: bar (200; 12.254905ms)
Aug 16 13:08:32.446: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/https:proxy-service-z87bz-pjgfr:462/proxy/: tls qux (200; 12.966195ms)
Aug 16 13:08:32.446: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/http:proxy-service-z87bz-pjgfr:160/proxy/: foo (200; 13.029225ms)
Aug 16 13:08:32.446: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr:1080/proxy/rewri... (200; 13.335059ms)
Aug 16 13:08:32.446: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/https:proxy-service-z87bz-pjgfr:460/proxy/: tls baz (200; 13.436213ms)
Aug 16 13:08:32.447: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/http:proxy-service-z87bz-pjgfr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/http:proxy-service-z87bz-pjgfr:1080/proxy/... (200; 13.539845ms)
Aug 16 13:08:32.447: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/http:proxy-service-z87bz-pjgfr:162/proxy/: bar (200; 13.793374ms)
Aug 16 13:08:32.447: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr/proxy/rewriteme"... (200; 13.932717ms)
Aug 16 13:08:32.447: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr:160/proxy/: foo (200; 13.912931ms)
Aug 16 13:08:32.447: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/http:proxy-service-z87bz:portname1/proxy/: foo (200; 14.656594ms)
Aug 16 13:08:32.451: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/https:proxy-service-z87bz:tlsportname1/proxy/: tls baz (200; 17.68896ms)
Aug 16 13:08:32.451: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/https:proxy-service-z87bz:tlsportname2/proxy/: tls qux (200; 18.158672ms)
Aug 16 13:08:32.451: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/proxy-service-z87bz:portname2/proxy/: bar (200; 17.909882ms)
Aug 16 13:08:32.451: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/http:proxy-service-z87bz:portname2/proxy/: bar (200; 18.510399ms)
Aug 16 13:08:32.451: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/proxy-service-z87bz:portname1/proxy/: foo (200; 18.467998ms)
Aug 16 13:08:32.460: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/https:proxy-service-z87bz-pjgfr:462/proxy/: tls qux (200; 8.080925ms)
Aug 16 13:08:32.462: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/https:proxy-service-z87bz-pjgfr:460/proxy/: tls baz (200; 10.600128ms)
Aug 16 13:08:32.463: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr:160/proxy/: foo (200; 11.687392ms)
Aug 16 13:08:32.471: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr:1080/proxy/rewri... (200; 18.744581ms)
Aug 16 13:08:32.471: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/http:proxy-service-z87bz-pjgfr:160/proxy/: foo (200; 18.657806ms)
Aug 16 13:08:32.471: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/https:proxy-service-z87bz:tlsportname2/proxy/: tls qux (200; 18.880247ms)
Aug 16 13:08:32.471: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/http:proxy-service-z87bz:portname1/proxy/: foo (200; 18.98453ms)
Aug 16 13:08:32.473: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/http:proxy-service-z87bz:portname2/proxy/: bar (200; 21.276145ms)
Aug 16 13:08:32.473: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/https:proxy-service-z87bz-pjgfr:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/https:proxy-service-z87bz-pjgfr:443/proxy/... (200; 21.249828ms)
Aug 16 13:08:32.474: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/http:proxy-service-z87bz-pjgfr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/http:proxy-service-z87bz-pjgfr:1080/proxy/... (200; 22.03666ms)
Aug 16 13:08:32.474: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr:162/proxy/: bar (200; 22.317849ms)
Aug 16 13:08:32.475: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/proxy-service-z87bz:portname2/proxy/: bar (200; 23.208015ms)
Aug 16 13:08:32.475: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/proxy-service-z87bz:portname1/proxy/: foo (200; 23.788839ms)
Aug 16 13:08:32.475: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/http:proxy-service-z87bz-pjgfr:162/proxy/: bar (200; 23.469843ms)
Aug 16 13:08:32.476: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr/proxy/rewriteme"... (200; 23.700233ms)
Aug 16 13:08:32.476: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/https:proxy-service-z87bz:tlsportname1/proxy/: tls baz (200; 23.927906ms)
Aug 16 13:08:32.488: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr:1080/proxy/rewri... (200; 11.667036ms)
Aug 16 13:08:32.489: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/http:proxy-service-z87bz-pjgfr:162/proxy/: bar (200; 12.399232ms)
Aug 16 13:08:32.489: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr:160/proxy/: foo (200; 12.50559ms)
Aug 16 13:08:32.489: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/http:proxy-service-z87bz-pjgfr:160/proxy/: foo (200; 12.678092ms)
Aug 16 13:08:32.490: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/https:proxy-service-z87bz-pjgfr:460/proxy/: tls baz (200; 13.642175ms)
Aug 16 13:08:32.490: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/http:proxy-service-z87bz-pjgfr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/http:proxy-service-z87bz-pjgfr:1080/proxy/... (200; 14.183725ms)
Aug 16 13:08:32.491: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr:162/proxy/: bar (200; 14.439891ms)
Aug 16 13:08:32.491: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/proxy-service-z87bz:portname1/proxy/: foo (200; 14.911625ms)
Aug 16 13:08:32.491: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/https:proxy-service-z87bz-pjgfr:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/https:proxy-service-z87bz-pjgfr:443/proxy/... (200; 14.55272ms)
Aug 16 13:08:32.491: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr/proxy/rewriteme"... (200; 14.990788ms)
Aug 16 13:08:32.491: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/https:proxy-service-z87bz-pjgfr:462/proxy/: tls qux (200; 15.61976ms)
Aug 16 13:08:32.492: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/proxy-service-z87bz:portname2/proxy/: bar (200; 16.262236ms)
Aug 16 13:08:32.494: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/https:proxy-service-z87bz:tlsportname2/proxy/: tls qux (200; 17.838951ms)
Aug 16 13:08:32.495: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/http:proxy-service-z87bz:portname2/proxy/: bar (200; 19.015191ms)
Aug 16 13:08:32.497: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/http:proxy-service-z87bz:portname1/proxy/: foo (200; 21.071852ms)
Aug 16 13:08:32.497: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/https:proxy-service-z87bz:tlsportname1/proxy/: tls baz (200; 21.484075ms)
Aug 16 13:08:32.507: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/https:proxy-service-z87bz-pjgfr:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/https:proxy-service-z87bz-pjgfr:443/proxy/... (200; 9.682738ms)
Aug 16 13:08:32.507: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr:162/proxy/: bar (200; 9.794448ms)
Aug 16 13:08:32.507: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/http:proxy-service-z87bz-pjgfr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/http:proxy-service-z87bz-pjgfr:1080/proxy/... (200; 9.848513ms)
Aug 16 13:08:32.511: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr:1080/proxy/rewri... (200; 13.469281ms)
Aug 16 13:08:32.512: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/http:proxy-service-z87bz:portname1/proxy/: foo (200; 14.226384ms)
Aug 16 13:08:32.513: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr/proxy/rewriteme"... (200; 15.320763ms)
Aug 16 13:08:32.514: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/http:proxy-service-z87bz:portname2/proxy/: bar (200; 15.896214ms)
Aug 16 13:08:32.514: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/https:proxy-service-z87bz:tlsportname1/proxy/: tls baz (200; 15.888502ms)
Aug 16 13:08:32.514: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/https:proxy-service-z87bz-pjgfr:462/proxy/: tls qux (200; 16.310505ms)
Aug 16 13:08:32.514: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/http:proxy-service-z87bz-pjgfr:160/proxy/: foo (200; 16.406465ms)
Aug 16 13:08:32.514: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/proxy-service-z87bz:portname2/proxy/: bar (200; 16.858635ms)
Aug 16 13:08:32.515: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/http:proxy-service-z87bz-pjgfr:162/proxy/: bar (200; 16.564686ms)
Aug 16 13:08:32.514: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/https:proxy-service-z87bz-pjgfr:460/proxy/: tls baz (200; 16.502018ms)
Aug 16 13:08:32.515: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/https:proxy-service-z87bz:tlsportname2/proxy/: tls qux (200; 17.183852ms)
Aug 16 13:08:32.515: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/proxy-service-z87bz:portname1/proxy/: foo (200; 16.556514ms)
Aug 16 13:08:32.515: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr:160/proxy/: foo (200; 16.676548ms)
Aug 16 13:08:32.521: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/https:proxy-service-z87bz-pjgfr:462/proxy/: tls qux (200; 5.490241ms)
Aug 16 13:08:32.521: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/https:proxy-service-z87bz-pjgfr:460/proxy/: tls baz (200; 5.563104ms)
Aug 16 13:08:32.521: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr:1080/proxy/rewri... (200; 5.748798ms)
Aug 16 13:08:32.522: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/https:proxy-service-z87bz:tlsportname1/proxy/: tls baz (200; 6.886343ms)
Aug 16 13:08:32.523: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/http:proxy-service-z87bz-pjgfr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/http:proxy-service-z87bz-pjgfr:1080/proxy/... (200; 7.322188ms)
Aug 16 13:08:32.523: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr/proxy/rewriteme"... (200; 7.696524ms)
Aug 16 13:08:32.523: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/http:proxy-service-z87bz-pjgfr:162/proxy/: bar (200; 7.950095ms)
Aug 16 13:08:32.523: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/https:proxy-service-z87bz-pjgfr:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/https:proxy-service-z87bz-pjgfr:443/proxy/... (200; 7.706151ms)
Aug 16 13:08:32.523: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr:160/proxy/: foo (200; 8.064933ms)
Aug 16 13:08:32.523: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/http:proxy-service-z87bz-pjgfr:160/proxy/: foo (200; 8.173845ms)
Aug 16 13:08:32.524: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr:162/proxy/: bar (200; 8.327923ms)
Aug 16 13:08:32.524: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/http:proxy-service-z87bz:portname1/proxy/: foo (200; 9.006233ms)
Aug 16 13:08:32.524: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/proxy-service-z87bz:portname1/proxy/: foo (200; 8.834503ms)
Aug 16 13:08:32.525: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/https:proxy-service-z87bz:tlsportname2/proxy/: tls qux (200; 9.677232ms)
Aug 16 13:08:32.525: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/http:proxy-service-z87bz:portname2/proxy/: bar (200; 9.774579ms)
Aug 16 13:08:32.526: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/proxy-service-z87bz:portname2/proxy/: bar (200; 10.452459ms)
Aug 16 13:08:32.531: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/https:proxy-service-z87bz-pjgfr:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/https:proxy-service-z87bz-pjgfr:443/proxy/... (200; 4.857833ms)
Aug 16 13:08:32.533: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr/proxy/rewriteme"... (200; 7.161642ms)
Aug 16 13:08:32.533: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr:162/proxy/: bar (200; 7.226483ms)
Aug 16 13:08:32.534: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/http:proxy-service-z87bz-pjgfr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/http:proxy-service-z87bz-pjgfr:1080/proxy/... (200; 7.616288ms)
Aug 16 13:08:32.534: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/https:proxy-service-z87bz-pjgfr:462/proxy/: tls qux (200; 7.676102ms)
Aug 16 13:08:32.534: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/http:proxy-service-z87bz-pjgfr:160/proxy/: foo (200; 7.912679ms)
Aug 16 13:08:32.534: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/http:proxy-service-z87bz-pjgfr:162/proxy/: bar (200; 8.033018ms)
Aug 16 13:08:32.534: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr:1080/proxy/rewri... (200; 7.954798ms)
Aug 16 13:08:32.534: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/https:proxy-service-z87bz-pjgfr:460/proxy/: tls baz (200; 8.005903ms)
Aug 16 13:08:32.534: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/https:proxy-service-z87bz:tlsportname1/proxy/: tls baz (200; 8.50168ms)
Aug 16 13:08:32.535: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr:160/proxy/: foo (200; 8.541237ms)
Aug 16 13:08:32.535: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/https:proxy-service-z87bz:tlsportname2/proxy/: tls qux (200; 8.796059ms)
Aug 16 13:08:32.537: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/http:proxy-service-z87bz:portname2/proxy/: bar (200; 10.239794ms)
Aug 16 13:08:32.537: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/proxy-service-z87bz:portname2/proxy/: bar (200; 10.631425ms)
Aug 16 13:08:32.537: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/proxy-service-z87bz:portname1/proxy/: foo (200; 10.43235ms)
Aug 16 13:08:32.537: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/http:proxy-service-z87bz:portname1/proxy/: foo (200; 10.59192ms)
Aug 16 13:08:32.542: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr/proxy/rewriteme"... (200; 5.008338ms)
Aug 16 13:08:32.542: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/https:proxy-service-z87bz-pjgfr:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/https:proxy-service-z87bz-pjgfr:443/proxy/... (200; 5.533172ms)
Aug 16 13:08:32.543: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr:160/proxy/: foo (200; 5.289849ms)
Aug 16 13:08:32.543: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/https:proxy-service-z87bz-pjgfr:460/proxy/: tls baz (200; 5.588894ms)
Aug 16 13:08:32.544: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr:1080/proxy/rewri... (200; 6.984838ms)
Aug 16 13:08:32.545: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/https:proxy-service-z87bz:tlsportname1/proxy/: tls baz (200; 7.705007ms)
Aug 16 13:08:32.545: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/http:proxy-service-z87bz-pjgfr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/http:proxy-service-z87bz-pjgfr:1080/proxy/... (200; 7.501189ms)
Aug 16 13:08:32.545: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/http:proxy-service-z87bz-pjgfr:162/proxy/: bar (200; 7.600174ms)
Aug 16 13:08:32.545: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/https:proxy-service-z87bz-pjgfr:462/proxy/: tls qux (200; 7.83297ms)
Aug 16 13:08:32.545: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr:162/proxy/: bar (200; 7.485748ms)
Aug 16 13:08:32.545: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/http:proxy-service-z87bz-pjgfr:160/proxy/: foo (200; 7.742405ms)
Aug 16 13:08:32.547: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/proxy-service-z87bz:portname2/proxy/: bar (200; 9.300864ms)
Aug 16 13:08:32.548: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/https:proxy-service-z87bz:tlsportname2/proxy/: tls qux (200; 10.99477ms)
Aug 16 13:08:32.548: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/http:proxy-service-z87bz:portname1/proxy/: foo (200; 11.173567ms)
Aug 16 13:08:32.548: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/proxy-service-z87bz:portname1/proxy/: foo (200; 11.008214ms)
Aug 16 13:08:32.548: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/http:proxy-service-z87bz:portname2/proxy/: bar (200; 11.35302ms)
Aug 16 13:08:32.552: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr:160/proxy/: foo (200; 3.301936ms)
Aug 16 13:08:32.554: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr:162/proxy/: bar (200; 5.032633ms)
Aug 16 13:08:32.555: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/http:proxy-service-z87bz-pjgfr:160/proxy/: foo (200; 6.576448ms)
Aug 16 13:08:32.556: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/https:proxy-service-z87bz-pjgfr:460/proxy/: tls baz (200; 7.732182ms)
Aug 16 13:08:32.556: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr/proxy/rewriteme"... (200; 7.414615ms)
Aug 16 13:08:32.557: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/https:proxy-service-z87bz-pjgfr:462/proxy/: tls qux (200; 7.996614ms)
Aug 16 13:08:32.557: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/https:proxy-service-z87bz-pjgfr:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/https:proxy-service-z87bz-pjgfr:443/proxy/... (200; 8.189085ms)
Aug 16 13:08:32.557: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/http:proxy-service-z87bz-pjgfr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/http:proxy-service-z87bz-pjgfr:1080/proxy/... (200; 8.248727ms)
Aug 16 13:08:32.557: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/http:proxy-service-z87bz-pjgfr:162/proxy/: bar (200; 8.451744ms)
Aug 16 13:08:32.558: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr:1080/proxy/rewri... (200; 9.107214ms)
Aug 16 13:08:32.558: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/proxy-service-z87bz:portname2/proxy/: bar (200; 9.023926ms)
Aug 16 13:08:32.559: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/http:proxy-service-z87bz:portname2/proxy/: bar (200; 10.483182ms)
Aug 16 13:08:32.560: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/proxy-service-z87bz:portname1/proxy/: foo (200; 10.617103ms)
Aug 16 13:08:32.560: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/http:proxy-service-z87bz:portname1/proxy/: foo (200; 10.773459ms)
Aug 16 13:08:32.560: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/https:proxy-service-z87bz:tlsportname2/proxy/: tls qux (200; 11.088818ms)
Aug 16 13:08:32.560: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/https:proxy-service-z87bz:tlsportname1/proxy/: tls baz (200; 10.892789ms)
Aug 16 13:08:32.563: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/http:proxy-service-z87bz-pjgfr:162/proxy/: bar (200; 3.537121ms)
Aug 16 13:08:32.565: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/http:proxy-service-z87bz-pjgfr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/http:proxy-service-z87bz-pjgfr:1080/proxy/... (200; 4.950639ms)
Aug 16 13:08:32.567: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr:1080/proxy/rewri... (200; 7.172285ms)
Aug 16 13:08:32.568: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/proxy-service-z87bz:portname2/proxy/: bar (200; 7.644009ms)
Aug 16 13:08:32.568: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr:162/proxy/: bar (200; 7.576651ms)
Aug 16 13:08:32.568: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/https:proxy-service-z87bz-pjgfr:460/proxy/: tls baz (200; 7.517318ms)
Aug 16 13:08:32.568: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/https:proxy-service-z87bz-pjgfr:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/https:proxy-service-z87bz-pjgfr:443/proxy/... (200; 7.85344ms)
Aug 16 13:08:32.568: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/http:proxy-service-z87bz-pjgfr:160/proxy/: foo (200; 8.039975ms)
Aug 16 13:08:32.568: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr:160/proxy/: foo (200; 8.029875ms)
Aug 16 13:08:32.568: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr/proxy/rewriteme"... (200; 8.121291ms)
Aug 16 13:08:32.569: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/https:proxy-service-z87bz:tlsportname2/proxy/: tls qux (200; 8.616473ms)
Aug 16 13:08:32.569: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/https:proxy-service-z87bz-pjgfr:462/proxy/: tls qux (200; 8.371865ms)
Aug 16 13:08:32.570: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/http:proxy-service-z87bz:portname2/proxy/: bar (200; 9.598167ms)
Aug 16 13:08:32.570: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/proxy-service-z87bz:portname1/proxy/: foo (200; 9.869993ms)
Aug 16 13:08:32.570: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/http:proxy-service-z87bz:portname1/proxy/: foo (200; 9.57203ms)
Aug 16 13:08:32.571: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/https:proxy-service-z87bz:tlsportname1/proxy/: tls baz (200; 10.97464ms)
Aug 16 13:08:32.576: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/https:proxy-service-z87bz-pjgfr:460/proxy/: tls baz (200; 4.725083ms)
Aug 16 13:08:32.579: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr:162/proxy/: bar (200; 6.925196ms)
Aug 16 13:08:32.579: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr:160/proxy/: foo (200; 7.597488ms)
Aug 16 13:08:32.579: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/https:proxy-service-z87bz-pjgfr:462/proxy/: tls qux (200; 7.753656ms)
Aug 16 13:08:32.579: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr/proxy/rewriteme"... (200; 7.564705ms)
Aug 16 13:08:32.579: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr:1080/proxy/rewri... (200; 8.057293ms)
Aug 16 13:08:32.580: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/https:proxy-service-z87bz-pjgfr:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/https:proxy-service-z87bz-pjgfr:443/proxy/... (200; 8.028518ms)
Aug 16 13:08:32.580: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/http:proxy-service-z87bz-pjgfr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/http:proxy-service-z87bz-pjgfr:1080/proxy/... (200; 8.194397ms)
Aug 16 13:08:32.580: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/http:proxy-service-z87bz-pjgfr:162/proxy/: bar (200; 8.380052ms)
Aug 16 13:08:32.580: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/proxy-service-z87bz:portname1/proxy/: foo (200; 8.868778ms)
Aug 16 13:08:32.580: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/http:proxy-service-z87bz-pjgfr:160/proxy/: foo (200; 8.579681ms)
Aug 16 13:08:32.580: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/http:proxy-service-z87bz:portname2/proxy/: bar (200; 9.025689ms)
Aug 16 13:08:32.580: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/https:proxy-service-z87bz:tlsportname2/proxy/: tls qux (200; 8.968103ms)
Aug 16 13:08:32.581: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/http:proxy-service-z87bz:portname1/proxy/: foo (200; 9.595038ms)
Aug 16 13:08:32.581: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/proxy-service-z87bz:portname2/proxy/: bar (200; 9.386404ms)
Aug 16 13:08:32.581: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/https:proxy-service-z87bz:tlsportname1/proxy/: tls baz (200; 9.725293ms)
Aug 16 13:08:32.585: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr:1080/proxy/rewri... (200; 3.336895ms)
Aug 16 13:08:32.589: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/https:proxy-service-z87bz-pjgfr:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/https:proxy-service-z87bz-pjgfr:443/proxy/... (200; 6.917649ms)
Aug 16 13:08:32.589: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr/proxy/rewriteme"... (200; 7.515945ms)
Aug 16 13:08:32.589: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr:160/proxy/: foo (200; 7.589236ms)
Aug 16 13:08:32.589: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/http:proxy-service-z87bz-pjgfr:162/proxy/: bar (200; 7.631747ms)
Aug 16 13:08:32.589: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/https:proxy-service-z87bz-pjgfr:462/proxy/: tls qux (200; 7.432988ms)
Aug 16 13:08:32.589: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/http:proxy-service-z87bz-pjgfr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/http:proxy-service-z87bz-pjgfr:1080/proxy/... (200; 7.599555ms)
Aug 16 13:08:32.589: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/proxy-service-z87bz-pjgfr:162/proxy/: bar (200; 7.633503ms)
Aug 16 13:08:32.590: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/proxy-service-z87bz:portname1/proxy/: foo (200; 8.413388ms)
Aug 16 13:08:32.590: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/https:proxy-service-z87bz-pjgfr:460/proxy/: tls baz (200; 8.168022ms)
Aug 16 13:08:32.590: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-zdrrg/pods/http:proxy-service-z87bz-pjgfr:160/proxy/: foo (200; 8.576481ms)
Aug 16 13:08:32.590: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/https:proxy-service-z87bz:tlsportname1/proxy/: tls baz (200; 8.756343ms)
Aug 16 13:08:32.591: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/https:proxy-service-z87bz:tlsportname2/proxy/: tls qux (200; 8.913728ms)
Aug 16 13:08:32.591: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/http:proxy-service-z87bz:portname1/proxy/: foo (200; 8.997801ms)
Aug 16 13:08:32.591: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/proxy-service-z87bz:portname2/proxy/: bar (200; 9.435491ms)
Aug 16 13:08:32.592: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-zdrrg/services/http:proxy-service-z87bz:portname2/proxy/: bar (200; 10.578002ms)
STEP: deleting ReplicationController proxy-service-z87bz in namespace e2e-tests-proxy-zdrrg, will wait for the garbage collector to delete the pods
Aug 16 13:08:32.656: INFO: Deleting ReplicationController proxy-service-z87bz took: 10.145178ms
Aug 16 13:08:32.756: INFO: Terminating ReplicationController proxy-service-z87bz pods took: 100.104505ms
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:08:41.356: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-zdrrg" for this suite.
Aug 16 13:08:47.373: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:08:47.443: INFO: namespace: e2e-tests-proxy-zdrrg, resource: bindings, ignored listing per whitelist
Aug 16 13:08:47.490: INFO: namespace e2e-tests-proxy-zdrrg deletion completed in 6.129254949s

• [SLOW TEST:21.342 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:08:47.490: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1399
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug 16 13:08:47.589: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-7nk2f'
Aug 16 13:08:47.967: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Aug 16 13:08:47.967: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1404
Aug 16 13:08:49.982: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-7nk2f'
Aug 16 13:08:50.059: INFO: stderr: ""
Aug 16 13:08:50.059: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:08:50.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-7nk2f" for this suite.
Aug 16 13:08:56.078: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:08:56.130: INFO: namespace: e2e-tests-kubectl-7nk2f, resource: bindings, ignored listing per whitelist
Aug 16 13:08:56.189: INFO: namespace e2e-tests-kubectl-7nk2f deletion completed in 6.125818568s

• [SLOW TEST:8.699 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:08:56.189: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Aug 16 13:08:56.247: INFO: Waiting up to 5m0s for pod "downward-api-00df3df0-c027-11e9-99f6-8a077000b195" in namespace "e2e-tests-downward-api-8pchg" to be "success or failure"
Aug 16 13:08:56.254: INFO: Pod "downward-api-00df3df0-c027-11e9-99f6-8a077000b195": Phase="Pending", Reason="", readiness=false. Elapsed: 6.57429ms
Aug 16 13:08:58.258: INFO: Pod "downward-api-00df3df0-c027-11e9-99f6-8a077000b195": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010529077s
Aug 16 13:09:00.262: INFO: Pod "downward-api-00df3df0-c027-11e9-99f6-8a077000b195": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01448005s
STEP: Saw pod success
Aug 16 13:09:00.262: INFO: Pod "downward-api-00df3df0-c027-11e9-99f6-8a077000b195" satisfied condition "success or failure"
Aug 16 13:09:00.265: INFO: Trying to get logs from node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 pod downward-api-00df3df0-c027-11e9-99f6-8a077000b195 container dapi-container: <nil>
STEP: delete the pod
Aug 16 13:09:00.293: INFO: Waiting for pod downward-api-00df3df0-c027-11e9-99f6-8a077000b195 to disappear
Aug 16 13:09:00.296: INFO: Pod downward-api-00df3df0-c027-11e9-99f6-8a077000b195 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:09:00.296: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-8pchg" for this suite.
Aug 16 13:09:06.314: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:09:06.392: INFO: namespace: e2e-tests-downward-api-8pchg, resource: bindings, ignored listing per whitelist
Aug 16 13:09:06.428: INFO: namespace e2e-tests-downward-api-8pchg deletion completed in 6.129034241s

• [SLOW TEST:10.239 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:09:06.428: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1298
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug 16 13:09:06.477: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-ml4v8'
Aug 16 13:09:06.553: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Aug 16 13:09:06.553: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Aug 16 13:09:06.567: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-lqh7r]
Aug 16 13:09:06.567: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-lqh7r" in namespace "e2e-tests-kubectl-ml4v8" to be "running and ready"
Aug 16 13:09:06.571: INFO: Pod "e2e-test-nginx-rc-lqh7r": Phase="Pending", Reason="", readiness=false. Elapsed: 4.110327ms
Aug 16 13:09:08.575: INFO: Pod "e2e-test-nginx-rc-lqh7r": Phase="Running", Reason="", readiness=true. Elapsed: 2.007937087s
Aug 16 13:09:08.575: INFO: Pod "e2e-test-nginx-rc-lqh7r" satisfied condition "running and ready"
Aug 16 13:09:08.575: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-lqh7r]
Aug 16 13:09:08.575: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-ml4v8'
Aug 16 13:09:08.652: INFO: stderr: ""
Aug 16 13:09:08.652: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1303
Aug 16 13:09:08.652: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-ml4v8'
Aug 16 13:09:08.722: INFO: stderr: ""
Aug 16 13:09:08.722: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:09:08.722: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-ml4v8" for this suite.
Aug 16 13:09:30.746: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:09:30.821: INFO: namespace: e2e-tests-kubectl-ml4v8, resource: bindings, ignored listing per whitelist
Aug 16 13:09:30.858: INFO: namespace e2e-tests-kubectl-ml4v8 deletion completed in 22.131869093s

• [SLOW TEST:24.429 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:09:30.858: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0816 13:10:00.957941      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Aug 16 13:10:00.958: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:10:00.958: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-84vc6" for this suite.
Aug 16 13:10:06.975: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:10:07.004: INFO: namespace: e2e-tests-gc-84vc6, resource: bindings, ignored listing per whitelist
Aug 16 13:10:07.088: INFO: namespace e2e-tests-gc-84vc6 deletion completed in 6.126485119s

• [SLOW TEST:36.229 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:10:07.088: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-2b218b90-c027-11e9-99f6-8a077000b195
STEP: Creating a pod to test consume secrets
Aug 16 13:10:07.152: INFO: Waiting up to 5m0s for pod "pod-secrets-2b223cc6-c027-11e9-99f6-8a077000b195" in namespace "e2e-tests-secrets-vq9sf" to be "success or failure"
Aug 16 13:10:07.158: INFO: Pod "pod-secrets-2b223cc6-c027-11e9-99f6-8a077000b195": Phase="Pending", Reason="", readiness=false. Elapsed: 6.185916ms
Aug 16 13:10:09.162: INFO: Pod "pod-secrets-2b223cc6-c027-11e9-99f6-8a077000b195": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010014202s
STEP: Saw pod success
Aug 16 13:10:09.162: INFO: Pod "pod-secrets-2b223cc6-c027-11e9-99f6-8a077000b195" satisfied condition "success or failure"
Aug 16 13:10:09.165: INFO: Trying to get logs from node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 pod pod-secrets-2b223cc6-c027-11e9-99f6-8a077000b195 container secret-volume-test: <nil>
STEP: delete the pod
Aug 16 13:10:09.193: INFO: Waiting for pod pod-secrets-2b223cc6-c027-11e9-99f6-8a077000b195 to disappear
Aug 16 13:10:09.199: INFO: Pod pod-secrets-2b223cc6-c027-11e9-99f6-8a077000b195 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:10:09.199: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-vq9sf" for this suite.
Aug 16 13:10:15.216: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:10:15.283: INFO: namespace: e2e-tests-secrets-vq9sf, resource: bindings, ignored listing per whitelist
Aug 16 13:10:15.325: INFO: namespace e2e-tests-secrets-vq9sf deletion completed in 6.121685639s

• [SLOW TEST:8.237 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:10:15.325: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-p4c7p/configmap-test-300b7e08-c027-11e9-99f6-8a077000b195
STEP: Creating a pod to test consume configMaps
Aug 16 13:10:15.397: INFO: Waiting up to 5m0s for pod "pod-configmaps-300c1b8c-c027-11e9-99f6-8a077000b195" in namespace "e2e-tests-configmap-p4c7p" to be "success or failure"
Aug 16 13:10:15.400: INFO: Pod "pod-configmaps-300c1b8c-c027-11e9-99f6-8a077000b195": Phase="Pending", Reason="", readiness=false. Elapsed: 3.637059ms
Aug 16 13:10:17.404: INFO: Pod "pod-configmaps-300c1b8c-c027-11e9-99f6-8a077000b195": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007361781s
STEP: Saw pod success
Aug 16 13:10:17.404: INFO: Pod "pod-configmaps-300c1b8c-c027-11e9-99f6-8a077000b195" satisfied condition "success or failure"
Aug 16 13:10:17.407: INFO: Trying to get logs from node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 pod pod-configmaps-300c1b8c-c027-11e9-99f6-8a077000b195 container env-test: <nil>
STEP: delete the pod
Aug 16 13:10:17.431: INFO: Waiting for pod pod-configmaps-300c1b8c-c027-11e9-99f6-8a077000b195 to disappear
Aug 16 13:10:17.435: INFO: Pod pod-configmaps-300c1b8c-c027-11e9-99f6-8a077000b195 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:10:17.435: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-p4c7p" for this suite.
Aug 16 13:10:23.456: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:10:23.482: INFO: namespace: e2e-tests-configmap-p4c7p, resource: bindings, ignored listing per whitelist
Aug 16 13:10:23.686: INFO: namespace e2e-tests-configmap-p4c7p deletion completed in 6.247467681s

• [SLOW TEST:8.362 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:10:23.686: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-8kjf9
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Aug 16 13:10:23.798: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Aug 16 13:10:23.799: INFO: Condition Ready of node worker-eab92000-c026-11e9-bfed-069795ba99e0 is false instead of true. Reason: KubeletNotReady, message: runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:docker: network plugin is not ready: cni config uninitialized
STEP: Creating test pods
Aug 16 13:11:13.890: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.2.4.3:8080/dial?request=hostName&protocol=http&host=10.2.4.2&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-8kjf9 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 16 13:11:13.890: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
Aug 16 13:11:13.969: INFO: Waiting for endpoints: map[]
Aug 16 13:11:13.973: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.2.4.3:8080/dial?request=hostName&protocol=http&host=10.2.3.15&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-8kjf9 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 16 13:11:13.973: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
Aug 16 13:11:14.047: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:11:14.047: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-8kjf9" for this suite.
Aug 16 13:11:36.082: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:11:36.114: INFO: namespace: e2e-tests-pod-network-test-8kjf9, resource: bindings, ignored listing per whitelist
Aug 16 13:11:36.198: INFO: namespace e2e-tests-pod-network-test-8kjf9 deletion completed in 22.145849298s

• [SLOW TEST:72.511 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:11:36.198: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-60403ec0-c027-11e9-99f6-8a077000b195
STEP: Creating a pod to test consume configMaps
Aug 16 13:11:36.272: INFO: Waiting up to 5m0s for pod "pod-configmaps-6040dff5-c027-11e9-99f6-8a077000b195" in namespace "e2e-tests-configmap-x2vh6" to be "success or failure"
Aug 16 13:11:36.276: INFO: Pod "pod-configmaps-6040dff5-c027-11e9-99f6-8a077000b195": Phase="Pending", Reason="", readiness=false. Elapsed: 4.098044ms
Aug 16 13:11:38.280: INFO: Pod "pod-configmaps-6040dff5-c027-11e9-99f6-8a077000b195": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007462219s
Aug 16 13:11:40.283: INFO: Pod "pod-configmaps-6040dff5-c027-11e9-99f6-8a077000b195": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010955837s
STEP: Saw pod success
Aug 16 13:11:40.283: INFO: Pod "pod-configmaps-6040dff5-c027-11e9-99f6-8a077000b195" satisfied condition "success or failure"
Aug 16 13:11:40.286: INFO: Trying to get logs from node worker-eab92000-c026-11e9-bfed-069795ba99e0 pod pod-configmaps-6040dff5-c027-11e9-99f6-8a077000b195 container configmap-volume-test: <nil>
STEP: delete the pod
Aug 16 13:11:40.320: INFO: Waiting for pod pod-configmaps-6040dff5-c027-11e9-99f6-8a077000b195 to disappear
Aug 16 13:11:40.324: INFO: Pod pod-configmaps-6040dff5-c027-11e9-99f6-8a077000b195 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:11:40.324: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-x2vh6" for this suite.
Aug 16 13:11:46.347: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:11:46.437: INFO: namespace: e2e-tests-configmap-x2vh6, resource: bindings, ignored listing per whitelist
Aug 16 13:11:46.466: INFO: namespace e2e-tests-configmap-x2vh6 deletion completed in 6.138025012s

• [SLOW TEST:10.268 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:11:46.466: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Aug 16 13:11:46.525: INFO: Pod name pod-release: Found 0 pods out of 1
Aug 16 13:11:51.529: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:11:51.546: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-6h9l9" for this suite.
Aug 16 13:11:57.579: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:11:57.620: INFO: namespace: e2e-tests-replication-controller-6h9l9, resource: bindings, ignored listing per whitelist
Aug 16 13:11:57.700: INFO: namespace e2e-tests-replication-controller-6h9l9 deletion completed in 6.149406374s

• [SLOW TEST:11.234 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:11:57.700: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Aug 16 13:11:57.749: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 create -f - --namespace=e2e-tests-kubectl-t7qlz'
Aug 16 13:11:58.141: INFO: stderr: ""
Aug 16 13:11:58.142: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug 16 13:11:58.142: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-t7qlz'
Aug 16 13:11:58.220: INFO: stderr: ""
Aug 16 13:11:58.220: INFO: stdout: "update-demo-nautilus-68bxv update-demo-nautilus-vf5nd "
Aug 16 13:11:58.220: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 get pods update-demo-nautilus-68bxv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-t7qlz'
Aug 16 13:11:58.275: INFO: stderr: ""
Aug 16 13:11:58.275: INFO: stdout: ""
Aug 16 13:11:58.275: INFO: update-demo-nautilus-68bxv is created but not running
Aug 16 13:12:03.276: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-t7qlz'
Aug 16 13:12:03.339: INFO: stderr: ""
Aug 16 13:12:03.339: INFO: stdout: "update-demo-nautilus-68bxv update-demo-nautilus-vf5nd "
Aug 16 13:12:03.339: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 get pods update-demo-nautilus-68bxv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-t7qlz'
Aug 16 13:12:03.395: INFO: stderr: ""
Aug 16 13:12:03.395: INFO: stdout: "true"
Aug 16 13:12:03.395: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 get pods update-demo-nautilus-68bxv -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-t7qlz'
Aug 16 13:12:03.450: INFO: stderr: ""
Aug 16 13:12:03.450: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 16 13:12:03.450: INFO: validating pod update-demo-nautilus-68bxv
Aug 16 13:12:03.455: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 16 13:12:03.456: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 16 13:12:03.456: INFO: update-demo-nautilus-68bxv is verified up and running
Aug 16 13:12:03.456: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 get pods update-demo-nautilus-vf5nd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-t7qlz'
Aug 16 13:12:03.512: INFO: stderr: ""
Aug 16 13:12:03.512: INFO: stdout: "true"
Aug 16 13:12:03.512: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 get pods update-demo-nautilus-vf5nd -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-t7qlz'
Aug 16 13:12:03.567: INFO: stderr: ""
Aug 16 13:12:03.567: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 16 13:12:03.567: INFO: validating pod update-demo-nautilus-vf5nd
Aug 16 13:12:03.571: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 16 13:12:03.571: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 16 13:12:03.571: INFO: update-demo-nautilus-vf5nd is verified up and running
STEP: scaling down the replication controller
Aug 16 13:12:03.572: INFO: scanned /root for discovery docs: <nil>
Aug 16 13:12:03.572: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-t7qlz'
Aug 16 13:12:04.660: INFO: stderr: ""
Aug 16 13:12:04.660: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug 16 13:12:04.661: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-t7qlz'
Aug 16 13:12:04.721: INFO: stderr: ""
Aug 16 13:12:04.721: INFO: stdout: "update-demo-nautilus-68bxv update-demo-nautilus-vf5nd "
STEP: Replicas for name=update-demo: expected=1 actual=2
Aug 16 13:12:09.721: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-t7qlz'
Aug 16 13:12:09.787: INFO: stderr: ""
Aug 16 13:12:09.787: INFO: stdout: "update-demo-nautilus-68bxv update-demo-nautilus-vf5nd "
STEP: Replicas for name=update-demo: expected=1 actual=2
Aug 16 13:12:14.787: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-t7qlz'
Aug 16 13:12:14.855: INFO: stderr: ""
Aug 16 13:12:14.855: INFO: stdout: "update-demo-nautilus-vf5nd "
Aug 16 13:12:14.855: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 get pods update-demo-nautilus-vf5nd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-t7qlz'
Aug 16 13:12:14.911: INFO: stderr: ""
Aug 16 13:12:14.911: INFO: stdout: "true"
Aug 16 13:12:14.911: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 get pods update-demo-nautilus-vf5nd -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-t7qlz'
Aug 16 13:12:14.971: INFO: stderr: ""
Aug 16 13:12:14.971: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 16 13:12:14.971: INFO: validating pod update-demo-nautilus-vf5nd
Aug 16 13:12:14.975: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 16 13:12:14.975: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 16 13:12:14.975: INFO: update-demo-nautilus-vf5nd is verified up and running
STEP: scaling up the replication controller
Aug 16 13:12:14.976: INFO: scanned /root for discovery docs: <nil>
Aug 16 13:12:14.976: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-t7qlz'
Aug 16 13:12:16.064: INFO: stderr: ""
Aug 16 13:12:16.064: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug 16 13:12:16.064: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-t7qlz'
Aug 16 13:12:16.124: INFO: stderr: ""
Aug 16 13:12:16.124: INFO: stdout: "update-demo-nautilus-6l8l8 update-demo-nautilus-vf5nd "
Aug 16 13:12:16.124: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 get pods update-demo-nautilus-6l8l8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-t7qlz'
Aug 16 13:12:16.179: INFO: stderr: ""
Aug 16 13:12:16.180: INFO: stdout: ""
Aug 16 13:12:16.180: INFO: update-demo-nautilus-6l8l8 is created but not running
Aug 16 13:12:21.180: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-t7qlz'
Aug 16 13:12:21.239: INFO: stderr: ""
Aug 16 13:12:21.239: INFO: stdout: "update-demo-nautilus-6l8l8 update-demo-nautilus-vf5nd "
Aug 16 13:12:21.239: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 get pods update-demo-nautilus-6l8l8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-t7qlz'
Aug 16 13:12:21.321: INFO: stderr: ""
Aug 16 13:12:21.321: INFO: stdout: "true"
Aug 16 13:12:21.321: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 get pods update-demo-nautilus-6l8l8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-t7qlz'
Aug 16 13:12:21.398: INFO: stderr: ""
Aug 16 13:12:21.398: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 16 13:12:21.398: INFO: validating pod update-demo-nautilus-6l8l8
Aug 16 13:12:21.405: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 16 13:12:21.405: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 16 13:12:21.405: INFO: update-demo-nautilus-6l8l8 is verified up and running
Aug 16 13:12:21.405: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 get pods update-demo-nautilus-vf5nd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-t7qlz'
Aug 16 13:12:21.462: INFO: stderr: ""
Aug 16 13:12:21.462: INFO: stdout: "true"
Aug 16 13:12:21.462: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 get pods update-demo-nautilus-vf5nd -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-t7qlz'
Aug 16 13:12:21.518: INFO: stderr: ""
Aug 16 13:12:21.518: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 16 13:12:21.518: INFO: validating pod update-demo-nautilus-vf5nd
Aug 16 13:12:21.522: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 16 13:12:21.522: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 16 13:12:21.522: INFO: update-demo-nautilus-vf5nd is verified up and running
STEP: using delete to clean up resources
Aug 16 13:12:21.522: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-t7qlz'
Aug 16 13:12:21.586: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 16 13:12:21.586: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Aug 16 13:12:21.586: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-t7qlz'
Aug 16 13:12:21.710: INFO: stderr: "No resources found.\n"
Aug 16 13:12:21.710: INFO: stdout: ""
Aug 16 13:12:21.710: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 get pods -l name=update-demo --namespace=e2e-tests-kubectl-t7qlz -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug 16 13:12:21.822: INFO: stderr: ""
Aug 16 13:12:21.822: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:12:21.822: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-t7qlz" for this suite.
Aug 16 13:12:43.846: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:12:43.888: INFO: namespace: e2e-tests-kubectl-t7qlz, resource: bindings, ignored listing per whitelist
Aug 16 13:12:43.964: INFO: namespace e2e-tests-kubectl-t7qlz deletion completed in 22.138142466s

• [SLOW TEST:46.264 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:12:43.965: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1262
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug 16 13:12:44.012: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-ktfdl'
Aug 16 13:12:44.091: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Aug 16 13:12:44.091: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1268
Aug 16 13:12:46.102: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-ktfdl'
Aug 16 13:12:46.174: INFO: stderr: ""
Aug 16 13:12:46.174: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:12:46.174: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-ktfdl" for this suite.
Aug 16 13:13:08.195: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:13:08.231: INFO: namespace: e2e-tests-kubectl-ktfdl, resource: bindings, ignored listing per whitelist
Aug 16 13:13:08.310: INFO: namespace e2e-tests-kubectl-ktfdl deletion completed in 22.130548078s

• [SLOW TEST:24.345 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:13:08.310: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug 16 13:13:08.367: INFO: (0) /api/v1/nodes/worker-72b80c6a-c026-11e9-bfed-069795ba99e0/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a href="... (200; 3.620499ms)
Aug 16 13:13:08.371: INFO: (1) /api/v1/nodes/worker-72b80c6a-c026-11e9-bfed-069795ba99e0/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a href="... (200; 3.329669ms)
Aug 16 13:13:08.374: INFO: (2) /api/v1/nodes/worker-72b80c6a-c026-11e9-bfed-069795ba99e0/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a href="... (200; 3.339819ms)
Aug 16 13:13:08.377: INFO: (3) /api/v1/nodes/worker-72b80c6a-c026-11e9-bfed-069795ba99e0/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a href="... (200; 3.252041ms)
Aug 16 13:13:08.380: INFO: (4) /api/v1/nodes/worker-72b80c6a-c026-11e9-bfed-069795ba99e0/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a href="... (200; 3.292706ms)
Aug 16 13:13:08.384: INFO: (5) /api/v1/nodes/worker-72b80c6a-c026-11e9-bfed-069795ba99e0/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a href="... (200; 3.245516ms)
Aug 16 13:13:08.387: INFO: (6) /api/v1/nodes/worker-72b80c6a-c026-11e9-bfed-069795ba99e0/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a href="... (200; 3.206911ms)
Aug 16 13:13:08.390: INFO: (7) /api/v1/nodes/worker-72b80c6a-c026-11e9-bfed-069795ba99e0/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a href="... (200; 3.252111ms)
Aug 16 13:13:08.394: INFO: (8) /api/v1/nodes/worker-72b80c6a-c026-11e9-bfed-069795ba99e0/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a href="... (200; 3.269708ms)
Aug 16 13:13:08.397: INFO: (9) /api/v1/nodes/worker-72b80c6a-c026-11e9-bfed-069795ba99e0/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a href="... (200; 3.270157ms)
Aug 16 13:13:08.401: INFO: (10) /api/v1/nodes/worker-72b80c6a-c026-11e9-bfed-069795ba99e0/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a href="... (200; 4.146558ms)
Aug 16 13:13:08.405: INFO: (11) /api/v1/nodes/worker-72b80c6a-c026-11e9-bfed-069795ba99e0/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a href="... (200; 3.6186ms)
Aug 16 13:13:08.408: INFO: (12) /api/v1/nodes/worker-72b80c6a-c026-11e9-bfed-069795ba99e0/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a href="... (200; 3.47411ms)
Aug 16 13:13:08.411: INFO: (13) /api/v1/nodes/worker-72b80c6a-c026-11e9-bfed-069795ba99e0/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a href="... (200; 3.220919ms)
Aug 16 13:13:08.415: INFO: (14) /api/v1/nodes/worker-72b80c6a-c026-11e9-bfed-069795ba99e0/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a href="... (200; 3.237835ms)
Aug 16 13:13:08.418: INFO: (15) /api/v1/nodes/worker-72b80c6a-c026-11e9-bfed-069795ba99e0/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a href="... (200; 3.23819ms)
Aug 16 13:13:08.421: INFO: (16) /api/v1/nodes/worker-72b80c6a-c026-11e9-bfed-069795ba99e0/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a href="... (200; 3.285199ms)
Aug 16 13:13:08.425: INFO: (17) /api/v1/nodes/worker-72b80c6a-c026-11e9-bfed-069795ba99e0/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a href="... (200; 3.669371ms)
Aug 16 13:13:08.428: INFO: (18) /api/v1/nodes/worker-72b80c6a-c026-11e9-bfed-069795ba99e0/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a href="... (200; 3.283895ms)
Aug 16 13:13:08.431: INFO: (19) /api/v1/nodes/worker-72b80c6a-c026-11e9-bfed-069795ba99e0/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a href="... (200; 3.238416ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:13:08.432: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-wb9lr" for this suite.
Aug 16 13:13:14.448: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:13:14.483: INFO: namespace: e2e-tests-proxy-wb9lr, resource: bindings, ignored listing per whitelist
Aug 16 13:13:14.557: INFO: namespace e2e-tests-proxy-wb9lr deletion completed in 6.122349957s

• [SLOW TEST:6.248 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:13:14.558: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug 16 13:13:14.615: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9adedf03-c027-11e9-99f6-8a077000b195" in namespace "e2e-tests-projected-85glm" to be "success or failure"
Aug 16 13:13:14.618: INFO: Pod "downwardapi-volume-9adedf03-c027-11e9-99f6-8a077000b195": Phase="Pending", Reason="", readiness=false. Elapsed: 3.303131ms
Aug 16 13:13:16.628: INFO: Pod "downwardapi-volume-9adedf03-c027-11e9-99f6-8a077000b195": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013600833s
STEP: Saw pod success
Aug 16 13:13:16.628: INFO: Pod "downwardapi-volume-9adedf03-c027-11e9-99f6-8a077000b195" satisfied condition "success or failure"
Aug 16 13:13:16.631: INFO: Trying to get logs from node worker-eab92000-c026-11e9-bfed-069795ba99e0 pod downwardapi-volume-9adedf03-c027-11e9-99f6-8a077000b195 container client-container: <nil>
STEP: delete the pod
Aug 16 13:13:16.658: INFO: Waiting for pod downwardapi-volume-9adedf03-c027-11e9-99f6-8a077000b195 to disappear
Aug 16 13:13:16.663: INFO: Pod downwardapi-volume-9adedf03-c027-11e9-99f6-8a077000b195 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:13:16.663: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-85glm" for this suite.
Aug 16 13:13:22.682: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:13:22.707: INFO: namespace: e2e-tests-projected-85glm, resource: bindings, ignored listing per whitelist
Aug 16 13:13:22.798: INFO: namespace e2e-tests-projected-85glm deletion completed in 6.1304649s

• [SLOW TEST:8.240 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:13:22.798: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-9fc887a8-c027-11e9-99f6-8a077000b195
STEP: Creating a pod to test consume configMaps
Aug 16 13:13:22.864: INFO: Waiting up to 5m0s for pod "pod-configmaps-9fc95697-c027-11e9-99f6-8a077000b195" in namespace "e2e-tests-configmap-mqj9c" to be "success or failure"
Aug 16 13:13:22.870: INFO: Pod "pod-configmaps-9fc95697-c027-11e9-99f6-8a077000b195": Phase="Pending", Reason="", readiness=false. Elapsed: 6.165982ms
Aug 16 13:13:24.874: INFO: Pod "pod-configmaps-9fc95697-c027-11e9-99f6-8a077000b195": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009927131s
STEP: Saw pod success
Aug 16 13:13:24.874: INFO: Pod "pod-configmaps-9fc95697-c027-11e9-99f6-8a077000b195" satisfied condition "success or failure"
Aug 16 13:13:24.877: INFO: Trying to get logs from node worker-eab92000-c026-11e9-bfed-069795ba99e0 pod pod-configmaps-9fc95697-c027-11e9-99f6-8a077000b195 container configmap-volume-test: <nil>
STEP: delete the pod
Aug 16 13:13:24.907: INFO: Waiting for pod pod-configmaps-9fc95697-c027-11e9-99f6-8a077000b195 to disappear
Aug 16 13:13:24.918: INFO: Pod pod-configmaps-9fc95697-c027-11e9-99f6-8a077000b195 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:13:24.918: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-mqj9c" for this suite.
Aug 16 13:13:30.935: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:13:31.024: INFO: namespace: e2e-tests-configmap-mqj9c, resource: bindings, ignored listing per whitelist
Aug 16 13:13:31.046: INFO: namespace e2e-tests-configmap-mqj9c deletion completed in 6.12404141s

• [SLOW TEST:8.248 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:13:31.046: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-7frg8.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-7frg8.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-7frg8.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-7frg8.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-7frg8.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-7frg8.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug 16 13:13:41.207: INFO: DNS probes using e2e-tests-dns-7frg8/dns-test-a4b5040b-c027-11e9-99f6-8a077000b195 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:13:41.226: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-7frg8" for this suite.
Aug 16 13:13:47.254: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:13:47.283: INFO: namespace: e2e-tests-dns-7frg8, resource: bindings, ignored listing per whitelist
Aug 16 13:13:47.366: INFO: namespace e2e-tests-dns-7frg8 deletion completed in 6.131410755s

• [SLOW TEST:16.319 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:13:47.366: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Aug 16 13:13:47.425: INFO: Waiting up to 5m0s for pod "downward-api-ae6d2a10-c027-11e9-99f6-8a077000b195" in namespace "e2e-tests-downward-api-nvv2b" to be "success or failure"
Aug 16 13:13:47.428: INFO: Pod "downward-api-ae6d2a10-c027-11e9-99f6-8a077000b195": Phase="Pending", Reason="", readiness=false. Elapsed: 3.24582ms
Aug 16 13:13:49.432: INFO: Pod "downward-api-ae6d2a10-c027-11e9-99f6-8a077000b195": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007131259s
Aug 16 13:13:51.435: INFO: Pod "downward-api-ae6d2a10-c027-11e9-99f6-8a077000b195": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010591357s
STEP: Saw pod success
Aug 16 13:13:51.435: INFO: Pod "downward-api-ae6d2a10-c027-11e9-99f6-8a077000b195" satisfied condition "success or failure"
Aug 16 13:13:51.438: INFO: Trying to get logs from node worker-eab92000-c026-11e9-bfed-069795ba99e0 pod downward-api-ae6d2a10-c027-11e9-99f6-8a077000b195 container dapi-container: <nil>
STEP: delete the pod
Aug 16 13:13:51.462: INFO: Waiting for pod downward-api-ae6d2a10-c027-11e9-99f6-8a077000b195 to disappear
Aug 16 13:13:51.466: INFO: Pod downward-api-ae6d2a10-c027-11e9-99f6-8a077000b195 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:13:51.466: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-nvv2b" for this suite.
Aug 16 13:13:57.491: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:13:57.533: INFO: namespace: e2e-tests-downward-api-nvv2b, resource: bindings, ignored listing per whitelist
Aug 16 13:13:57.605: INFO: namespace e2e-tests-downward-api-nvv2b deletion completed in 6.134803259s

• [SLOW TEST:10.239 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:13:57.605: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug 16 13:13:57.671: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Aug 16 13:13:57.681: INFO: Number of nodes with available pods: 0
Aug 16 13:13:57.681: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Aug 16 13:13:57.703: INFO: Number of nodes with available pods: 0
Aug 16 13:13:57.703: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:13:58.707: INFO: Number of nodes with available pods: 0
Aug 16 13:13:58.707: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:13:59.707: INFO: Number of nodes with available pods: 0
Aug 16 13:13:59.707: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:14:00.707: INFO: Number of nodes with available pods: 1
Aug 16 13:14:00.707: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Aug 16 13:14:00.729: INFO: Number of nodes with available pods: 1
Aug 16 13:14:00.729: INFO: Number of running nodes: 0, number of available pods: 1
Aug 16 13:14:01.733: INFO: Number of nodes with available pods: 0
Aug 16 13:14:01.733: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Aug 16 13:14:01.744: INFO: Number of nodes with available pods: 0
Aug 16 13:14:01.744: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:14:02.748: INFO: Number of nodes with available pods: 0
Aug 16 13:14:02.748: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:14:03.748: INFO: Number of nodes with available pods: 0
Aug 16 13:14:03.748: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:14:04.748: INFO: Number of nodes with available pods: 0
Aug 16 13:14:04.748: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:14:05.748: INFO: Number of nodes with available pods: 0
Aug 16 13:14:05.748: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:14:06.748: INFO: Number of nodes with available pods: 0
Aug 16 13:14:06.748: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:14:07.754: INFO: Number of nodes with available pods: 0
Aug 16 13:14:07.754: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:14:08.748: INFO: Number of nodes with available pods: 0
Aug 16 13:14:08.748: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:14:09.748: INFO: Number of nodes with available pods: 0
Aug 16 13:14:09.748: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:14:10.748: INFO: Number of nodes with available pods: 0
Aug 16 13:14:10.748: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:14:11.748: INFO: Number of nodes with available pods: 0
Aug 16 13:14:11.748: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:14:12.748: INFO: Number of nodes with available pods: 0
Aug 16 13:14:12.748: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:14:13.748: INFO: Number of nodes with available pods: 0
Aug 16 13:14:13.748: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:14:14.748: INFO: Number of nodes with available pods: 0
Aug 16 13:14:14.748: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:14:15.748: INFO: Number of nodes with available pods: 0
Aug 16 13:14:15.748: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:14:16.748: INFO: Number of nodes with available pods: 0
Aug 16 13:14:16.748: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:14:17.748: INFO: Number of nodes with available pods: 0
Aug 16 13:14:17.748: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:14:18.754: INFO: Number of nodes with available pods: 0
Aug 16 13:14:18.754: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:14:19.748: INFO: Number of nodes with available pods: 0
Aug 16 13:14:19.748: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:14:20.748: INFO: Number of nodes with available pods: 0
Aug 16 13:14:20.748: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:14:21.748: INFO: Number of nodes with available pods: 0
Aug 16 13:14:21.748: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:14:22.748: INFO: Number of nodes with available pods: 0
Aug 16 13:14:22.748: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:14:23.748: INFO: Number of nodes with available pods: 0
Aug 16 13:14:23.748: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:14:24.748: INFO: Number of nodes with available pods: 0
Aug 16 13:14:24.748: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:14:25.748: INFO: Number of nodes with available pods: 0
Aug 16 13:14:25.748: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:14:26.748: INFO: Number of nodes with available pods: 0
Aug 16 13:14:26.748: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:14:27.748: INFO: Number of nodes with available pods: 0
Aug 16 13:14:27.748: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:14:28.748: INFO: Number of nodes with available pods: 0
Aug 16 13:14:28.748: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:14:29.754: INFO: Number of nodes with available pods: 0
Aug 16 13:14:29.754: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:14:30.748: INFO: Number of nodes with available pods: 0
Aug 16 13:14:30.748: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:14:31.748: INFO: Number of nodes with available pods: 0
Aug 16 13:14:31.748: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:14:32.748: INFO: Number of nodes with available pods: 0
Aug 16 13:14:32.748: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:14:33.748: INFO: Number of nodes with available pods: 0
Aug 16 13:14:33.748: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:14:34.748: INFO: Number of nodes with available pods: 0
Aug 16 13:14:34.748: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:14:35.748: INFO: Number of nodes with available pods: 0
Aug 16 13:14:35.748: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:14:36.748: INFO: Number of nodes with available pods: 0
Aug 16 13:14:36.748: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:14:37.748: INFO: Number of nodes with available pods: 0
Aug 16 13:14:37.748: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:14:38.748: INFO: Number of nodes with available pods: 0
Aug 16 13:14:38.748: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:14:39.748: INFO: Number of nodes with available pods: 0
Aug 16 13:14:39.748: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:14:40.754: INFO: Number of nodes with available pods: 0
Aug 16 13:14:40.754: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:14:41.748: INFO: Number of nodes with available pods: 0
Aug 16 13:14:41.748: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:14:42.748: INFO: Number of nodes with available pods: 1
Aug 16 13:14:42.748: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-t6mrj, will wait for the garbage collector to delete the pods
Aug 16 13:14:42.817: INFO: Deleting DaemonSet.extensions daemon-set took: 10.467616ms
Aug 16 13:14:42.917: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.130625ms
Aug 16 13:15:21.327: INFO: Number of nodes with available pods: 0
Aug 16 13:15:21.327: INFO: Number of running nodes: 0, number of available pods: 0
Aug 16 13:15:21.331: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-t6mrj/daemonsets","resourceVersion":"16938"},"items":null}

Aug 16 13:15:21.334: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-t6mrj/pods","resourceVersion":"16938"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:15:21.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-t6mrj" for this suite.
Aug 16 13:15:27.378: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:15:27.487: INFO: namespace: e2e-tests-daemonsets-t6mrj, resource: bindings, ignored listing per whitelist
Aug 16 13:15:27.496: INFO: namespace e2e-tests-daemonsets-t6mrj deletion completed in 6.132753184s

• [SLOW TEST:89.891 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:15:27.496: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1358
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug 16 13:15:27.543: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-mkrbf'
Aug 16 13:15:27.609: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Aug 16 13:15:27.609: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Aug 16 13:15:27.616: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Aug 16 13:15:27.623: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Aug 16 13:15:27.637: INFO: scanned /root for discovery docs: <nil>
Aug 16 13:15:27.637: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-mkrbf'
Aug 16 13:15:43.417: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Aug 16 13:15:43.417: INFO: stdout: "Created e2e-test-nginx-rc-c3d06b26f3a4b316956cb89e970ad767\nScaling up e2e-test-nginx-rc-c3d06b26f3a4b316956cb89e970ad767 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-c3d06b26f3a4b316956cb89e970ad767 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-c3d06b26f3a4b316956cb89e970ad767 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Aug 16 13:15:43.417: INFO: stdout: "Created e2e-test-nginx-rc-c3d06b26f3a4b316956cb89e970ad767\nScaling up e2e-test-nginx-rc-c3d06b26f3a4b316956cb89e970ad767 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-c3d06b26f3a4b316956cb89e970ad767 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-c3d06b26f3a4b316956cb89e970ad767 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Aug 16 13:15:43.417: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-mkrbf'
Aug 16 13:15:43.486: INFO: stderr: ""
Aug 16 13:15:43.486: INFO: stdout: "e2e-test-nginx-rc-c3d06b26f3a4b316956cb89e970ad767-pk9n4 "
Aug 16 13:15:43.486: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 get pods e2e-test-nginx-rc-c3d06b26f3a4b316956cb89e970ad767-pk9n4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-mkrbf'
Aug 16 13:15:43.547: INFO: stderr: ""
Aug 16 13:15:43.547: INFO: stdout: "true"
Aug 16 13:15:43.547: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 get pods e2e-test-nginx-rc-c3d06b26f3a4b316956cb89e970ad767-pk9n4 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-mkrbf'
Aug 16 13:15:43.601: INFO: stderr: ""
Aug 16 13:15:43.601: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Aug 16 13:15:43.601: INFO: e2e-test-nginx-rc-c3d06b26f3a4b316956cb89e970ad767-pk9n4 is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1364
Aug 16 13:15:43.601: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-mkrbf'
Aug 16 13:15:43.667: INFO: stderr: ""
Aug 16 13:15:43.667: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:15:43.667: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-mkrbf" for this suite.
Aug 16 13:16:05.702: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:16:05.812: INFO: namespace: e2e-tests-kubectl-mkrbf, resource: bindings, ignored listing per whitelist
Aug 16 13:16:05.818: INFO: namespace e2e-tests-kubectl-mkrbf deletion completed in 22.145351013s

• [SLOW TEST:38.322 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:16:05.818: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
Aug 16 13:16:07.887: INFO: Pod pod-hostip-00f2f955-c028-11e9-99f6-8a077000b195 has hostIP: 10.1.161.42
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:16:07.887: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-7m848" for this suite.
Aug 16 13:16:29.904: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:16:29.985: INFO: namespace: e2e-tests-pods-7m848, resource: bindings, ignored listing per whitelist
Aug 16 13:16:30.021: INFO: namespace e2e-tests-pods-7m848 deletion completed in 22.129826042s

• [SLOW TEST:24.203 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:16:30.021: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug 16 13:16:30.134: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0f68648c-c028-11e9-99f6-8a077000b195" in namespace "e2e-tests-downward-api-jz5mq" to be "success or failure"
Aug 16 13:16:30.142: INFO: Pod "downwardapi-volume-0f68648c-c028-11e9-99f6-8a077000b195": Phase="Pending", Reason="", readiness=false. Elapsed: 8.022354ms
Aug 16 13:16:32.146: INFO: Pod "downwardapi-volume-0f68648c-c028-11e9-99f6-8a077000b195": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011776758s
STEP: Saw pod success
Aug 16 13:16:32.146: INFO: Pod "downwardapi-volume-0f68648c-c028-11e9-99f6-8a077000b195" satisfied condition "success or failure"
Aug 16 13:16:32.149: INFO: Trying to get logs from node worker-eab92000-c026-11e9-bfed-069795ba99e0 pod downwardapi-volume-0f68648c-c028-11e9-99f6-8a077000b195 container client-container: <nil>
STEP: delete the pod
Aug 16 13:16:32.174: INFO: Waiting for pod downwardapi-volume-0f68648c-c028-11e9-99f6-8a077000b195 to disappear
Aug 16 13:16:32.181: INFO: Pod downwardapi-volume-0f68648c-c028-11e9-99f6-8a077000b195 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:16:32.181: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-jz5mq" for this suite.
Aug 16 13:16:38.205: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:16:38.225: INFO: namespace: e2e-tests-downward-api-jz5mq, resource: bindings, ignored listing per whitelist
Aug 16 13:16:38.319: INFO: namespace e2e-tests-downward-api-jz5mq deletion completed in 6.13352865s

• [SLOW TEST:8.298 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:16:38.319: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-145456a7-c028-11e9-99f6-8a077000b195
STEP: Creating configMap with name cm-test-opt-upd-145456df-c028-11e9-99f6-8a077000b195
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-145456a7-c028-11e9-99f6-8a077000b195
STEP: Updating configmap cm-test-opt-upd-145456df-c028-11e9-99f6-8a077000b195
STEP: Creating configMap with name cm-test-opt-create-145456ef-c028-11e9-99f6-8a077000b195
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:16:42.492: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-qb4zh" for this suite.
Aug 16 13:17:04.509: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:17:04.531: INFO: namespace: e2e-tests-projected-qb4zh, resource: bindings, ignored listing per whitelist
Aug 16 13:17:04.622: INFO: namespace e2e-tests-projected-qb4zh deletion completed in 22.125978296s

• [SLOW TEST:26.303 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:17:04.622: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-m45fb
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-m45fb to expose endpoints map[]
Aug 16 13:17:04.690: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-m45fb exposes endpoints map[] (10.173598ms elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-m45fb
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-m45fb to expose endpoints map[pod1:[80]]
Aug 16 13:17:06.729: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-m45fb exposes endpoints map[pod1:[80]] (2.024232667s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-m45fb
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-m45fb to expose endpoints map[pod2:[80] pod1:[80]]
Aug 16 13:17:08.768: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-m45fb exposes endpoints map[pod1:[80] pod2:[80]] (2.031981128s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-m45fb
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-m45fb to expose endpoints map[pod2:[80]]
Aug 16 13:17:08.789: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-m45fb exposes endpoints map[pod2:[80]] (15.342601ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-m45fb
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-m45fb to expose endpoints map[]
Aug 16 13:17:08.811: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-m45fb exposes endpoints map[] (6.337016ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:17:08.840: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-m45fb" for this suite.
Aug 16 13:17:30.859: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:17:30.896: INFO: namespace: e2e-tests-services-m45fb, resource: bindings, ignored listing per whitelist
Aug 16 13:17:30.970: INFO: namespace e2e-tests-services-m45fb deletion completed in 22.125520573s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:26.348 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:17:30.970: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Aug 16 13:17:31.536: INFO: Waiting up to 5m0s for pod "pod-service-account-34021436-c028-11e9-99f6-8a077000b195-2pgn8" in namespace "e2e-tests-svcaccounts-q5tjr" to be "success or failure"
Aug 16 13:17:31.540: INFO: Pod "pod-service-account-34021436-c028-11e9-99f6-8a077000b195-2pgn8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.176739ms
Aug 16 13:17:33.550: INFO: Pod "pod-service-account-34021436-c028-11e9-99f6-8a077000b195-2pgn8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014234683s
STEP: Saw pod success
Aug 16 13:17:33.550: INFO: Pod "pod-service-account-34021436-c028-11e9-99f6-8a077000b195-2pgn8" satisfied condition "success or failure"
Aug 16 13:17:33.553: INFO: Trying to get logs from node worker-eab92000-c026-11e9-bfed-069795ba99e0 pod pod-service-account-34021436-c028-11e9-99f6-8a077000b195-2pgn8 container token-test: <nil>
STEP: delete the pod
Aug 16 13:17:33.586: INFO: Waiting for pod pod-service-account-34021436-c028-11e9-99f6-8a077000b195-2pgn8 to disappear
Aug 16 13:17:33.589: INFO: Pod pod-service-account-34021436-c028-11e9-99f6-8a077000b195-2pgn8 no longer exists
STEP: Creating a pod to test consume service account root CA
Aug 16 13:17:33.600: INFO: Waiting up to 5m0s for pod "pod-service-account-34021436-c028-11e9-99f6-8a077000b195-nl69v" in namespace "e2e-tests-svcaccounts-q5tjr" to be "success or failure"
Aug 16 13:17:33.608: INFO: Pod "pod-service-account-34021436-c028-11e9-99f6-8a077000b195-nl69v": Phase="Pending", Reason="", readiness=false. Elapsed: 7.584333ms
Aug 16 13:17:35.612: INFO: Pod "pod-service-account-34021436-c028-11e9-99f6-8a077000b195-nl69v": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011389052s
STEP: Saw pod success
Aug 16 13:17:35.612: INFO: Pod "pod-service-account-34021436-c028-11e9-99f6-8a077000b195-nl69v" satisfied condition "success or failure"
Aug 16 13:17:35.615: INFO: Trying to get logs from node worker-eab92000-c026-11e9-bfed-069795ba99e0 pod pod-service-account-34021436-c028-11e9-99f6-8a077000b195-nl69v container root-ca-test: <nil>
STEP: delete the pod
Aug 16 13:17:35.647: INFO: Waiting for pod pod-service-account-34021436-c028-11e9-99f6-8a077000b195-nl69v to disappear
Aug 16 13:17:35.651: INFO: Pod pod-service-account-34021436-c028-11e9-99f6-8a077000b195-nl69v no longer exists
STEP: Creating a pod to test consume service account namespace
Aug 16 13:17:35.656: INFO: Waiting up to 5m0s for pod "pod-service-account-34021436-c028-11e9-99f6-8a077000b195-wwgtr" in namespace "e2e-tests-svcaccounts-q5tjr" to be "success or failure"
Aug 16 13:17:35.660: INFO: Pod "pod-service-account-34021436-c028-11e9-99f6-8a077000b195-wwgtr": Phase="Pending", Reason="", readiness=false. Elapsed: 4.178546ms
Aug 16 13:17:37.664: INFO: Pod "pod-service-account-34021436-c028-11e9-99f6-8a077000b195-wwgtr": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007884206s
STEP: Saw pod success
Aug 16 13:17:37.664: INFO: Pod "pod-service-account-34021436-c028-11e9-99f6-8a077000b195-wwgtr" satisfied condition "success or failure"
Aug 16 13:17:37.667: INFO: Trying to get logs from node worker-eab92000-c026-11e9-bfed-069795ba99e0 pod pod-service-account-34021436-c028-11e9-99f6-8a077000b195-wwgtr container namespace-test: <nil>
STEP: delete the pod
Aug 16 13:17:37.698: INFO: Waiting for pod pod-service-account-34021436-c028-11e9-99f6-8a077000b195-wwgtr to disappear
Aug 16 13:17:37.702: INFO: Pod pod-service-account-34021436-c028-11e9-99f6-8a077000b195-wwgtr no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:17:37.702: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-q5tjr" for this suite.
Aug 16 13:17:43.726: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:17:43.835: INFO: namespace: e2e-tests-svcaccounts-q5tjr, resource: bindings, ignored listing per whitelist
Aug 16 13:17:43.838: INFO: namespace e2e-tests-svcaccounts-q5tjr deletion completed in 6.131590183s

• [SLOW TEST:12.868 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:17:43.838: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-3b604a92-c028-11e9-99f6-8a077000b195
STEP: Creating a pod to test consume configMaps
Aug 16 13:17:43.906: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-3b611100-c028-11e9-99f6-8a077000b195" in namespace "e2e-tests-projected-6g6d7" to be "success or failure"
Aug 16 13:17:43.912: INFO: Pod "pod-projected-configmaps-3b611100-c028-11e9-99f6-8a077000b195": Phase="Pending", Reason="", readiness=false. Elapsed: 5.347075ms
Aug 16 13:17:45.916: INFO: Pod "pod-projected-configmaps-3b611100-c028-11e9-99f6-8a077000b195": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009105899s
STEP: Saw pod success
Aug 16 13:17:45.916: INFO: Pod "pod-projected-configmaps-3b611100-c028-11e9-99f6-8a077000b195" satisfied condition "success or failure"
Aug 16 13:17:45.918: INFO: Trying to get logs from node worker-eab92000-c026-11e9-bfed-069795ba99e0 pod pod-projected-configmaps-3b611100-c028-11e9-99f6-8a077000b195 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 16 13:17:45.943: INFO: Waiting for pod pod-projected-configmaps-3b611100-c028-11e9-99f6-8a077000b195 to disappear
Aug 16 13:17:45.947: INFO: Pod pod-projected-configmaps-3b611100-c028-11e9-99f6-8a077000b195 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:17:45.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-6g6d7" for this suite.
Aug 16 13:17:51.965: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:17:52.026: INFO: namespace: e2e-tests-projected-6g6d7, resource: bindings, ignored listing per whitelist
Aug 16 13:17:52.085: INFO: namespace e2e-tests-projected-6g6d7 deletion completed in 6.133534403s

• [SLOW TEST:8.247 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:17:52.085: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Aug 16 13:17:52.166: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:17:52.166: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:17:52.166: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:17:52.170: INFO: Number of nodes with available pods: 0
Aug 16 13:17:52.170: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:17:53.174: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:17:53.174: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:17:53.174: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:17:53.177: INFO: Number of nodes with available pods: 0
Aug 16 13:17:53.177: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:17:54.181: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:17:54.181: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:17:54.181: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:17:54.184: INFO: Number of nodes with available pods: 1
Aug 16 13:17:54.184: INFO: Node worker-eab92000-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:17:55.175: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:17:55.175: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:17:55.175: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:17:55.178: INFO: Number of nodes with available pods: 2
Aug 16 13:17:55.178: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Stop a daemon pod, check that the daemon pod is revived.
Aug 16 13:17:55.202: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:17:55.202: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:17:55.202: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:17:55.205: INFO: Number of nodes with available pods: 1
Aug 16 13:17:55.205: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:17:56.210: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:17:56.210: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:17:56.210: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:17:56.213: INFO: Number of nodes with available pods: 1
Aug 16 13:17:56.213: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:17:57.210: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:17:57.210: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:17:57.210: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:17:57.213: INFO: Number of nodes with available pods: 1
Aug 16 13:17:57.213: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:17:58.210: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:17:58.210: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:17:58.210: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:17:58.213: INFO: Number of nodes with available pods: 1
Aug 16 13:17:58.213: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:17:59.210: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:17:59.210: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:17:59.210: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:17:59.214: INFO: Number of nodes with available pods: 1
Aug 16 13:17:59.214: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:18:00.210: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:00.210: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:00.210: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:00.214: INFO: Number of nodes with available pods: 1
Aug 16 13:18:00.214: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:18:01.210: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:01.210: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:01.210: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:01.214: INFO: Number of nodes with available pods: 1
Aug 16 13:18:01.214: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:18:02.210: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:02.210: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:02.210: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:02.214: INFO: Number of nodes with available pods: 1
Aug 16 13:18:02.214: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:18:03.210: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:03.210: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:03.210: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:03.213: INFO: Number of nodes with available pods: 1
Aug 16 13:18:03.213: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:18:04.217: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:04.217: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:04.217: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:04.220: INFO: Number of nodes with available pods: 1
Aug 16 13:18:04.220: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:18:05.210: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:05.210: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:05.210: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:05.213: INFO: Number of nodes with available pods: 1
Aug 16 13:18:05.213: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:18:06.210: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:06.210: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:06.210: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:06.214: INFO: Number of nodes with available pods: 1
Aug 16 13:18:06.214: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:18:07.210: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:07.210: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:07.210: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:07.213: INFO: Number of nodes with available pods: 1
Aug 16 13:18:07.213: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:18:08.210: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:08.210: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:08.210: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:08.213: INFO: Number of nodes with available pods: 1
Aug 16 13:18:08.213: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:18:09.210: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:09.210: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:09.210: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:09.214: INFO: Number of nodes with available pods: 1
Aug 16 13:18:09.214: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:18:10.210: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:10.210: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:10.210: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:10.213: INFO: Number of nodes with available pods: 1
Aug 16 13:18:10.213: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:18:11.210: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:11.210: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:11.210: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:11.213: INFO: Number of nodes with available pods: 1
Aug 16 13:18:11.214: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:18:12.210: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:12.210: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:12.210: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:12.214: INFO: Number of nodes with available pods: 1
Aug 16 13:18:12.214: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:18:13.210: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:13.210: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:13.210: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:13.213: INFO: Number of nodes with available pods: 1
Aug 16 13:18:13.213: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:18:14.210: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:14.210: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:14.210: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:14.213: INFO: Number of nodes with available pods: 1
Aug 16 13:18:14.213: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:18:15.217: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:15.217: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:15.217: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:15.220: INFO: Number of nodes with available pods: 1
Aug 16 13:18:15.220: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:18:16.210: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:16.210: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:16.210: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:16.213: INFO: Number of nodes with available pods: 1
Aug 16 13:18:16.213: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:18:17.210: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:17.210: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:17.210: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:17.214: INFO: Number of nodes with available pods: 1
Aug 16 13:18:17.214: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:18:18.210: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:18.210: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:18.210: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:18.214: INFO: Number of nodes with available pods: 1
Aug 16 13:18:18.214: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:18:19.210: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:19.210: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:19.210: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:19.214: INFO: Number of nodes with available pods: 1
Aug 16 13:18:19.214: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:18:20.210: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:20.210: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:20.210: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:20.213: INFO: Number of nodes with available pods: 1
Aug 16 13:18:20.213: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:18:21.210: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:21.210: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:21.210: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:21.214: INFO: Number of nodes with available pods: 1
Aug 16 13:18:21.214: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:18:22.211: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:22.211: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:22.211: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:22.215: INFO: Number of nodes with available pods: 1
Aug 16 13:18:22.215: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:18:23.210: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:23.210: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:23.210: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:23.213: INFO: Number of nodes with available pods: 1
Aug 16 13:18:23.213: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:18:24.210: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:24.210: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:24.210: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:24.213: INFO: Number of nodes with available pods: 1
Aug 16 13:18:24.213: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:18:25.210: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:25.210: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:25.210: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:25.214: INFO: Number of nodes with available pods: 1
Aug 16 13:18:25.214: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:18:26.216: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:26.216: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:26.216: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:26.219: INFO: Number of nodes with available pods: 1
Aug 16 13:18:26.219: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:18:27.210: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:27.210: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:27.210: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:27.213: INFO: Number of nodes with available pods: 1
Aug 16 13:18:27.213: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:18:28.210: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:28.210: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:28.210: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:28.213: INFO: Number of nodes with available pods: 1
Aug 16 13:18:28.213: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:18:29.210: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:29.210: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:29.210: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:29.213: INFO: Number of nodes with available pods: 1
Aug 16 13:18:29.213: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:18:30.210: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:30.210: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:30.210: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:30.214: INFO: Number of nodes with available pods: 1
Aug 16 13:18:30.214: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:18:31.210: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:31.210: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:31.210: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:31.213: INFO: Number of nodes with available pods: 1
Aug 16 13:18:31.213: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:18:32.210: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:32.210: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:32.210: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:32.213: INFO: Number of nodes with available pods: 1
Aug 16 13:18:32.213: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:18:33.210: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:33.210: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:33.210: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:18:33.213: INFO: Number of nodes with available pods: 2
Aug 16 13:18:33.213: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-ccqh2, will wait for the garbage collector to delete the pods
Aug 16 13:18:33.279: INFO: Deleting DaemonSet.extensions daemon-set took: 9.930873ms
Aug 16 13:18:33.379: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.130437ms
Aug 16 13:19:11.389: INFO: Number of nodes with available pods: 0
Aug 16 13:19:11.389: INFO: Number of running nodes: 0, number of available pods: 0
Aug 16 13:19:11.392: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-ccqh2/daemonsets","resourceVersion":"18158"},"items":null}

Aug 16 13:19:11.395: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-ccqh2/pods","resourceVersion":"18158"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:19:11.413: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-ccqh2" for this suite.
Aug 16 13:19:17.435: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:19:17.521: INFO: namespace: e2e-tests-daemonsets-ccqh2, resource: bindings, ignored listing per whitelist
Aug 16 13:19:17.551: INFO: namespace e2e-tests-daemonsets-ccqh2 deletion completed in 6.131917778s

• [SLOW TEST:85.466 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:19:17.551: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug 16 13:19:17.597: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:19:19.698: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-kwdxx" for this suite.
Aug 16 13:20:05.722: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:20:05.770: INFO: namespace: e2e-tests-pods-kwdxx, resource: bindings, ignored listing per whitelist
Aug 16 13:20:05.834: INFO: namespace e2e-tests-pods-kwdxx deletion completed in 46.131751345s

• [SLOW TEST:48.283 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:20:05.834: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug 16 13:20:05.907: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Aug 16 13:20:05.917: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:05.918: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:05.918: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:05.923: INFO: Number of nodes with available pods: 0
Aug 16 13:20:05.923: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:20:06.928: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:06.928: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:06.928: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:06.933: INFO: Number of nodes with available pods: 0
Aug 16 13:20:06.933: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:20:07.935: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:07.935: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:07.936: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:07.939: INFO: Number of nodes with available pods: 2
Aug 16 13:20:07.939: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Aug 16 13:20:07.962: INFO: Wrong image for pod: daemon-set-6qhdg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:07.962: INFO: Wrong image for pod: daemon-set-6stx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:07.967: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:07.968: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:07.968: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:08.973: INFO: Wrong image for pod: daemon-set-6qhdg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:08.973: INFO: Wrong image for pod: daemon-set-6stx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:08.978: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:08.978: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:08.978: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:09.972: INFO: Wrong image for pod: daemon-set-6qhdg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:09.972: INFO: Wrong image for pod: daemon-set-6stx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:09.976: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:09.976: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:09.976: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:10.972: INFO: Wrong image for pod: daemon-set-6qhdg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:10.972: INFO: Wrong image for pod: daemon-set-6stx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:10.976: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:10.976: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:10.976: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:11.972: INFO: Wrong image for pod: daemon-set-6qhdg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:11.972: INFO: Wrong image for pod: daemon-set-6stx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:11.976: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:11.976: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:11.976: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:12.972: INFO: Wrong image for pod: daemon-set-6qhdg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:12.972: INFO: Wrong image for pod: daemon-set-6stx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:12.976: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:12.976: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:12.976: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:13.972: INFO: Wrong image for pod: daemon-set-6qhdg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:13.972: INFO: Wrong image for pod: daemon-set-6stx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:13.976: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:13.976: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:13.976: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:14.972: INFO: Wrong image for pod: daemon-set-6qhdg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:14.972: INFO: Wrong image for pod: daemon-set-6stx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:14.976: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:14.976: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:14.976: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:15.972: INFO: Wrong image for pod: daemon-set-6qhdg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:15.972: INFO: Wrong image for pod: daemon-set-6stx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:15.976: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:15.976: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:15.976: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:16.972: INFO: Wrong image for pod: daemon-set-6qhdg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:16.972: INFO: Wrong image for pod: daemon-set-6stx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:16.976: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:16.976: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:16.976: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:17.978: INFO: Wrong image for pod: daemon-set-6qhdg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:17.978: INFO: Wrong image for pod: daemon-set-6stx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:17.983: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:17.983: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:17.983: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:18.972: INFO: Wrong image for pod: daemon-set-6qhdg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:18.972: INFO: Wrong image for pod: daemon-set-6stx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:18.976: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:18.976: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:18.976: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:19.972: INFO: Wrong image for pod: daemon-set-6qhdg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:19.972: INFO: Wrong image for pod: daemon-set-6stx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:19.976: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:19.976: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:19.976: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:20.972: INFO: Wrong image for pod: daemon-set-6qhdg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:20.972: INFO: Wrong image for pod: daemon-set-6stx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:20.976: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:20.976: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:20.976: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:21.974: INFO: Wrong image for pod: daemon-set-6qhdg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:21.974: INFO: Wrong image for pod: daemon-set-6stx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:21.983: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:21.983: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:21.983: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:22.972: INFO: Wrong image for pod: daemon-set-6qhdg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:22.972: INFO: Wrong image for pod: daemon-set-6stx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:22.977: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:22.977: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:22.977: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:23.972: INFO: Wrong image for pod: daemon-set-6qhdg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:23.972: INFO: Wrong image for pod: daemon-set-6stx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:23.976: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:23.976: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:23.976: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:24.972: INFO: Wrong image for pod: daemon-set-6qhdg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:24.972: INFO: Wrong image for pod: daemon-set-6stx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:24.976: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:24.976: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:24.976: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:25.971: INFO: Wrong image for pod: daemon-set-6qhdg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:25.971: INFO: Wrong image for pod: daemon-set-6stx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:25.976: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:25.976: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:25.976: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:26.972: INFO: Wrong image for pod: daemon-set-6qhdg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:26.972: INFO: Wrong image for pod: daemon-set-6stx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:26.976: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:26.976: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:26.976: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:27.972: INFO: Wrong image for pod: daemon-set-6qhdg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:27.972: INFO: Wrong image for pod: daemon-set-6stx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:27.976: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:27.976: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:27.976: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:28.978: INFO: Wrong image for pod: daemon-set-6qhdg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:28.978: INFO: Wrong image for pod: daemon-set-6stx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:28.982: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:28.982: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:28.982: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:29.972: INFO: Wrong image for pod: daemon-set-6qhdg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:29.972: INFO: Wrong image for pod: daemon-set-6stx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:29.976: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:29.976: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:29.988: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:30.972: INFO: Wrong image for pod: daemon-set-6qhdg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:30.972: INFO: Wrong image for pod: daemon-set-6stx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:30.976: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:30.976: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:30.976: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:31.972: INFO: Wrong image for pod: daemon-set-6qhdg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:31.972: INFO: Wrong image for pod: daemon-set-6stx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:31.976: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:31.976: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:31.976: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:32.972: INFO: Wrong image for pod: daemon-set-6qhdg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:32.972: INFO: Wrong image for pod: daemon-set-6stx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:32.976: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:32.976: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:32.976: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:33.971: INFO: Wrong image for pod: daemon-set-6qhdg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:33.972: INFO: Wrong image for pod: daemon-set-6stx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:33.976: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:33.976: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:33.976: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:34.972: INFO: Wrong image for pod: daemon-set-6qhdg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:34.972: INFO: Wrong image for pod: daemon-set-6stx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:34.976: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:34.976: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:34.976: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:35.972: INFO: Wrong image for pod: daemon-set-6qhdg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:35.972: INFO: Wrong image for pod: daemon-set-6stx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:35.976: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:35.976: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:35.976: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:36.972: INFO: Wrong image for pod: daemon-set-6qhdg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:36.972: INFO: Wrong image for pod: daemon-set-6stx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:36.976: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:36.976: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:36.976: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:37.972: INFO: Wrong image for pod: daemon-set-6qhdg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:37.972: INFO: Wrong image for pod: daemon-set-6stx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:37.976: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:37.976: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:37.976: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:38.972: INFO: Wrong image for pod: daemon-set-6qhdg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:38.972: INFO: Wrong image for pod: daemon-set-6stx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:38.976: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:38.976: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:38.976: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:39.978: INFO: Wrong image for pod: daemon-set-6qhdg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:39.978: INFO: Wrong image for pod: daemon-set-6stx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:39.983: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:39.983: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:39.983: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:40.972: INFO: Wrong image for pod: daemon-set-6qhdg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:40.972: INFO: Pod daemon-set-6qhdg is not available
Aug 16 13:20:40.972: INFO: Wrong image for pod: daemon-set-6stx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:40.975: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:40.975: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:40.975: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:41.972: INFO: Wrong image for pod: daemon-set-6stx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:41.972: INFO: Pod daemon-set-8sssz is not available
Aug 16 13:20:41.976: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:41.976: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:41.976: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:42.972: INFO: Wrong image for pod: daemon-set-6stx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:42.972: INFO: Pod daemon-set-8sssz is not available
Aug 16 13:20:42.976: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:42.976: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:42.976: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:43.971: INFO: Wrong image for pod: daemon-set-6stx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:43.971: INFO: Pod daemon-set-8sssz is not available
Aug 16 13:20:43.975: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:43.975: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:43.975: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:44.972: INFO: Wrong image for pod: daemon-set-6stx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:44.976: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:44.976: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:44.976: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:45.972: INFO: Wrong image for pod: daemon-set-6stx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:45.976: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:45.976: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:45.976: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:46.971: INFO: Wrong image for pod: daemon-set-6stx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:46.975: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:46.976: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:46.976: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:47.972: INFO: Wrong image for pod: daemon-set-6stx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:47.976: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:47.976: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:47.976: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:48.972: INFO: Wrong image for pod: daemon-set-6stx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:48.976: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:48.976: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:48.976: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:49.972: INFO: Wrong image for pod: daemon-set-6stx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:49.976: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:49.976: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:49.976: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:50.978: INFO: Wrong image for pod: daemon-set-6stx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:50.982: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:50.982: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:50.982: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:51.972: INFO: Wrong image for pod: daemon-set-6stx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:51.978: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:51.978: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:51.978: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:52.972: INFO: Wrong image for pod: daemon-set-6stx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:52.976: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:52.976: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:52.976: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:53.972: INFO: Wrong image for pod: daemon-set-6stx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:53.976: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:53.976: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:53.976: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:54.972: INFO: Wrong image for pod: daemon-set-6stx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:54.976: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:54.976: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:54.976: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:55.972: INFO: Wrong image for pod: daemon-set-6stx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:55.976: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:55.976: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:55.976: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:56.972: INFO: Wrong image for pod: daemon-set-6stx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:56.976: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:56.976: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:56.976: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:57.971: INFO: Wrong image for pod: daemon-set-6stx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:57.975: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:57.975: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:57.975: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:58.972: INFO: Wrong image for pod: daemon-set-6stx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:58.976: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:58.976: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:58.976: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:59.972: INFO: Wrong image for pod: daemon-set-6stx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:20:59.976: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:59.976: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:20:59.976: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:21:00.972: INFO: Wrong image for pod: daemon-set-6stx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:21:00.975: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:21:00.975: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:21:00.975: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:21:01.979: INFO: Wrong image for pod: daemon-set-6stx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:21:01.983: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:21:01.983: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:21:01.983: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:21:02.972: INFO: Wrong image for pod: daemon-set-6stx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:21:02.976: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:21:02.976: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:21:02.976: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:21:03.972: INFO: Wrong image for pod: daemon-set-6stx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:21:03.976: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:21:03.976: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:21:03.976: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:21:04.971: INFO: Wrong image for pod: daemon-set-6stx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:21:04.975: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:21:04.976: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:21:04.976: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:21:05.972: INFO: Wrong image for pod: daemon-set-6stx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:21:05.976: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:21:05.976: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:21:05.976: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:21:06.973: INFO: Wrong image for pod: daemon-set-6stx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:21:06.977: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:21:06.977: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:21:06.977: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:21:07.972: INFO: Wrong image for pod: daemon-set-6stx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:21:07.976: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:21:07.976: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:21:07.976: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:21:08.972: INFO: Wrong image for pod: daemon-set-6stx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:21:08.976: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:21:08.976: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:21:08.976: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:21:09.972: INFO: Wrong image for pod: daemon-set-6stx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:21:09.976: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:21:09.976: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:21:09.976: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:21:10.972: INFO: Wrong image for pod: daemon-set-6stx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:21:10.976: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:21:10.976: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:21:10.976: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:21:11.972: INFO: Wrong image for pod: daemon-set-6stx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:21:11.976: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:21:11.976: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:21:11.976: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:21:12.979: INFO: Wrong image for pod: daemon-set-6stx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:21:12.983: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:21:12.983: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:21:12.983: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:21:13.972: INFO: Wrong image for pod: daemon-set-6stx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:21:13.976: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:21:13.976: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:21:13.976: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:21:14.972: INFO: Wrong image for pod: daemon-set-6stx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:21:14.980: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:21:14.980: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:21:14.980: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:21:15.972: INFO: Wrong image for pod: daemon-set-6stx7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Aug 16 13:21:15.972: INFO: Pod daemon-set-6stx7 is not available
Aug 16 13:21:15.976: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:21:15.976: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:21:15.976: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:21:16.972: INFO: Pod daemon-set-hbgzw is not available
Aug 16 13:21:16.976: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:21:16.976: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:21:16.976: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
Aug 16 13:21:16.980: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:21:16.980: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:21:16.980: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:21:16.984: INFO: Number of nodes with available pods: 1
Aug 16 13:21:16.984: INFO: Node worker-eab92000-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:21:17.989: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:21:17.989: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:21:17.989: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:21:17.992: INFO: Number of nodes with available pods: 1
Aug 16 13:21:17.992: INFO: Node worker-eab92000-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:21:18.988: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:21:18.989: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:21:18.989: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:21:18.992: INFO: Number of nodes with available pods: 2
Aug 16 13:21:18.992: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-zsqbn, will wait for the garbage collector to delete the pods
Aug 16 13:21:19.070: INFO: Deleting DaemonSet.extensions daemon-set took: 9.701021ms
Aug 16 13:21:19.170: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.220483ms
Aug 16 13:21:31.380: INFO: Number of nodes with available pods: 0
Aug 16 13:21:31.380: INFO: Number of running nodes: 0, number of available pods: 0
Aug 16 13:21:31.383: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-zsqbn/daemonsets","resourceVersion":"18775"},"items":null}

Aug 16 13:21:31.386: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-zsqbn/pods","resourceVersion":"18775"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:21:31.396: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-zsqbn" for this suite.
Aug 16 13:21:37.417: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:21:37.444: INFO: namespace: e2e-tests-daemonsets-zsqbn, resource: bindings, ignored listing per whitelist
Aug 16 13:21:37.535: INFO: namespace e2e-tests-daemonsets-zsqbn deletion completed in 6.135095565s

• [SLOW TEST:91.701 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:21:37.535: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-c6ad3356-c028-11e9-99f6-8a077000b195
STEP: Creating secret with name s-test-opt-upd-c6ad3389-c028-11e9-99f6-8a077000b195
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-c6ad3356-c028-11e9-99f6-8a077000b195
STEP: Updating secret s-test-opt-upd-c6ad3389-c028-11e9-99f6-8a077000b195
STEP: Creating secret with name s-test-opt-create-c6ad339b-c028-11e9-99f6-8a077000b195
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:22:52.060: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-4ftlt" for this suite.
Aug 16 13:23:14.087: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:23:14.141: INFO: namespace: e2e-tests-projected-4ftlt, resource: bindings, ignored listing per whitelist
Aug 16 13:23:14.200: INFO: namespace e2e-tests-projected-4ftlt deletion completed in 22.135835437s

• [SLOW TEST:96.665 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:23:14.201: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-00491e6d-c029-11e9-99f6-8a077000b195
STEP: Creating a pod to test consume configMaps
Aug 16 13:23:14.261: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-0049b70f-c029-11e9-99f6-8a077000b195" in namespace "e2e-tests-projected-ghl6v" to be "success or failure"
Aug 16 13:23:14.266: INFO: Pod "pod-projected-configmaps-0049b70f-c029-11e9-99f6-8a077000b195": Phase="Pending", Reason="", readiness=false. Elapsed: 5.10142ms
Aug 16 13:23:16.270: INFO: Pod "pod-projected-configmaps-0049b70f-c029-11e9-99f6-8a077000b195": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00858998s
STEP: Saw pod success
Aug 16 13:23:16.270: INFO: Pod "pod-projected-configmaps-0049b70f-c029-11e9-99f6-8a077000b195" satisfied condition "success or failure"
Aug 16 13:23:16.273: INFO: Trying to get logs from node worker-eab92000-c026-11e9-bfed-069795ba99e0 pod pod-projected-configmaps-0049b70f-c029-11e9-99f6-8a077000b195 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 16 13:23:16.298: INFO: Waiting for pod pod-projected-configmaps-0049b70f-c029-11e9-99f6-8a077000b195 to disappear
Aug 16 13:23:16.302: INFO: Pod pod-projected-configmaps-0049b70f-c029-11e9-99f6-8a077000b195 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:23:16.302: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-ghl6v" for this suite.
Aug 16 13:23:22.322: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:23:22.340: INFO: namespace: e2e-tests-projected-ghl6v, resource: bindings, ignored listing per whitelist
Aug 16 13:23:22.432: INFO: namespace e2e-tests-projected-ghl6v deletion completed in 6.125885929s

• [SLOW TEST:8.231 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:23:22.432: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Aug 16 13:23:22.495: INFO: Waiting up to 5m0s for pod "pod-0531d315-c029-11e9-99f6-8a077000b195" in namespace "e2e-tests-emptydir-vvsxm" to be "success or failure"
Aug 16 13:23:22.500: INFO: Pod "pod-0531d315-c029-11e9-99f6-8a077000b195": Phase="Pending", Reason="", readiness=false. Elapsed: 4.333183ms
Aug 16 13:23:24.510: INFO: Pod "pod-0531d315-c029-11e9-99f6-8a077000b195": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014353035s
STEP: Saw pod success
Aug 16 13:23:24.510: INFO: Pod "pod-0531d315-c029-11e9-99f6-8a077000b195" satisfied condition "success or failure"
Aug 16 13:23:24.513: INFO: Trying to get logs from node worker-eab92000-c026-11e9-bfed-069795ba99e0 pod pod-0531d315-c029-11e9-99f6-8a077000b195 container test-container: <nil>
STEP: delete the pod
Aug 16 13:23:24.540: INFO: Waiting for pod pod-0531d315-c029-11e9-99f6-8a077000b195 to disappear
Aug 16 13:23:24.545: INFO: Pod pod-0531d315-c029-11e9-99f6-8a077000b195 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:23:24.545: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-vvsxm" for this suite.
Aug 16 13:23:30.563: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:23:30.585: INFO: namespace: e2e-tests-emptydir-vvsxm, resource: bindings, ignored listing per whitelist
Aug 16 13:23:30.691: INFO: namespace e2e-tests-emptydir-vvsxm deletion completed in 6.141773514s

• [SLOW TEST:8.259 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:23:30.691: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
Aug 16 13:23:32.796: INFO: error from create uninitialized namespace: <nil>
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:23:56.852: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-jwpnv" for this suite.
Aug 16 13:24:02.869: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:24:02.918: INFO: namespace: e2e-tests-namespaces-jwpnv, resource: bindings, ignored listing per whitelist
Aug 16 13:24:02.993: INFO: namespace e2e-tests-namespaces-jwpnv deletion completed in 6.137356207s
STEP: Destroying namespace "e2e-tests-nsdeletetest-cc67n" for this suite.
Aug 16 13:24:02.996: INFO: Namespace e2e-tests-nsdeletetest-cc67n was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-7vflw" for this suite.
Aug 16 13:24:09.009: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:24:09.084: INFO: namespace: e2e-tests-nsdeletetest-7vflw, resource: bindings, ignored listing per whitelist
Aug 16 13:24:09.129: INFO: namespace e2e-tests-nsdeletetest-7vflw deletion completed in 6.133020108s

• [SLOW TEST:38.438 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:24:09.129: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-21087f78-c029-11e9-99f6-8a077000b195
STEP: Creating a pod to test consume configMaps
Aug 16 13:24:09.205: INFO: Waiting up to 5m0s for pod "pod-configmaps-21091648-c029-11e9-99f6-8a077000b195" in namespace "e2e-tests-configmap-mlgjj" to be "success or failure"
Aug 16 13:24:09.209: INFO: Pod "pod-configmaps-21091648-c029-11e9-99f6-8a077000b195": Phase="Pending", Reason="", readiness=false. Elapsed: 4.83357ms
Aug 16 13:24:11.213: INFO: Pod "pod-configmaps-21091648-c029-11e9-99f6-8a077000b195": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008738519s
STEP: Saw pod success
Aug 16 13:24:11.213: INFO: Pod "pod-configmaps-21091648-c029-11e9-99f6-8a077000b195" satisfied condition "success or failure"
Aug 16 13:24:11.216: INFO: Trying to get logs from node worker-eab92000-c026-11e9-bfed-069795ba99e0 pod pod-configmaps-21091648-c029-11e9-99f6-8a077000b195 container configmap-volume-test: <nil>
STEP: delete the pod
Aug 16 13:24:11.241: INFO: Waiting for pod pod-configmaps-21091648-c029-11e9-99f6-8a077000b195 to disappear
Aug 16 13:24:11.251: INFO: Pod pod-configmaps-21091648-c029-11e9-99f6-8a077000b195 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:24:11.251: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-mlgjj" for this suite.
Aug 16 13:24:17.288: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:24:17.303: INFO: namespace: e2e-tests-configmap-mlgjj, resource: bindings, ignored listing per whitelist
Aug 16 13:24:17.406: INFO: namespace e2e-tests-configmap-mlgjj deletion completed in 6.144030439s

• [SLOW TEST:8.277 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:24:17.406: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Aug 16 13:24:17.464: INFO: Waiting up to 5m0s for pod "pod-25f59bb3-c029-11e9-99f6-8a077000b195" in namespace "e2e-tests-emptydir-94n9v" to be "success or failure"
Aug 16 13:24:17.467: INFO: Pod "pod-25f59bb3-c029-11e9-99f6-8a077000b195": Phase="Pending", Reason="", readiness=false. Elapsed: 3.26294ms
Aug 16 13:24:19.471: INFO: Pod "pod-25f59bb3-c029-11e9-99f6-8a077000b195": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007209387s
STEP: Saw pod success
Aug 16 13:24:19.471: INFO: Pod "pod-25f59bb3-c029-11e9-99f6-8a077000b195" satisfied condition "success or failure"
Aug 16 13:24:19.474: INFO: Trying to get logs from node worker-eab92000-c026-11e9-bfed-069795ba99e0 pod pod-25f59bb3-c029-11e9-99f6-8a077000b195 container test-container: <nil>
STEP: delete the pod
Aug 16 13:24:19.498: INFO: Waiting for pod pod-25f59bb3-c029-11e9-99f6-8a077000b195 to disappear
Aug 16 13:24:19.502: INFO: Pod pod-25f59bb3-c029-11e9-99f6-8a077000b195 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:24:19.502: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-94n9v" for this suite.
Aug 16 13:24:25.520: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:24:25.609: INFO: namespace: e2e-tests-emptydir-94n9v, resource: bindings, ignored listing per whitelist
Aug 16 13:24:25.629: INFO: namespace e2e-tests-emptydir-94n9v deletion completed in 6.122638995s

• [SLOW TEST:8.223 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:24:25.629: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug 16 13:24:25.687: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2adc5bcc-c029-11e9-99f6-8a077000b195" in namespace "e2e-tests-projected-rqfnl" to be "success or failure"
Aug 16 13:24:25.691: INFO: Pod "downwardapi-volume-2adc5bcc-c029-11e9-99f6-8a077000b195": Phase="Pending", Reason="", readiness=false. Elapsed: 3.281459ms
Aug 16 13:24:27.701: INFO: Pod "downwardapi-volume-2adc5bcc-c029-11e9-99f6-8a077000b195": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013649412s
STEP: Saw pod success
Aug 16 13:24:27.701: INFO: Pod "downwardapi-volume-2adc5bcc-c029-11e9-99f6-8a077000b195" satisfied condition "success or failure"
Aug 16 13:24:27.704: INFO: Trying to get logs from node worker-eab92000-c026-11e9-bfed-069795ba99e0 pod downwardapi-volume-2adc5bcc-c029-11e9-99f6-8a077000b195 container client-container: <nil>
STEP: delete the pod
Aug 16 13:24:27.727: INFO: Waiting for pod downwardapi-volume-2adc5bcc-c029-11e9-99f6-8a077000b195 to disappear
Aug 16 13:24:27.731: INFO: Pod downwardapi-volume-2adc5bcc-c029-11e9-99f6-8a077000b195 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:24:27.731: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-rqfnl" for this suite.
Aug 16 13:24:33.748: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:24:33.845: INFO: namespace: e2e-tests-projected-rqfnl, resource: bindings, ignored listing per whitelist
Aug 16 13:24:33.862: INFO: namespace e2e-tests-projected-rqfnl deletion completed in 6.126794388s

• [SLOW TEST:8.233 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:24:33.862: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug 16 13:24:33.910: INFO: Creating deployment "nginx-deployment"
Aug 16 13:24:33.915: INFO: Waiting for observed generation 1
Aug 16 13:24:35.929: INFO: Waiting for all required pods to come up
Aug 16 13:24:35.945: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Aug 16 13:24:39.964: INFO: Waiting for deployment "nginx-deployment" to complete
Aug 16 13:24:39.971: INFO: Updating deployment "nginx-deployment" with a non-existent image
Aug 16 13:24:39.979: INFO: Updating deployment nginx-deployment
Aug 16 13:24:39.979: INFO: Waiting for observed generation 2
Aug 16 13:24:41.986: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Aug 16 13:24:41.989: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Aug 16 13:24:41.992: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Aug 16 13:24:42.001: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Aug 16 13:24:42.001: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Aug 16 13:24:42.003: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Aug 16 13:24:42.011: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Aug 16 13:24:42.011: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Aug 16 13:24:42.028: INFO: Updating deployment nginx-deployment
Aug 16 13:24:42.028: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Aug 16 13:24:42.034: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Aug 16 13:24:42.040: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Aug 16 13:24:42.071: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-xbf7f,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-xbf7f/deployments/nginx-deployment,UID:2fbc418c-c029-11e9-ae7d-02d5aa9cbbca,ResourceVersion:19904,Generation:3,CreationTimestamp:2019-08-16 13:24:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:5,Conditions:[{Progressing True 2019-08-16 13:24:40 +0000 UTC 2019-08-16 13:24:33 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-65bbdb5f8" is progressing.} {Available False 2019-08-16 13:24:41 +0000 UTC 2019-08-16 13:24:41 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}],ReadyReplicas:8,CollisionCount:nil,},}

Aug 16 13:24:42.083: INFO: New ReplicaSet "nginx-deployment-65bbdb5f8" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8,GenerateName:,Namespace:e2e-tests-deployment-xbf7f,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-xbf7f/replicasets/nginx-deployment-65bbdb5f8,UID:335a5e2b-c029-11e9-ae7d-02d5aa9cbbca,ResourceVersion:19901,Generation:3,CreationTimestamp:2019-08-16 13:24:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 2fbc418c-c029-11e9-ae7d-02d5aa9cbbca 0xc001a6af97 0xc001a6af98}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug 16 13:24:42.083: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Aug 16 13:24:42.083: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965,GenerateName:,Namespace:e2e-tests-deployment-xbf7f,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-xbf7f/replicasets/nginx-deployment-555b55d965,UID:2fbcf176-c029-11e9-ae7d-02d5aa9cbbca,ResourceVersion:19899,Generation:3,CreationTimestamp:2019-08-16 13:24:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 2fbc418c-c029-11e9-ae7d-02d5aa9cbbca 0xc001a6aed7 0xc001a6aed8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Aug 16 13:24:42.124: INFO: Pod "nginx-deployment-555b55d965-5j2nc" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-5j2nc,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-xbf7f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xbf7f/pods/nginx-deployment-555b55d965-5j2nc,UID:2fc08cc5-c029-11e9-ae7d-02d5aa9cbbca,ResourceVersion:19796,Generation:0,CreationTimestamp:2019-08-16 13:24:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.4.38/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 2fbcf176-c029-11e9-ae7d-02d5aa9cbbca 0xc001ac0217 0xc001ac0218}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t9gdc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t9gdc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-t9gdc true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-eab92000-c026-11e9-bfed-069795ba99e0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001ac0280} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001ac02a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 13:24:33 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 13:24:36 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 13:24:36 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 13:24:33 +0000 UTC  }],Message:,Reason:,HostIP:10.1.161.42,PodIP:10.2.4.38,StartTime:2019-08-16 13:24:33 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-16 13:24:36 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://9d13f7849f26a0372508ec42011232049df18684fc221d8c2da892a283e48542}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 16 13:24:42.125: INFO: Pod "nginx-deployment-555b55d965-65zjq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-65zjq,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-xbf7f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xbf7f/pods/nginx-deployment-555b55d965-65zjq,UID:3495dd86-c029-11e9-ae7d-02d5aa9cbbca,ResourceVersion:19915,Generation:0,CreationTimestamp:2019-08-16 13:24:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 2fbcf176-c029-11e9-ae7d-02d5aa9cbbca 0xc001ac0360 0xc001ac0361}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t9gdc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t9gdc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-t9gdc true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-eab92000-c026-11e9-bfed-069795ba99e0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001ac03c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001ac03e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 13:24:41 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 16 13:24:42.125: INFO: Pod "nginx-deployment-555b55d965-8c6p4" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-8c6p4,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-xbf7f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xbf7f/pods/nginx-deployment-555b55d965-8c6p4,UID:2fc0509d-c029-11e9-ae7d-02d5aa9cbbca,ResourceVersion:19771,Generation:0,CreationTimestamp:2019-08-16 13:24:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.3.24/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 2fbcf176-c029-11e9-ae7d-02d5aa9cbbca 0xc001ac0500 0xc001ac0501}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t9gdc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t9gdc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-t9gdc true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-72b80c6a-c026-11e9-bfed-069795ba99e0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001ac0560} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001ac0580}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 13:24:33 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 13:24:35 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 13:24:35 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 13:24:33 +0000 UTC  }],Message:,Reason:,HostIP:10.1.162.26,PodIP:10.2.3.24,StartTime:2019-08-16 13:24:33 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-16 13:24:35 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://e2544a8cb4be64f35c76d790adb9eb843a5ff366c896636a1cdf2f2d684f2136}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 16 13:24:42.125: INFO: Pod "nginx-deployment-555b55d965-gchvn" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-gchvn,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-xbf7f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xbf7f/pods/nginx-deployment-555b55d965-gchvn,UID:2fc39ab2-c029-11e9-ae7d-02d5aa9cbbca,ResourceVersion:19767,Generation:0,CreationTimestamp:2019-08-16 13:24:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.3.25/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 2fbcf176-c029-11e9-ae7d-02d5aa9cbbca 0xc001ac0650 0xc001ac0651}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t9gdc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t9gdc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-t9gdc true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-72b80c6a-c026-11e9-bfed-069795ba99e0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001ac0730} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001ac0750}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 13:24:33 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 13:24:35 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 13:24:35 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 13:24:33 +0000 UTC  }],Message:,Reason:,HostIP:10.1.162.26,PodIP:10.2.3.25,StartTime:2019-08-16 13:24:33 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-16 13:24:35 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://0f5ee5a3dfa10a47ea2c525a52e46c91e2cb44709879de5f781f0ec0073df008}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 16 13:24:42.125: INFO: Pod "nginx-deployment-555b55d965-hd8xr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-hd8xr,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-xbf7f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xbf7f/pods/nginx-deployment-555b55d965-hd8xr,UID:34960bf5-c029-11e9-ae7d-02d5aa9cbbca,ResourceVersion:19916,Generation:0,CreationTimestamp:2019-08-16 13:24:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 2fbcf176-c029-11e9-ae7d-02d5aa9cbbca 0xc001ac0810 0xc001ac0811}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t9gdc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t9gdc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-t9gdc true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-eab92000-c026-11e9-bfed-069795ba99e0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001ac0870} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001ac0890}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 13:24:41 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 16 13:24:42.125: INFO: Pod "nginx-deployment-555b55d965-jgdvs" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-jgdvs,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-xbf7f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xbf7f/pods/nginx-deployment-555b55d965-jgdvs,UID:2fc3a720-c029-11e9-ae7d-02d5aa9cbbca,ResourceVersion:19811,Generation:0,CreationTimestamp:2019-08-16 13:24:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.4.40/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 2fbcf176-c029-11e9-ae7d-02d5aa9cbbca 0xc001ac0910 0xc001ac0911}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t9gdc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t9gdc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-t9gdc true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-eab92000-c026-11e9-bfed-069795ba99e0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001ac0b10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001ac0b30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 13:24:33 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 13:24:37 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 13:24:37 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 13:24:33 +0000 UTC  }],Message:,Reason:,HostIP:10.1.161.42,PodIP:10.2.4.40,StartTime:2019-08-16 13:24:33 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-16 13:24:36 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://d74c7f02e55da5cac494215e9edde3295af3ef37296228991b908e4c1951aa91}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 16 13:24:42.125: INFO: Pod "nginx-deployment-555b55d965-jp7fw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-jp7fw,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-xbf7f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xbf7f/pods/nginx-deployment-555b55d965-jp7fw,UID:349b26cc-c029-11e9-ae7d-02d5aa9cbbca,ResourceVersion:19921,Generation:0,CreationTimestamp:2019-08-16 13:24:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 2fbcf176-c029-11e9-ae7d-02d5aa9cbbca 0xc001ac0bf0 0xc001ac0bf1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t9gdc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t9gdc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-t9gdc true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001ac0c90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001ac0cb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 16 13:24:42.125: INFO: Pod "nginx-deployment-555b55d965-kbfxx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-kbfxx,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-xbf7f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xbf7f/pods/nginx-deployment-555b55d965-kbfxx,UID:349ba7a0-c029-11e9-ae7d-02d5aa9cbbca,ResourceVersion:19925,Generation:0,CreationTimestamp:2019-08-16 13:24:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 2fbcf176-c029-11e9-ae7d-02d5aa9cbbca 0xc001ac0d07 0xc001ac0d08}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t9gdc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t9gdc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-t9gdc true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001ac0d80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001ac0da0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 16 13:24:42.125: INFO: Pod "nginx-deployment-555b55d965-kc46s" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-kc46s,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-xbf7f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xbf7f/pods/nginx-deployment-555b55d965-kc46s,UID:349b6b26-c029-11e9-ae7d-02d5aa9cbbca,ResourceVersion:19923,Generation:0,CreationTimestamp:2019-08-16 13:24:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 2fbcf176-c029-11e9-ae7d-02d5aa9cbbca 0xc001ac0df7 0xc001ac0df8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t9gdc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t9gdc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-t9gdc true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001ac0f00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001ac0f30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 16 13:24:42.125: INFO: Pod "nginx-deployment-555b55d965-kqtfx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-kqtfx,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-xbf7f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xbf7f/pods/nginx-deployment-555b55d965-kqtfx,UID:3499ef64-c029-11e9-ae7d-02d5aa9cbbca,ResourceVersion:19926,Generation:0,CreationTimestamp:2019-08-16 13:24:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 2fbcf176-c029-11e9-ae7d-02d5aa9cbbca 0xc001ac0f87 0xc001ac0f88}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t9gdc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t9gdc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-t9gdc true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-72b80c6a-c026-11e9-bfed-069795ba99e0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001ac0ff0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001ac1010}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 13:24:41 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 16 13:24:42.126: INFO: Pod "nginx-deployment-555b55d965-kz5pf" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-kz5pf,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-xbf7f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xbf7f/pods/nginx-deployment-555b55d965-kz5pf,UID:2fc3678d-c029-11e9-ae7d-02d5aa9cbbca,ResourceVersion:19802,Generation:0,CreationTimestamp:2019-08-16 13:24:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.4.39/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 2fbcf176-c029-11e9-ae7d-02d5aa9cbbca 0xc001ac1110 0xc001ac1111}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t9gdc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t9gdc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-t9gdc true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-eab92000-c026-11e9-bfed-069795ba99e0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001ac1170} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001ac1190}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 13:24:33 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 13:24:37 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 13:24:37 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 13:24:33 +0000 UTC  }],Message:,Reason:,HostIP:10.1.161.42,PodIP:10.2.4.39,StartTime:2019-08-16 13:24:33 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-16 13:24:36 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://e0a2fb475084a5d607a430af4ba8ba28f763d0ec5b14cc2ca4253c6814992389}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 16 13:24:42.126: INFO: Pod "nginx-deployment-555b55d965-nhwkb" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-nhwkb,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-xbf7f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xbf7f/pods/nginx-deployment-555b55d965-nhwkb,UID:2fc630e6-c029-11e9-ae7d-02d5aa9cbbca,ResourceVersion:19774,Generation:0,CreationTimestamp:2019-08-16 13:24:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.3.27/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 2fbcf176-c029-11e9-ae7d-02d5aa9cbbca 0xc001ac1260 0xc001ac1261}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t9gdc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t9gdc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-t9gdc true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-72b80c6a-c026-11e9-bfed-069795ba99e0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001ac1740} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001ac1760}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 13:24:34 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 13:24:35 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 13:24:35 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 13:24:33 +0000 UTC  }],Message:,Reason:,HostIP:10.1.162.26,PodIP:10.2.3.27,StartTime:2019-08-16 13:24:34 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-16 13:24:35 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://69e087b0a4d2d4b0ff24adb8160a7ffa334fc8386590a0c87333a0517d2d1a40}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 16 13:24:42.126: INFO: Pod "nginx-deployment-555b55d965-tqlv4" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-tqlv4,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-xbf7f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xbf7f/pods/nginx-deployment-555b55d965-tqlv4,UID:2fbe4db7-c029-11e9-ae7d-02d5aa9cbbca,ResourceVersion:19775,Generation:0,CreationTimestamp:2019-08-16 13:24:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.4.36/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 2fbcf176-c029-11e9-ae7d-02d5aa9cbbca 0xc001ac1830 0xc001ac1831}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t9gdc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t9gdc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-t9gdc true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-eab92000-c026-11e9-bfed-069795ba99e0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001ac1960} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001ac1980}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 13:24:33 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 13:24:35 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 13:24:35 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 13:24:33 +0000 UTC  }],Message:,Reason:,HostIP:10.1.161.42,PodIP:10.2.4.36,StartTime:2019-08-16 13:24:33 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-16 13:24:35 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://456c68a691bfb94cf0da5b08df46d6f36a01876e81f4adf7a56c4e421011c356}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 16 13:24:42.126: INFO: Pod "nginx-deployment-555b55d965-wg9vp" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-wg9vp,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-xbf7f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xbf7f/pods/nginx-deployment-555b55d965-wg9vp,UID:2fc3b113-c029-11e9-ae7d-02d5aa9cbbca,ResourceVersion:19778,Generation:0,CreationTimestamp:2019-08-16 13:24:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.3.26/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 2fbcf176-c029-11e9-ae7d-02d5aa9cbbca 0xc001ac1e00 0xc001ac1e01}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t9gdc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t9gdc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-t9gdc true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-72b80c6a-c026-11e9-bfed-069795ba99e0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001ac1e60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001ac1e80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 13:24:33 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 13:24:35 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 13:24:35 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 13:24:33 +0000 UTC  }],Message:,Reason:,HostIP:10.1.162.26,PodIP:10.2.3.26,StartTime:2019-08-16 13:24:33 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-16 13:24:35 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://f3da03b842bb167b838e8adab8114b051f55184f5588a16e277c622dc060fd62}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 16 13:24:42.126: INFO: Pod "nginx-deployment-555b55d965-zpk6v" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-zpk6v,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-xbf7f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xbf7f/pods/nginx-deployment-555b55d965-zpk6v,UID:3493f267-c029-11e9-ae7d-02d5aa9cbbca,ResourceVersion:19903,Generation:0,CreationTimestamp:2019-08-16 13:24:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 2fbcf176-c029-11e9-ae7d-02d5aa9cbbca 0xc001a8a040 0xc001a8a041}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t9gdc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t9gdc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-t9gdc true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-eab92000-c026-11e9-bfed-069795ba99e0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a8a100} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a8a120}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 13:24:41 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 16 13:24:42.126: INFO: Pod "nginx-deployment-65bbdb5f8-4dvqg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-4dvqg,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-xbf7f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xbf7f/pods/nginx-deployment-65bbdb5f8-4dvqg,UID:3495ba09-c029-11e9-ae7d-02d5aa9cbbca,ResourceVersion:19912,Generation:0,CreationTimestamp:2019-08-16 13:24:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 335a5e2b-c029-11e9-ae7d-02d5aa9cbbca 0xc001a8a190 0xc001a8a191}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t9gdc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t9gdc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-t9gdc true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-72b80c6a-c026-11e9-bfed-069795ba99e0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a8a200} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a8a2d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 13:24:41 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 16 13:24:42.126: INFO: Pod "nginx-deployment-65bbdb5f8-4lzf9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-4lzf9,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-xbf7f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xbf7f/pods/nginx-deployment-65bbdb5f8-4lzf9,UID:335d340e-c029-11e9-ae7d-02d5aa9cbbca,ResourceVersion:19896,Generation:0,CreationTimestamp:2019-08-16 13:24:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.3.28/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 335a5e2b-c029-11e9-ae7d-02d5aa9cbbca 0xc001a8a610 0xc001a8a611}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t9gdc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t9gdc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-t9gdc true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-72b80c6a-c026-11e9-bfed-069795ba99e0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a8a680} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a8a6a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 13:24:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-16 13:24:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-16 13:24:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 13:24:39 +0000 UTC  }],Message:,Reason:,HostIP:10.1.162.26,PodIP:10.2.3.28,StartTime:2019-08-16 13:24:40 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 16 13:24:42.126: INFO: Pod "nginx-deployment-65bbdb5f8-ft2bt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-ft2bt,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-xbf7f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xbf7f/pods/nginx-deployment-65bbdb5f8-ft2bt,UID:335d603d-c029-11e9-ae7d-02d5aa9cbbca,ResourceVersion:19891,Generation:0,CreationTimestamp:2019-08-16 13:24:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.4.44/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 335a5e2b-c029-11e9-ae7d-02d5aa9cbbca 0xc001a8a790 0xc001a8a791}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t9gdc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t9gdc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-t9gdc true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-eab92000-c026-11e9-bfed-069795ba99e0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a8a800} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a8a820}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 13:24:39 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-16 13:24:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-16 13:24:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 13:24:39 +0000 UTC  }],Message:,Reason:,HostIP:10.1.161.42,PodIP:,StartTime:2019-08-16 13:24:39 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 16 13:24:42.127: INFO: Pod "nginx-deployment-65bbdb5f8-j7w5b" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-j7w5b,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-xbf7f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xbf7f/pods/nginx-deployment-65bbdb5f8-j7w5b,UID:336a53e0-c029-11e9-ae7d-02d5aa9cbbca,ResourceVersion:19877,Generation:0,CreationTimestamp:2019-08-16 13:24:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.3.29/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 335a5e2b-c029-11e9-ae7d-02d5aa9cbbca 0xc001a8a8f0 0xc001a8a8f1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t9gdc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t9gdc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-t9gdc true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-72b80c6a-c026-11e9-bfed-069795ba99e0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a8a960} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a8a980}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 13:24:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-16 13:24:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-16 13:24:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 13:24:39 +0000 UTC  }],Message:,Reason:,HostIP:10.1.162.26,PodIP:,StartTime:2019-08-16 13:24:40 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 16 13:24:42.127: INFO: Pod "nginx-deployment-65bbdb5f8-vq2nv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-vq2nv,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-xbf7f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xbf7f/pods/nginx-deployment-65bbdb5f8-vq2nv,UID:3498ca80-c029-11e9-ae7d-02d5aa9cbbca,ResourceVersion:19922,Generation:0,CreationTimestamp:2019-08-16 13:24:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 335a5e2b-c029-11e9-ae7d-02d5aa9cbbca 0xc001a8aa40 0xc001a8aa41}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t9gdc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t9gdc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-t9gdc true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-72b80c6a-c026-11e9-bfed-069795ba99e0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a8aab0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a8aad0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 13:24:41 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 16 13:24:42.127: INFO: Pod "nginx-deployment-65bbdb5f8-vsvws" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-vsvws,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-xbf7f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xbf7f/pods/nginx-deployment-65bbdb5f8-vsvws,UID:335bb3fc-c029-11e9-ae7d-02d5aa9cbbca,ResourceVersion:19879,Generation:0,CreationTimestamp:2019-08-16 13:24:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.4.42/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 335a5e2b-c029-11e9-ae7d-02d5aa9cbbca 0xc001a8ab50 0xc001a8ab51}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t9gdc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t9gdc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-t9gdc true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-eab92000-c026-11e9-bfed-069795ba99e0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a8abd0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a8abf0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 13:24:39 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-16 13:24:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-16 13:24:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 13:24:39 +0000 UTC  }],Message:,Reason:,HostIP:10.1.161.42,PodIP:,StartTime:2019-08-16 13:24:39 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 16 13:24:42.127: INFO: Pod "nginx-deployment-65bbdb5f8-xxqrv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-xxqrv,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-xbf7f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xbf7f/pods/nginx-deployment-65bbdb5f8-xxqrv,UID:3365f1da-c029-11e9-ae7d-02d5aa9cbbca,ResourceVersion:19883,Generation:0,CreationTimestamp:2019-08-16 13:24:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.4.43/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 335a5e2b-c029-11e9-ae7d-02d5aa9cbbca 0xc001a8acc0 0xc001a8acc1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t9gdc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t9gdc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-t9gdc true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-eab92000-c026-11e9-bfed-069795ba99e0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a8ad30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a8ad50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 13:24:39 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 16 13:24:42.127: INFO: Pod "nginx-deployment-65bbdb5f8-zpwnn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-zpwnn,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-xbf7f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-xbf7f/pods/nginx-deployment-65bbdb5f8-zpwnn,UID:3498acf7-c029-11e9-ae7d-02d5aa9cbbca,ResourceVersion:19919,Generation:0,CreationTimestamp:2019-08-16 13:24:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 335a5e2b-c029-11e9-ae7d-02d5aa9cbbca 0xc001a8adc0 0xc001a8adc1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t9gdc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t9gdc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-t9gdc true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-eab92000-c026-11e9-bfed-069795ba99e0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a8ae30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a8ae50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 13:24:41 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:24:42.127: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-xbf7f" for this suite.
Aug 16 13:24:50.202: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:24:50.293: INFO: namespace: e2e-tests-deployment-xbf7f, resource: bindings, ignored listing per whitelist
Aug 16 13:24:50.322: INFO: namespace e2e-tests-deployment-xbf7f deletion completed in 8.165933572s

• [SLOW TEST:16.460 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:24:50.322: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-399563ef-c029-11e9-99f6-8a077000b195
STEP: Creating secret with name secret-projected-all-test-volume-399563d9-c029-11e9-99f6-8a077000b195
STEP: Creating a pod to test Check all projections for projected volume plugin
Aug 16 13:24:50.394: INFO: Waiting up to 5m0s for pod "projected-volume-399563ae-c029-11e9-99f6-8a077000b195" in namespace "e2e-tests-projected-b2ssw" to be "success or failure"
Aug 16 13:24:50.400: INFO: Pod "projected-volume-399563ae-c029-11e9-99f6-8a077000b195": Phase="Pending", Reason="", readiness=false. Elapsed: 5.294384ms
Aug 16 13:24:52.403: INFO: Pod "projected-volume-399563ae-c029-11e9-99f6-8a077000b195": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008779991s
Aug 16 13:24:54.407: INFO: Pod "projected-volume-399563ae-c029-11e9-99f6-8a077000b195": Phase="Pending", Reason="", readiness=false. Elapsed: 4.012488061s
Aug 16 13:24:56.411: INFO: Pod "projected-volume-399563ae-c029-11e9-99f6-8a077000b195": Phase="Pending", Reason="", readiness=false. Elapsed: 6.016116162s
Aug 16 13:24:58.421: INFO: Pod "projected-volume-399563ae-c029-11e9-99f6-8a077000b195": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.026541239s
STEP: Saw pod success
Aug 16 13:24:58.421: INFO: Pod "projected-volume-399563ae-c029-11e9-99f6-8a077000b195" satisfied condition "success or failure"
Aug 16 13:24:58.424: INFO: Trying to get logs from node worker-eab92000-c026-11e9-bfed-069795ba99e0 pod projected-volume-399563ae-c029-11e9-99f6-8a077000b195 container projected-all-volume-test: <nil>
STEP: delete the pod
Aug 16 13:24:58.455: INFO: Waiting for pod projected-volume-399563ae-c029-11e9-99f6-8a077000b195 to disappear
Aug 16 13:24:58.459: INFO: Pod projected-volume-399563ae-c029-11e9-99f6-8a077000b195 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:24:58.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-b2ssw" for this suite.
Aug 16 13:25:04.477: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:25:04.583: INFO: namespace: e2e-tests-projected-b2ssw, resource: bindings, ignored listing per whitelist
Aug 16 13:25:04.591: INFO: namespace e2e-tests-projected-b2ssw deletion completed in 6.127311592s

• [SLOW TEST:14.269 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:25:04.591: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Aug 16 13:25:04.647: INFO: Waiting up to 5m0s for pod "pod-42154bd0-c029-11e9-99f6-8a077000b195" in namespace "e2e-tests-emptydir-pk5xt" to be "success or failure"
Aug 16 13:25:04.652: INFO: Pod "pod-42154bd0-c029-11e9-99f6-8a077000b195": Phase="Pending", Reason="", readiness=false. Elapsed: 5.436212ms
Aug 16 13:25:06.656: INFO: Pod "pod-42154bd0-c029-11e9-99f6-8a077000b195": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008979497s
STEP: Saw pod success
Aug 16 13:25:06.656: INFO: Pod "pod-42154bd0-c029-11e9-99f6-8a077000b195" satisfied condition "success or failure"
Aug 16 13:25:06.659: INFO: Trying to get logs from node worker-eab92000-c026-11e9-bfed-069795ba99e0 pod pod-42154bd0-c029-11e9-99f6-8a077000b195 container test-container: <nil>
STEP: delete the pod
Aug 16 13:25:06.681: INFO: Waiting for pod pod-42154bd0-c029-11e9-99f6-8a077000b195 to disappear
Aug 16 13:25:06.685: INFO: Pod pod-42154bd0-c029-11e9-99f6-8a077000b195 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:25:06.685: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-pk5xt" for this suite.
Aug 16 13:25:12.701: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:25:12.710: INFO: namespace: e2e-tests-emptydir-pk5xt, resource: bindings, ignored listing per whitelist
Aug 16 13:25:12.828: INFO: namespace e2e-tests-emptydir-pk5xt deletion completed in 6.138724356s

• [SLOW TEST:8.237 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:25:12.828: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Aug 16 13:25:12.920: INFO: Waiting up to 5m0s for pod "downward-api-4703624c-c029-11e9-99f6-8a077000b195" in namespace "e2e-tests-downward-api-tsmvl" to be "success or failure"
Aug 16 13:25:12.923: INFO: Pod "downward-api-4703624c-c029-11e9-99f6-8a077000b195": Phase="Pending", Reason="", readiness=false. Elapsed: 3.491736ms
Aug 16 13:25:14.927: INFO: Pod "downward-api-4703624c-c029-11e9-99f6-8a077000b195": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007168536s
STEP: Saw pod success
Aug 16 13:25:14.927: INFO: Pod "downward-api-4703624c-c029-11e9-99f6-8a077000b195" satisfied condition "success or failure"
Aug 16 13:25:14.930: INFO: Trying to get logs from node worker-eab92000-c026-11e9-bfed-069795ba99e0 pod downward-api-4703624c-c029-11e9-99f6-8a077000b195 container dapi-container: <nil>
STEP: delete the pod
Aug 16 13:25:14.952: INFO: Waiting for pod downward-api-4703624c-c029-11e9-99f6-8a077000b195 to disappear
Aug 16 13:25:14.962: INFO: Pod downward-api-4703624c-c029-11e9-99f6-8a077000b195 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:25:14.962: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-tsmvl" for this suite.
Aug 16 13:25:20.979: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:25:21.009: INFO: namespace: e2e-tests-downward-api-tsmvl, resource: bindings, ignored listing per whitelist
Aug 16 13:25:21.097: INFO: namespace e2e-tests-downward-api-tsmvl deletion completed in 6.130700033s

• [SLOW TEST:8.269 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:25:21.097: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-kkxrw
Aug 16 13:25:25.164: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-kkxrw
STEP: checking the pod's current state and verifying that restartCount is present
Aug 16 13:25:25.167: INFO: Initial restart count of pod liveness-http is 0
Aug 16 13:25:39.211: INFO: Restart count of pod e2e-tests-container-probe-kkxrw/liveness-http is now 1 (14.043829248s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:25:39.230: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-kkxrw" for this suite.
Aug 16 13:25:45.251: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:25:45.308: INFO: namespace: e2e-tests-container-probe-kkxrw, resource: bindings, ignored listing per whitelist
Aug 16 13:25:45.365: INFO: namespace e2e-tests-container-probe-kkxrw deletion completed in 6.131359082s

• [SLOW TEST:24.268 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:25:45.366: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
Aug 16 13:25:45.421: INFO: Waiting up to 5m0s for pod "client-containers-5a62e992-c029-11e9-99f6-8a077000b195" in namespace "e2e-tests-containers-jhwcf" to be "success or failure"
Aug 16 13:25:45.425: INFO: Pod "client-containers-5a62e992-c029-11e9-99f6-8a077000b195": Phase="Pending", Reason="", readiness=false. Elapsed: 4.039362ms
Aug 16 13:25:47.428: INFO: Pod "client-containers-5a62e992-c029-11e9-99f6-8a077000b195": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007465556s
Aug 16 13:25:49.438: INFO: Pod "client-containers-5a62e992-c029-11e9-99f6-8a077000b195": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017562352s
STEP: Saw pod success
Aug 16 13:25:49.438: INFO: Pod "client-containers-5a62e992-c029-11e9-99f6-8a077000b195" satisfied condition "success or failure"
Aug 16 13:25:49.441: INFO: Trying to get logs from node worker-eab92000-c026-11e9-bfed-069795ba99e0 pod client-containers-5a62e992-c029-11e9-99f6-8a077000b195 container test-container: <nil>
STEP: delete the pod
Aug 16 13:25:49.463: INFO: Waiting for pod client-containers-5a62e992-c029-11e9-99f6-8a077000b195 to disappear
Aug 16 13:25:49.467: INFO: Pod client-containers-5a62e992-c029-11e9-99f6-8a077000b195 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:25:49.467: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-jhwcf" for this suite.
Aug 16 13:25:55.485: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:25:55.533: INFO: namespace: e2e-tests-containers-jhwcf, resource: bindings, ignored listing per whitelist
Aug 16 13:25:55.597: INFO: namespace e2e-tests-containers-jhwcf deletion completed in 6.126010564s

• [SLOW TEST:10.232 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:25:55.598: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug 16 13:25:55.661: INFO: Waiting up to 5m0s for pod "downwardapi-volume-607d87db-c029-11e9-99f6-8a077000b195" in namespace "e2e-tests-projected-c6hjj" to be "success or failure"
Aug 16 13:25:55.676: INFO: Pod "downwardapi-volume-607d87db-c029-11e9-99f6-8a077000b195": Phase="Pending", Reason="", readiness=false. Elapsed: 15.286447ms
Aug 16 13:25:57.680: INFO: Pod "downwardapi-volume-607d87db-c029-11e9-99f6-8a077000b195": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019386077s
STEP: Saw pod success
Aug 16 13:25:57.681: INFO: Pod "downwardapi-volume-607d87db-c029-11e9-99f6-8a077000b195" satisfied condition "success or failure"
Aug 16 13:25:57.684: INFO: Trying to get logs from node worker-eab92000-c026-11e9-bfed-069795ba99e0 pod downwardapi-volume-607d87db-c029-11e9-99f6-8a077000b195 container client-container: <nil>
STEP: delete the pod
Aug 16 13:25:57.713: INFO: Waiting for pod downwardapi-volume-607d87db-c029-11e9-99f6-8a077000b195 to disappear
Aug 16 13:25:57.727: INFO: Pod downwardapi-volume-607d87db-c029-11e9-99f6-8a077000b195 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:25:57.727: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-c6hjj" for this suite.
Aug 16 13:26:03.748: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:26:03.809: INFO: namespace: e2e-tests-projected-c6hjj, resource: bindings, ignored listing per whitelist
Aug 16 13:26:03.870: INFO: namespace e2e-tests-projected-c6hjj deletion completed in 6.138252302s

• [SLOW TEST:8.272 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:26:03.870: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Aug 16 13:26:07.974: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 16 13:26:07.977: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 16 13:26:09.977: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 16 13:26:09.988: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 16 13:26:11.977: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 16 13:26:11.981: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 16 13:26:13.977: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 16 13:26:13.981: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 16 13:26:15.977: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 16 13:26:15.981: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 16 13:26:17.978: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 16 13:26:17.982: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 16 13:26:19.977: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 16 13:26:19.981: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 16 13:26:21.977: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 16 13:26:21.992: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 16 13:26:23.977: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 16 13:26:23.981: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 16 13:26:25.977: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 16 13:26:25.981: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 16 13:26:27.977: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 16 13:26:27.981: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 16 13:26:29.977: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 16 13:26:29.981: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 16 13:26:31.977: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 16 13:26:31.982: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 16 13:26:33.977: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 16 13:26:33.988: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:26:33.988: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-gh4gb" for this suite.
Aug 16 13:26:56.013: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:26:56.079: INFO: namespace: e2e-tests-container-lifecycle-hook-gh4gb, resource: bindings, ignored listing per whitelist
Aug 16 13:26:56.128: INFO: namespace e2e-tests-container-lifecycle-hook-gh4gb deletion completed in 22.136322229s

• [SLOW TEST:52.258 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:26:56.128: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug 16 13:26:56.193: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8491a1e8-c029-11e9-99f6-8a077000b195" in namespace "e2e-tests-downward-api-xl4v9" to be "success or failure"
Aug 16 13:26:56.197: INFO: Pod "downwardapi-volume-8491a1e8-c029-11e9-99f6-8a077000b195": Phase="Pending", Reason="", readiness=false. Elapsed: 3.694766ms
Aug 16 13:26:58.201: INFO: Pod "downwardapi-volume-8491a1e8-c029-11e9-99f6-8a077000b195": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007504358s
STEP: Saw pod success
Aug 16 13:26:58.201: INFO: Pod "downwardapi-volume-8491a1e8-c029-11e9-99f6-8a077000b195" satisfied condition "success or failure"
Aug 16 13:26:58.204: INFO: Trying to get logs from node worker-eab92000-c026-11e9-bfed-069795ba99e0 pod downwardapi-volume-8491a1e8-c029-11e9-99f6-8a077000b195 container client-container: <nil>
STEP: delete the pod
Aug 16 13:26:58.230: INFO: Waiting for pod downwardapi-volume-8491a1e8-c029-11e9-99f6-8a077000b195 to disappear
Aug 16 13:26:58.236: INFO: Pod downwardapi-volume-8491a1e8-c029-11e9-99f6-8a077000b195 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:26:58.236: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-xl4v9" for this suite.
Aug 16 13:27:04.253: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:27:04.277: INFO: namespace: e2e-tests-downward-api-xl4v9, resource: bindings, ignored listing per whitelist
Aug 16 13:27:04.369: INFO: namespace e2e-tests-downward-api-xl4v9 deletion completed in 6.128703343s

• [SLOW TEST:8.241 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:27:04.369: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-74nmr
Aug 16 13:27:06.492: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-74nmr
STEP: checking the pod's current state and verifying that restartCount is present
Aug 16 13:27:06.495: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:31:07.125: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-74nmr" for this suite.
Aug 16 13:31:13.146: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:31:13.238: INFO: namespace: e2e-tests-container-probe-74nmr, resource: bindings, ignored listing per whitelist
Aug 16 13:31:13.260: INFO: namespace e2e-tests-container-probe-74nmr deletion completed in 6.126311916s

• [SLOW TEST:248.890 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:31:13.260: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug 16 13:31:13.329: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
Aug 16 13:31:13.335: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-l9m5n/daemonsets","resourceVersion":"21765"},"items":null}

Aug 16 13:31:13.338: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-l9m5n/pods","resourceVersion":"21765"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:31:13.347: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-l9m5n" for this suite.
Aug 16 13:31:19.366: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:31:19.444: INFO: namespace: e2e-tests-daemonsets-l9m5n, resource: bindings, ignored listing per whitelist
Aug 16 13:31:19.477: INFO: namespace e2e-tests-daemonsets-l9m5n deletion completed in 6.126581293s

S [SKIPPING] [6.218 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  Aug 16 13:31:13.329: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:31:19.477: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-21886bdc-c02a-11e9-99f6-8a077000b195
STEP: Creating a pod to test consume secrets
Aug 16 13:31:19.537: INFO: Waiting up to 5m0s for pod "pod-secrets-21892064-c02a-11e9-99f6-8a077000b195" in namespace "e2e-tests-secrets-2zkhz" to be "success or failure"
Aug 16 13:31:19.541: INFO: Pod "pod-secrets-21892064-c02a-11e9-99f6-8a077000b195": Phase="Pending", Reason="", readiness=false. Elapsed: 3.938396ms
Aug 16 13:31:21.544: INFO: Pod "pod-secrets-21892064-c02a-11e9-99f6-8a077000b195": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007419888s
STEP: Saw pod success
Aug 16 13:31:21.544: INFO: Pod "pod-secrets-21892064-c02a-11e9-99f6-8a077000b195" satisfied condition "success or failure"
Aug 16 13:31:21.547: INFO: Trying to get logs from node worker-eab92000-c026-11e9-bfed-069795ba99e0 pod pod-secrets-21892064-c02a-11e9-99f6-8a077000b195 container secret-volume-test: <nil>
STEP: delete the pod
Aug 16 13:31:21.573: INFO: Waiting for pod pod-secrets-21892064-c02a-11e9-99f6-8a077000b195 to disappear
Aug 16 13:31:21.578: INFO: Pod pod-secrets-21892064-c02a-11e9-99f6-8a077000b195 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:31:21.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-2zkhz" for this suite.
Aug 16 13:31:27.606: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:31:27.683: INFO: namespace: e2e-tests-secrets-2zkhz, resource: bindings, ignored listing per whitelist
Aug 16 13:31:27.716: INFO: namespace e2e-tests-secrets-2zkhz deletion completed in 6.133402205s

• [SLOW TEST:8.239 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:31:27.717: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0816 13:31:37.851735      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Aug 16 13:31:37.851: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:31:37.851: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-gdh6f" for this suite.
Aug 16 13:31:43.868: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:31:43.944: INFO: namespace: e2e-tests-gc-gdh6f, resource: bindings, ignored listing per whitelist
Aug 16 13:31:43.984: INFO: namespace e2e-tests-gc-gdh6f deletion completed in 6.129393471s

• [SLOW TEST:16.268 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:31:43.985: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Aug 16 13:31:44.062: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:31:44.062: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:31:44.062: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:31:44.067: INFO: Number of nodes with available pods: 0
Aug 16 13:31:44.067: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:31:45.071: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:31:45.071: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:31:45.071: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:31:45.075: INFO: Number of nodes with available pods: 0
Aug 16 13:31:45.075: INFO: Node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 is running more than one daemon pod
Aug 16 13:31:46.072: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:31:46.072: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:31:46.072: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:31:46.075: INFO: Number of nodes with available pods: 2
Aug 16 13:31:46.075: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Aug 16 13:31:46.094: INFO: DaemonSet pods can't tolerate node master-6164ec76-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:31:46.094: INFO: DaemonSet pods can't tolerate node master-6164ec9e-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:31:46.094: INFO: DaemonSet pods can't tolerate node master-6164ecb2-c01c-11e9-bfed-069795ba99e0 with taints [{Key:Dedicated Value:Master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Aug 16 13:31:46.099: INFO: Number of nodes with available pods: 2
Aug 16 13:31:46.099: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-pxf66, will wait for the garbage collector to delete the pods
Aug 16 13:31:47.174: INFO: Deleting DaemonSet.extensions daemon-set took: 10.218142ms
Aug 16 13:31:47.274: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.136211ms
Aug 16 13:33:28.383: INFO: Number of nodes with available pods: 0
Aug 16 13:33:28.383: INFO: Number of running nodes: 0, number of available pods: 0
Aug 16 13:33:28.391: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-pxf66/daemonsets","resourceVersion":"22542"},"items":null}

Aug 16 13:33:28.396: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-pxf66/pods","resourceVersion":"22542"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:33:28.410: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-pxf66" for this suite.
Aug 16 13:33:34.428: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:33:34.437: INFO: namespace: e2e-tests-daemonsets-pxf66, resource: bindings, ignored listing per whitelist
Aug 16 13:33:34.547: INFO: namespace e2e-tests-daemonsets-pxf66 deletion completed in 6.133540396s

• [SLOW TEST:110.562 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:33:34.547: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-lwp5
STEP: Creating a pod to test atomic-volume-subpath
Aug 16 13:33:34.616: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-lwp5" in namespace "e2e-tests-subpath-nghqj" to be "success or failure"
Aug 16 13:33:34.622: INFO: Pod "pod-subpath-test-configmap-lwp5": Phase="Pending", Reason="", readiness=false. Elapsed: 5.856712ms
Aug 16 13:33:36.625: INFO: Pod "pod-subpath-test-configmap-lwp5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009345485s
Aug 16 13:33:38.636: INFO: Pod "pod-subpath-test-configmap-lwp5": Phase="Running", Reason="", readiness=false. Elapsed: 4.019995605s
Aug 16 13:33:40.640: INFO: Pod "pod-subpath-test-configmap-lwp5": Phase="Running", Reason="", readiness=false. Elapsed: 6.0236565s
Aug 16 13:33:42.643: INFO: Pod "pod-subpath-test-configmap-lwp5": Phase="Running", Reason="", readiness=false. Elapsed: 8.027445174s
Aug 16 13:33:44.649: INFO: Pod "pod-subpath-test-configmap-lwp5": Phase="Running", Reason="", readiness=false. Elapsed: 10.033382754s
Aug 16 13:33:46.653: INFO: Pod "pod-subpath-test-configmap-lwp5": Phase="Running", Reason="", readiness=false. Elapsed: 12.037286205s
Aug 16 13:33:48.663: INFO: Pod "pod-subpath-test-configmap-lwp5": Phase="Running", Reason="", readiness=false. Elapsed: 14.047417968s
Aug 16 13:33:50.667: INFO: Pod "pod-subpath-test-configmap-lwp5": Phase="Running", Reason="", readiness=false. Elapsed: 16.051196856s
Aug 16 13:33:52.671: INFO: Pod "pod-subpath-test-configmap-lwp5": Phase="Running", Reason="", readiness=false. Elapsed: 18.055032237s
Aug 16 13:33:54.675: INFO: Pod "pod-subpath-test-configmap-lwp5": Phase="Running", Reason="", readiness=false. Elapsed: 20.058917027s
Aug 16 13:33:56.679: INFO: Pod "pod-subpath-test-configmap-lwp5": Phase="Running", Reason="", readiness=false. Elapsed: 22.062771293s
Aug 16 13:33:58.689: INFO: Pod "pod-subpath-test-configmap-lwp5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.073226109s
STEP: Saw pod success
Aug 16 13:33:58.689: INFO: Pod "pod-subpath-test-configmap-lwp5" satisfied condition "success or failure"
Aug 16 13:33:58.692: INFO: Trying to get logs from node worker-eab92000-c026-11e9-bfed-069795ba99e0 pod pod-subpath-test-configmap-lwp5 container test-container-subpath-configmap-lwp5: <nil>
STEP: delete the pod
Aug 16 13:33:58.720: INFO: Waiting for pod pod-subpath-test-configmap-lwp5 to disappear
Aug 16 13:33:58.723: INFO: Pod pod-subpath-test-configmap-lwp5 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-lwp5
Aug 16 13:33:58.723: INFO: Deleting pod "pod-subpath-test-configmap-lwp5" in namespace "e2e-tests-subpath-nghqj"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:33:58.726: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-nghqj" for this suite.
Aug 16 13:34:04.743: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:34:04.753: INFO: namespace: e2e-tests-subpath-nghqj, resource: bindings, ignored listing per whitelist
Aug 16 13:34:04.862: INFO: namespace e2e-tests-subpath-nghqj deletion completed in 6.132543534s

• [SLOW TEST:30.315 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:34:04.863: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-t77qf
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Aug 16 13:34:04.910: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Aug 16 13:34:22.990: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 10.2.4.74 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-t77qf PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 16 13:34:22.990: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
Aug 16 13:34:24.072: INFO: Found all expected endpoints: [netserver-0]
Aug 16 13:34:24.075: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 10.2.3.44 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-t77qf PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 16 13:34:24.075: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
Aug 16 13:34:25.143: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:34:25.143: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-t77qf" for this suite.
Aug 16 13:34:47.161: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:34:47.167: INFO: namespace: e2e-tests-pod-network-test-t77qf, resource: bindings, ignored listing per whitelist
Aug 16 13:34:47.274: INFO: namespace e2e-tests-pod-network-test-t77qf deletion completed in 22.126385589s

• [SLOW TEST:42.411 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:34:47.274: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-9d63ed1b-c02a-11e9-99f6-8a077000b195
STEP: Creating a pod to test consume configMaps
Aug 16 13:34:47.336: INFO: Waiting up to 5m0s for pod "pod-configmaps-9d6494f1-c02a-11e9-99f6-8a077000b195" in namespace "e2e-tests-configmap-bnfh5" to be "success or failure"
Aug 16 13:34:47.344: INFO: Pod "pod-configmaps-9d6494f1-c02a-11e9-99f6-8a077000b195": Phase="Pending", Reason="", readiness=false. Elapsed: 7.428678ms
Aug 16 13:34:49.347: INFO: Pod "pod-configmaps-9d6494f1-c02a-11e9-99f6-8a077000b195": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01114111s
STEP: Saw pod success
Aug 16 13:34:49.347: INFO: Pod "pod-configmaps-9d6494f1-c02a-11e9-99f6-8a077000b195" satisfied condition "success or failure"
Aug 16 13:34:49.350: INFO: Trying to get logs from node worker-eab92000-c026-11e9-bfed-069795ba99e0 pod pod-configmaps-9d6494f1-c02a-11e9-99f6-8a077000b195 container configmap-volume-test: <nil>
STEP: delete the pod
Aug 16 13:34:49.372: INFO: Waiting for pod pod-configmaps-9d6494f1-c02a-11e9-99f6-8a077000b195 to disappear
Aug 16 13:34:49.380: INFO: Pod pod-configmaps-9d6494f1-c02a-11e9-99f6-8a077000b195 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:34:49.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-bnfh5" for this suite.
Aug 16 13:34:55.398: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:34:55.454: INFO: namespace: e2e-tests-configmap-bnfh5, resource: bindings, ignored listing per whitelist
Aug 16 13:34:55.507: INFO: namespace e2e-tests-configmap-bnfh5 deletion completed in 6.122987794s

• [SLOW TEST:8.232 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:34:55.507: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
Aug 16 13:34:55.560: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 --namespace=e2e-tests-kubectl-xq5vk run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Aug 16 13:34:57.106: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Aug 16 13:34:57.106: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:34:59.113: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-xq5vk" for this suite.
Aug 16 13:35:05.138: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:35:05.180: INFO: namespace: e2e-tests-kubectl-xq5vk, resource: bindings, ignored listing per whitelist
Aug 16 13:35:05.252: INFO: namespace e2e-tests-kubectl-xq5vk deletion completed in 6.135332589s

• [SLOW TEST:9.745 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:35:05.253: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Aug 16 13:35:09.352: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug 16 13:35:09.358: INFO: Pod pod-with-poststart-http-hook still exists
Aug 16 13:35:11.358: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug 16 13:35:11.362: INFO: Pod pod-with-poststart-http-hook still exists
Aug 16 13:35:13.358: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug 16 13:35:13.362: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:35:13.362: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-86vcm" for this suite.
Aug 16 13:35:35.380: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:35:35.483: INFO: namespace: e2e-tests-container-lifecycle-hook-86vcm, resource: bindings, ignored listing per whitelist
Aug 16 13:35:35.495: INFO: namespace e2e-tests-container-lifecycle-hook-86vcm deletion completed in 22.128984846s

• [SLOW TEST:30.242 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:35:35.495: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug 16 13:35:35.552: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ba216f7b-c02a-11e9-99f6-8a077000b195" in namespace "e2e-tests-projected-pfnlk" to be "success or failure"
Aug 16 13:35:35.560: INFO: Pod "downwardapi-volume-ba216f7b-c02a-11e9-99f6-8a077000b195": Phase="Pending", Reason="", readiness=false. Elapsed: 6.448503ms
Aug 16 13:35:37.571: INFO: Pod "downwardapi-volume-ba216f7b-c02a-11e9-99f6-8a077000b195": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016652572s
STEP: Saw pod success
Aug 16 13:35:37.571: INFO: Pod "downwardapi-volume-ba216f7b-c02a-11e9-99f6-8a077000b195" satisfied condition "success or failure"
Aug 16 13:35:37.574: INFO: Trying to get logs from node worker-eab92000-c026-11e9-bfed-069795ba99e0 pod downwardapi-volume-ba216f7b-c02a-11e9-99f6-8a077000b195 container client-container: <nil>
STEP: delete the pod
Aug 16 13:35:37.605: INFO: Waiting for pod downwardapi-volume-ba216f7b-c02a-11e9-99f6-8a077000b195 to disappear
Aug 16 13:35:37.608: INFO: Pod downwardapi-volume-ba216f7b-c02a-11e9-99f6-8a077000b195 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:35:37.608: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-pfnlk" for this suite.
Aug 16 13:35:43.625: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:35:43.645: INFO: namespace: e2e-tests-projected-pfnlk, resource: bindings, ignored listing per whitelist
Aug 16 13:35:43.734: INFO: namespace e2e-tests-projected-pfnlk deletion completed in 6.121809443s

• [SLOW TEST:8.238 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:35:43.734: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:35:48.821: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-4j4kf" for this suite.
Aug 16 13:36:10.845: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:36:10.872: INFO: namespace: e2e-tests-replication-controller-4j4kf, resource: bindings, ignored listing per whitelist
Aug 16 13:36:10.958: INFO: namespace e2e-tests-replication-controller-4j4kf deletion completed in 22.132883253s

• [SLOW TEST:27.224 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:36:10.958: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:36:13.050: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-h9js9" for this suite.
Aug 16 13:36:53.068: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:36:53.176: INFO: namespace: e2e-tests-kubelet-test-h9js9, resource: bindings, ignored listing per whitelist
Aug 16 13:36:53.187: INFO: namespace e2e-tests-kubelet-test-h9js9 deletion completed in 40.132746392s

• [SLOW TEST:42.228 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:36:53.187: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-8hs9c/configmap-test-e870bf79-c02a-11e9-99f6-8a077000b195
STEP: Creating a pod to test consume configMaps
Aug 16 13:36:53.250: INFO: Waiting up to 5m0s for pod "pod-configmaps-e871794f-c02a-11e9-99f6-8a077000b195" in namespace "e2e-tests-configmap-8hs9c" to be "success or failure"
Aug 16 13:36:53.255: INFO: Pod "pod-configmaps-e871794f-c02a-11e9-99f6-8a077000b195": Phase="Pending", Reason="", readiness=false. Elapsed: 4.812936ms
Aug 16 13:36:55.265: INFO: Pod "pod-configmaps-e871794f-c02a-11e9-99f6-8a077000b195": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014899484s
STEP: Saw pod success
Aug 16 13:36:55.265: INFO: Pod "pod-configmaps-e871794f-c02a-11e9-99f6-8a077000b195" satisfied condition "success or failure"
Aug 16 13:36:55.268: INFO: Trying to get logs from node worker-eab92000-c026-11e9-bfed-069795ba99e0 pod pod-configmaps-e871794f-c02a-11e9-99f6-8a077000b195 container env-test: <nil>
STEP: delete the pod
Aug 16 13:36:55.293: INFO: Waiting for pod pod-configmaps-e871794f-c02a-11e9-99f6-8a077000b195 to disappear
Aug 16 13:36:55.296: INFO: Pod pod-configmaps-e871794f-c02a-11e9-99f6-8a077000b195 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:36:55.296: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-8hs9c" for this suite.
Aug 16 13:37:01.313: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:37:01.397: INFO: namespace: e2e-tests-configmap-8hs9c, resource: bindings, ignored listing per whitelist
Aug 16 13:37:01.427: INFO: namespace e2e-tests-configmap-8hs9c deletion completed in 6.126846322s

• [SLOW TEST:8.240 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:37:01.427: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
Aug 16 13:37:01.481: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 create -f - --namespace=e2e-tests-kubectl-b2js4'
Aug 16 13:37:01.602: INFO: stderr: ""
Aug 16 13:37:01.602: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug 16 13:37:01.603: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-b2js4'
Aug 16 13:37:01.690: INFO: stderr: ""
Aug 16 13:37:01.690: INFO: stdout: "update-demo-nautilus-65k7b update-demo-nautilus-c4f94 "
Aug 16 13:37:01.690: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 get pods update-demo-nautilus-65k7b -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-b2js4'
Aug 16 13:37:01.746: INFO: stderr: ""
Aug 16 13:37:01.746: INFO: stdout: ""
Aug 16 13:37:01.746: INFO: update-demo-nautilus-65k7b is created but not running
Aug 16 13:37:06.746: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-b2js4'
Aug 16 13:37:06.807: INFO: stderr: ""
Aug 16 13:37:06.807: INFO: stdout: "update-demo-nautilus-65k7b update-demo-nautilus-c4f94 "
Aug 16 13:37:06.807: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 get pods update-demo-nautilus-65k7b -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-b2js4'
Aug 16 13:37:06.862: INFO: stderr: ""
Aug 16 13:37:06.862: INFO: stdout: "true"
Aug 16 13:37:06.862: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 get pods update-demo-nautilus-65k7b -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-b2js4'
Aug 16 13:37:06.922: INFO: stderr: ""
Aug 16 13:37:06.922: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 16 13:37:06.922: INFO: validating pod update-demo-nautilus-65k7b
Aug 16 13:37:06.926: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 16 13:37:06.926: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 16 13:37:06.926: INFO: update-demo-nautilus-65k7b is verified up and running
Aug 16 13:37:06.926: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 get pods update-demo-nautilus-c4f94 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-b2js4'
Aug 16 13:37:06.981: INFO: stderr: ""
Aug 16 13:37:06.981: INFO: stdout: "true"
Aug 16 13:37:06.981: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 get pods update-demo-nautilus-c4f94 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-b2js4'
Aug 16 13:37:07.039: INFO: stderr: ""
Aug 16 13:37:07.039: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 16 13:37:07.039: INFO: validating pod update-demo-nautilus-c4f94
Aug 16 13:37:07.043: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 16 13:37:07.043: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 16 13:37:07.043: INFO: update-demo-nautilus-c4f94 is verified up and running
STEP: rolling-update to new replication controller
Aug 16 13:37:07.044: INFO: scanned /root for discovery docs: <nil>
Aug 16 13:37:07.044: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-b2js4'
Aug 16 13:37:28.473: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Aug 16 13:37:28.473: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug 16 13:37:28.473: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-b2js4'
Aug 16 13:37:28.550: INFO: stderr: ""
Aug 16 13:37:28.550: INFO: stdout: "update-demo-kitten-47djj update-demo-kitten-zz87n "
Aug 16 13:37:28.550: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 get pods update-demo-kitten-47djj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-b2js4'
Aug 16 13:37:28.608: INFO: stderr: ""
Aug 16 13:37:28.608: INFO: stdout: "true"
Aug 16 13:37:28.608: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 get pods update-demo-kitten-47djj -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-b2js4'
Aug 16 13:37:28.664: INFO: stderr: ""
Aug 16 13:37:28.664: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Aug 16 13:37:28.664: INFO: validating pod update-demo-kitten-47djj
Aug 16 13:37:28.669: INFO: got data: {
  "image": "kitten.jpg"
}

Aug 16 13:37:28.669: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Aug 16 13:37:28.669: INFO: update-demo-kitten-47djj is verified up and running
Aug 16 13:37:28.669: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 get pods update-demo-kitten-zz87n -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-b2js4'
Aug 16 13:37:28.722: INFO: stderr: ""
Aug 16 13:37:28.722: INFO: stdout: "true"
Aug 16 13:37:28.722: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 get pods update-demo-kitten-zz87n -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-b2js4'
Aug 16 13:37:28.777: INFO: stderr: ""
Aug 16 13:37:28.777: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Aug 16 13:37:28.777: INFO: validating pod update-demo-kitten-zz87n
Aug 16 13:37:28.781: INFO: got data: {
  "image": "kitten.jpg"
}

Aug 16 13:37:28.781: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Aug 16 13:37:28.781: INFO: update-demo-kitten-zz87n is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:37:28.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-b2js4" for this suite.
Aug 16 13:37:50.806: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:37:50.816: INFO: namespace: e2e-tests-kubectl-b2js4, resource: bindings, ignored listing per whitelist
Aug 16 13:37:50.915: INFO: namespace e2e-tests-kubectl-b2js4 deletion completed in 22.128997533s

• [SLOW TEST:49.488 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:37:50.915: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug 16 13:37:50.964: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Aug 16 13:37:50.974: INFO: Pod name sample-pod: Found 0 pods out of 1
Aug 16 13:37:55.978: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Aug 16 13:37:55.978: INFO: Creating deployment "test-rolling-update-deployment"
Aug 16 13:37:55.983: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Aug 16 13:37:55.989: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Aug 16 13:37:57.996: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Aug 16 13:37:57.999: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Aug 16 13:37:58.008: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-bt6rv,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-bt6rv/deployments/test-rolling-update-deployment,UID:0dd0d789-c02b-11e9-ae7d-02d5aa9cbbca,ResourceVersion:24000,Generation:1,CreationTimestamp:2019-08-16 13:37:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-08-16 13:37:55 +0000 UTC 2019-08-16 13:37:55 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-08-16 13:37:57 +0000 UTC 2019-08-16 13:37:55 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-68b55d7bc6" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Aug 16 13:37:58.011: INFO: New ReplicaSet "test-rolling-update-deployment-68b55d7bc6" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6,GenerateName:,Namespace:e2e-tests-deployment-bt6rv,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-bt6rv/replicasets/test-rolling-update-deployment-68b55d7bc6,UID:0dd31b8f-c02b-11e9-ae7d-02d5aa9cbbca,ResourceVersion:23990,Generation:1,CreationTimestamp:2019-08-16 13:37:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 0dd0d789-c02b-11e9-ae7d-02d5aa9cbbca 0xc001223d67 0xc001223d68}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Aug 16 13:37:58.011: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Aug 16 13:37:58.011: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-bt6rv,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-bt6rv/replicasets/test-rolling-update-controller,UID:0ad3bc8a-c02b-11e9-ae7d-02d5aa9cbbca,ResourceVersion:23999,Generation:2,CreationTimestamp:2019-08-16 13:37:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 0dd0d789-c02b-11e9-ae7d-02d5aa9cbbca 0xc001223ca7 0xc001223ca8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug 16 13:37:58.014: INFO: Pod "test-rolling-update-deployment-68b55d7bc6-hnzs2" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6-hnzs2,GenerateName:test-rolling-update-deployment-68b55d7bc6-,Namespace:e2e-tests-deployment-bt6rv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bt6rv/pods/test-rolling-update-deployment-68b55d7bc6-hnzs2,UID:0dd41cc8-c02b-11e9-ae7d-02d5aa9cbbca,ResourceVersion:23989,Generation:0,CreationTimestamp:2019-08-16 13:37:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.4.87/32,},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-68b55d7bc6 0dd31b8f-c02b-11e9-ae7d-02d5aa9cbbca 0xc001ac8d37 0xc001ac8d38}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vnj85 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vnj85,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-vnj85 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-eab92000-c026-11e9-bfed-069795ba99e0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001ac8e20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001ac8e40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 13:37:55 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 13:37:56 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 13:37:56 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 13:37:55 +0000 UTC  }],Message:,Reason:,HostIP:10.1.161.42,PodIP:10.2.4.87,StartTime:2019-08-16 13:37:55 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-08-16 13:37:56 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://bcd515362044cd55a7a0ce07d9ebe913ed2a802659879f8d75acaaf4fb2070ba}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:37:58.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-bt6rv" for this suite.
Aug 16 13:38:04.031: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:38:04.123: INFO: namespace: e2e-tests-deployment-bt6rv, resource: bindings, ignored listing per whitelist
Aug 16 13:38:04.151: INFO: namespace e2e-tests-deployment-bt6rv deletion completed in 6.132494148s

• [SLOW TEST:13.235 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:38:04.151: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-12bd4bf9-c02b-11e9-99f6-8a077000b195
STEP: Creating a pod to test consume configMaps
Aug 16 13:38:04.226: INFO: Waiting up to 5m0s for pod "pod-configmaps-12bea990-c02b-11e9-99f6-8a077000b195" in namespace "e2e-tests-configmap-94wxq" to be "success or failure"
Aug 16 13:38:04.240: INFO: Pod "pod-configmaps-12bea990-c02b-11e9-99f6-8a077000b195": Phase="Pending", Reason="", readiness=false. Elapsed: 14.207084ms
Aug 16 13:38:06.244: INFO: Pod "pod-configmaps-12bea990-c02b-11e9-99f6-8a077000b195": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017948057s
STEP: Saw pod success
Aug 16 13:38:06.244: INFO: Pod "pod-configmaps-12bea990-c02b-11e9-99f6-8a077000b195" satisfied condition "success or failure"
Aug 16 13:38:06.247: INFO: Trying to get logs from node worker-eab92000-c026-11e9-bfed-069795ba99e0 pod pod-configmaps-12bea990-c02b-11e9-99f6-8a077000b195 container configmap-volume-test: <nil>
STEP: delete the pod
Aug 16 13:38:06.270: INFO: Waiting for pod pod-configmaps-12bea990-c02b-11e9-99f6-8a077000b195 to disappear
Aug 16 13:38:06.275: INFO: Pod pod-configmaps-12bea990-c02b-11e9-99f6-8a077000b195 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:38:06.275: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-94wxq" for this suite.
Aug 16 13:38:12.300: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:38:12.386: INFO: namespace: e2e-tests-configmap-94wxq, resource: bindings, ignored listing per whitelist
Aug 16 13:38:12.408: INFO: namespace e2e-tests-configmap-94wxq deletion completed in 6.129327808s

• [SLOW TEST:8.257 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:38:12.408: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug 16 13:38:12.506: INFO: Creating ReplicaSet my-hostname-basic-17b04c32-c02b-11e9-99f6-8a077000b195
Aug 16 13:38:12.515: INFO: Pod name my-hostname-basic-17b04c32-c02b-11e9-99f6-8a077000b195: Found 0 pods out of 1
Aug 16 13:38:17.519: INFO: Pod name my-hostname-basic-17b04c32-c02b-11e9-99f6-8a077000b195: Found 1 pods out of 1
Aug 16 13:38:17.519: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-17b04c32-c02b-11e9-99f6-8a077000b195" is running
Aug 16 13:38:17.523: INFO: Pod "my-hostname-basic-17b04c32-c02b-11e9-99f6-8a077000b195-nvdzc" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-16 13:38:12 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-16 13:38:14 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-16 13:38:14 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-16 13:38:12 +0000 UTC Reason: Message:}])
Aug 16 13:38:17.523: INFO: Trying to dial the pod
Aug 16 13:38:22.540: INFO: Controller my-hostname-basic-17b04c32-c02b-11e9-99f6-8a077000b195: Got expected result from replica 1 [my-hostname-basic-17b04c32-c02b-11e9-99f6-8a077000b195-nvdzc]: "my-hostname-basic-17b04c32-c02b-11e9-99f6-8a077000b195-nvdzc", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:38:22.540: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-dcbzm" for this suite.
Aug 16 13:38:28.558: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:38:28.578: INFO: namespace: e2e-tests-replicaset-dcbzm, resource: bindings, ignored listing per whitelist
Aug 16 13:38:28.666: INFO: namespace e2e-tests-replicaset-dcbzm deletion completed in 6.121710356s

• [SLOW TEST:16.258 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:38:28.666: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug 16 13:38:28.724: INFO: Waiting up to 5m0s for pod "downwardapi-volume-21597289-c02b-11e9-99f6-8a077000b195" in namespace "e2e-tests-downward-api-cpkkt" to be "success or failure"
Aug 16 13:38:28.727: INFO: Pod "downwardapi-volume-21597289-c02b-11e9-99f6-8a077000b195": Phase="Pending", Reason="", readiness=false. Elapsed: 3.117172ms
Aug 16 13:38:30.731: INFO: Pod "downwardapi-volume-21597289-c02b-11e9-99f6-8a077000b195": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006853385s
STEP: Saw pod success
Aug 16 13:38:30.731: INFO: Pod "downwardapi-volume-21597289-c02b-11e9-99f6-8a077000b195" satisfied condition "success or failure"
Aug 16 13:38:30.734: INFO: Trying to get logs from node worker-eab92000-c026-11e9-bfed-069795ba99e0 pod downwardapi-volume-21597289-c02b-11e9-99f6-8a077000b195 container client-container: <nil>
STEP: delete the pod
Aug 16 13:38:30.756: INFO: Waiting for pod downwardapi-volume-21597289-c02b-11e9-99f6-8a077000b195 to disappear
Aug 16 13:38:30.764: INFO: Pod downwardapi-volume-21597289-c02b-11e9-99f6-8a077000b195 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:38:30.764: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-cpkkt" for this suite.
Aug 16 13:38:36.781: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:38:36.832: INFO: namespace: e2e-tests-downward-api-cpkkt, resource: bindings, ignored listing per whitelist
Aug 16 13:38:36.895: INFO: namespace e2e-tests-downward-api-cpkkt deletion completed in 6.1277165s

• [SLOW TEST:8.229 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:38:36.896: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-qnbc
STEP: Creating a pod to test atomic-volume-subpath
Aug 16 13:38:36.959: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-qnbc" in namespace "e2e-tests-subpath-v5lx5" to be "success or failure"
Aug 16 13:38:36.968: INFO: Pod "pod-subpath-test-secret-qnbc": Phase="Pending", Reason="", readiness=false. Elapsed: 8.320671ms
Aug 16 13:38:38.972: INFO: Pod "pod-subpath-test-secret-qnbc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012646516s
Aug 16 13:38:40.976: INFO: Pod "pod-subpath-test-secret-qnbc": Phase="Running", Reason="", readiness=false. Elapsed: 4.016524581s
Aug 16 13:38:42.986: INFO: Pod "pod-subpath-test-secret-qnbc": Phase="Running", Reason="", readiness=false. Elapsed: 6.026976098s
Aug 16 13:38:44.990: INFO: Pod "pod-subpath-test-secret-qnbc": Phase="Running", Reason="", readiness=false. Elapsed: 8.030733337s
Aug 16 13:38:46.994: INFO: Pod "pod-subpath-test-secret-qnbc": Phase="Running", Reason="", readiness=false. Elapsed: 10.034278663s
Aug 16 13:38:48.997: INFO: Pod "pod-subpath-test-secret-qnbc": Phase="Running", Reason="", readiness=false. Elapsed: 12.037961815s
Aug 16 13:38:51.001: INFO: Pod "pod-subpath-test-secret-qnbc": Phase="Running", Reason="", readiness=false. Elapsed: 14.041648214s
Aug 16 13:38:53.011: INFO: Pod "pod-subpath-test-secret-qnbc": Phase="Running", Reason="", readiness=false. Elapsed: 16.051861363s
Aug 16 13:38:55.015: INFO: Pod "pod-subpath-test-secret-qnbc": Phase="Running", Reason="", readiness=false. Elapsed: 18.055597186s
Aug 16 13:38:57.019: INFO: Pod "pod-subpath-test-secret-qnbc": Phase="Running", Reason="", readiness=false. Elapsed: 20.05998528s
Aug 16 13:38:59.023: INFO: Pod "pod-subpath-test-secret-qnbc": Phase="Running", Reason="", readiness=false. Elapsed: 22.063595915s
Aug 16 13:39:01.027: INFO: Pod "pod-subpath-test-secret-qnbc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.067305915s
STEP: Saw pod success
Aug 16 13:39:01.027: INFO: Pod "pod-subpath-test-secret-qnbc" satisfied condition "success or failure"
Aug 16 13:39:01.030: INFO: Trying to get logs from node worker-eab92000-c026-11e9-bfed-069795ba99e0 pod pod-subpath-test-secret-qnbc container test-container-subpath-secret-qnbc: <nil>
STEP: delete the pod
Aug 16 13:39:01.061: INFO: Waiting for pod pod-subpath-test-secret-qnbc to disappear
Aug 16 13:39:01.064: INFO: Pod pod-subpath-test-secret-qnbc no longer exists
STEP: Deleting pod pod-subpath-test-secret-qnbc
Aug 16 13:39:01.064: INFO: Deleting pod "pod-subpath-test-secret-qnbc" in namespace "e2e-tests-subpath-v5lx5"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:39:01.067: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-v5lx5" for this suite.
Aug 16 13:39:07.086: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:39:07.195: INFO: namespace: e2e-tests-subpath-v5lx5, resource: bindings, ignored listing per whitelist
Aug 16 13:39:07.198: INFO: namespace e2e-tests-subpath-v5lx5 deletion completed in 6.126994353s

• [SLOW TEST:30.303 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:39:07.198: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-385335a4-c02b-11e9-99f6-8a077000b195
STEP: Creating a pod to test consume configMaps
Aug 16 13:39:07.273: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-3853ce47-c02b-11e9-99f6-8a077000b195" in namespace "e2e-tests-projected-kxl44" to be "success or failure"
Aug 16 13:39:07.278: INFO: Pod "pod-projected-configmaps-3853ce47-c02b-11e9-99f6-8a077000b195": Phase="Pending", Reason="", readiness=false. Elapsed: 5.09515ms
Aug 16 13:39:09.282: INFO: Pod "pod-projected-configmaps-3853ce47-c02b-11e9-99f6-8a077000b195": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009105255s
STEP: Saw pod success
Aug 16 13:39:09.282: INFO: Pod "pod-projected-configmaps-3853ce47-c02b-11e9-99f6-8a077000b195" satisfied condition "success or failure"
Aug 16 13:39:09.285: INFO: Trying to get logs from node worker-eab92000-c026-11e9-bfed-069795ba99e0 pod pod-projected-configmaps-3853ce47-c02b-11e9-99f6-8a077000b195 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 16 13:39:09.310: INFO: Waiting for pod pod-projected-configmaps-3853ce47-c02b-11e9-99f6-8a077000b195 to disappear
Aug 16 13:39:09.317: INFO: Pod pod-projected-configmaps-3853ce47-c02b-11e9-99f6-8a077000b195 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:39:09.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-kxl44" for this suite.
Aug 16 13:39:15.334: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:39:15.387: INFO: namespace: e2e-tests-projected-kxl44, resource: bindings, ignored listing per whitelist
Aug 16 13:39:15.443: INFO: namespace e2e-tests-projected-kxl44 deletion completed in 6.122215736s

• [SLOW TEST:8.245 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:39:15.443: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1134
STEP: creating an rc
Aug 16 13:39:15.493: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 create -f - --namespace=e2e-tests-kubectl-xx2f2'
Aug 16 13:39:15.617: INFO: stderr: ""
Aug 16 13:39:15.617: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
Aug 16 13:39:16.621: INFO: Selector matched 1 pods for map[app:redis]
Aug 16 13:39:16.621: INFO: Found 0 / 1
Aug 16 13:39:17.621: INFO: Selector matched 1 pods for map[app:redis]
Aug 16 13:39:17.621: INFO: Found 1 / 1
Aug 16 13:39:17.621: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Aug 16 13:39:17.624: INFO: Selector matched 1 pods for map[app:redis]
Aug 16 13:39:17.624: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Aug 16 13:39:17.624: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 logs redis-master-np54h redis-master --namespace=e2e-tests-kubectl-xx2f2'
Aug 16 13:39:17.694: INFO: stderr: ""
Aug 16 13:39:17.694: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 16 Aug 13:39:16.428 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 16 Aug 13:39:16.429 # Server started, Redis version 3.2.12\n1:M 16 Aug 13:39:16.429 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 16 Aug 13:39:16.429 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Aug 16 13:39:17.694: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 log redis-master-np54h redis-master --namespace=e2e-tests-kubectl-xx2f2 --tail=1'
Aug 16 13:39:17.762: INFO: stderr: ""
Aug 16 13:39:17.762: INFO: stdout: "1:M 16 Aug 13:39:16.429 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Aug 16 13:39:17.762: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 log redis-master-np54h redis-master --namespace=e2e-tests-kubectl-xx2f2 --limit-bytes=1'
Aug 16 13:39:17.827: INFO: stderr: ""
Aug 16 13:39:17.827: INFO: stdout: " "
STEP: exposing timestamps
Aug 16 13:39:17.827: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 log redis-master-np54h redis-master --namespace=e2e-tests-kubectl-xx2f2 --tail=1 --timestamps'
Aug 16 13:39:17.893: INFO: stderr: ""
Aug 16 13:39:17.893: INFO: stdout: "2019-08-16T13:39:16.431132453Z 1:M 16 Aug 13:39:16.429 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Aug 16 13:39:20.393: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 log redis-master-np54h redis-master --namespace=e2e-tests-kubectl-xx2f2 --since=1s'
Aug 16 13:39:20.476: INFO: stderr: ""
Aug 16 13:39:20.476: INFO: stdout: ""
Aug 16 13:39:20.476: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 log redis-master-np54h redis-master --namespace=e2e-tests-kubectl-xx2f2 --since=24h'
Aug 16 13:39:20.548: INFO: stderr: ""
Aug 16 13:39:20.548: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 16 Aug 13:39:16.428 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 16 Aug 13:39:16.429 # Server started, Redis version 3.2.12\n1:M 16 Aug 13:39:16.429 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 16 Aug 13:39:16.429 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1140
STEP: using delete to clean up resources
Aug 16 13:39:20.549: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-xx2f2'
Aug 16 13:39:20.612: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 16 13:39:20.612: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Aug 16 13:39:20.612: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-xx2f2'
Aug 16 13:39:20.676: INFO: stderr: "No resources found.\n"
Aug 16 13:39:20.676: INFO: stdout: ""
Aug 16 13:39:20.676: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 get pods -l name=nginx --namespace=e2e-tests-kubectl-xx2f2 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug 16 13:39:20.730: INFO: stderr: ""
Aug 16 13:39:20.731: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:39:20.731: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-xx2f2" for this suite.
Aug 16 13:39:26.748: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:39:26.842: INFO: namespace: e2e-tests-kubectl-xx2f2, resource: bindings, ignored listing per whitelist
Aug 16 13:39:26.856: INFO: namespace e2e-tests-kubectl-xx2f2 deletion completed in 6.12114377s

• [SLOW TEST:11.413 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:39:26.856: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug 16 13:39:26.903: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:39:28.934: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-xd9sh" for this suite.
Aug 16 13:40:14.956: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:40:15.055: INFO: namespace: e2e-tests-pods-xd9sh, resource: bindings, ignored listing per whitelist
Aug 16 13:40:15.071: INFO: namespace e2e-tests-pods-xd9sh deletion completed in 46.133523687s

• [SLOW TEST:48.215 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:40:15.072: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:40:21.233: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-jqjt8" for this suite.
Aug 16 13:40:27.250: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:40:27.299: INFO: namespace: e2e-tests-namespaces-jqjt8, resource: bindings, ignored listing per whitelist
Aug 16 13:40:27.363: INFO: namespace e2e-tests-namespaces-jqjt8 deletion completed in 6.125851544s
STEP: Destroying namespace "e2e-tests-nsdeletetest-lg5kx" for this suite.
Aug 16 13:40:27.366: INFO: Namespace e2e-tests-nsdeletetest-lg5kx was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-c49dn" for this suite.
Aug 16 13:40:33.379: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:40:33.485: INFO: namespace: e2e-tests-nsdeletetest-c49dn, resource: bindings, ignored listing per whitelist
Aug 16 13:40:33.491: INFO: namespace e2e-tests-nsdeletetest-c49dn deletion completed in 6.125034575s

• [SLOW TEST:18.419 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:40:33.491: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug 16 13:40:33.549: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6bc09e96-c02b-11e9-99f6-8a077000b195" in namespace "e2e-tests-projected-5tn2b" to be "success or failure"
Aug 16 13:40:33.554: INFO: Pod "downwardapi-volume-6bc09e96-c02b-11e9-99f6-8a077000b195": Phase="Pending", Reason="", readiness=false. Elapsed: 4.838912ms
Aug 16 13:40:35.558: INFO: Pod "downwardapi-volume-6bc09e96-c02b-11e9-99f6-8a077000b195": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008688485s
STEP: Saw pod success
Aug 16 13:40:35.558: INFO: Pod "downwardapi-volume-6bc09e96-c02b-11e9-99f6-8a077000b195" satisfied condition "success or failure"
Aug 16 13:40:35.561: INFO: Trying to get logs from node worker-eab92000-c026-11e9-bfed-069795ba99e0 pod downwardapi-volume-6bc09e96-c02b-11e9-99f6-8a077000b195 container client-container: <nil>
STEP: delete the pod
Aug 16 13:40:35.586: INFO: Waiting for pod downwardapi-volume-6bc09e96-c02b-11e9-99f6-8a077000b195 to disappear
Aug 16 13:40:35.593: INFO: Pod downwardapi-volume-6bc09e96-c02b-11e9-99f6-8a077000b195 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:40:35.593: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-5tn2b" for this suite.
Aug 16 13:40:41.620: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:40:41.697: INFO: namespace: e2e-tests-projected-5tn2b, resource: bindings, ignored listing per whitelist
Aug 16 13:40:41.740: INFO: namespace e2e-tests-projected-5tn2b deletion completed in 6.142848868s

• [SLOW TEST:8.248 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:40:41.740: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Aug 16 13:40:41.795: INFO: Waiting up to 5m0s for pod "pod-70aabd85-c02b-11e9-99f6-8a077000b195" in namespace "e2e-tests-emptydir-xjdp6" to be "success or failure"
Aug 16 13:40:41.798: INFO: Pod "pod-70aabd85-c02b-11e9-99f6-8a077000b195": Phase="Pending", Reason="", readiness=false. Elapsed: 3.458385ms
Aug 16 13:40:43.802: INFO: Pod "pod-70aabd85-c02b-11e9-99f6-8a077000b195": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00703427s
STEP: Saw pod success
Aug 16 13:40:43.802: INFO: Pod "pod-70aabd85-c02b-11e9-99f6-8a077000b195" satisfied condition "success or failure"
Aug 16 13:40:43.805: INFO: Trying to get logs from node worker-eab92000-c026-11e9-bfed-069795ba99e0 pod pod-70aabd85-c02b-11e9-99f6-8a077000b195 container test-container: <nil>
STEP: delete the pod
Aug 16 13:40:43.829: INFO: Waiting for pod pod-70aabd85-c02b-11e9-99f6-8a077000b195 to disappear
Aug 16 13:40:43.834: INFO: Pod pod-70aabd85-c02b-11e9-99f6-8a077000b195 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:40:43.835: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-xjdp6" for this suite.
Aug 16 13:40:49.852: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:40:49.891: INFO: namespace: e2e-tests-emptydir-xjdp6, resource: bindings, ignored listing per whitelist
Aug 16 13:40:49.973: INFO: namespace e2e-tests-emptydir-xjdp6 deletion completed in 6.133944089s

• [SLOW TEST:8.233 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:40:49.973: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
Aug 16 13:40:50.020: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 api-versions'
Aug 16 13:40:50.077: INFO: stderr: ""
Aug 16 13:40:50.077: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1beta1\ncrd.projectcalico.org/v1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\nvke.vmware.com/v1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:40:50.077: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-l8dmg" for this suite.
Aug 16 13:40:56.096: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:40:56.185: INFO: namespace: e2e-tests-kubectl-l8dmg, resource: bindings, ignored listing per whitelist
Aug 16 13:40:56.208: INFO: namespace e2e-tests-kubectl-l8dmg deletion completed in 6.126330086s

• [SLOW TEST:6.235 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:40:56.208: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug 16 13:40:56.327: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7953e4aa-c02b-11e9-99f6-8a077000b195" in namespace "e2e-tests-projected-gn5lq" to be "success or failure"
Aug 16 13:40:56.339: INFO: Pod "downwardapi-volume-7953e4aa-c02b-11e9-99f6-8a077000b195": Phase="Pending", Reason="", readiness=false. Elapsed: 11.676177ms
Aug 16 13:40:58.343: INFO: Pod "downwardapi-volume-7953e4aa-c02b-11e9-99f6-8a077000b195": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015652448s
STEP: Saw pod success
Aug 16 13:40:58.343: INFO: Pod "downwardapi-volume-7953e4aa-c02b-11e9-99f6-8a077000b195" satisfied condition "success or failure"
Aug 16 13:40:58.347: INFO: Trying to get logs from node worker-eab92000-c026-11e9-bfed-069795ba99e0 pod downwardapi-volume-7953e4aa-c02b-11e9-99f6-8a077000b195 container client-container: <nil>
STEP: delete the pod
Aug 16 13:40:58.369: INFO: Waiting for pod downwardapi-volume-7953e4aa-c02b-11e9-99f6-8a077000b195 to disappear
Aug 16 13:40:58.375: INFO: Pod downwardapi-volume-7953e4aa-c02b-11e9-99f6-8a077000b195 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:40:58.375: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-gn5lq" for this suite.
Aug 16 13:41:04.392: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:41:04.486: INFO: namespace: e2e-tests-projected-gn5lq, resource: bindings, ignored listing per whitelist
Aug 16 13:41:04.510: INFO: namespace e2e-tests-projected-gn5lq deletion completed in 6.130340869s

• [SLOW TEST:8.301 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:41:04.510: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-7e3e9fc6-c02b-11e9-99f6-8a077000b195
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-7e3e9fc6-c02b-11e9-99f6-8a077000b195
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:41:08.619: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-flpm7" for this suite.
Aug 16 13:41:30.637: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:41:30.673: INFO: namespace: e2e-tests-projected-flpm7, resource: bindings, ignored listing per whitelist
Aug 16 13:41:30.744: INFO: namespace e2e-tests-projected-flpm7 deletion completed in 22.121264613s

• [SLOW TEST:26.234 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:41:30.744: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-8de08bcc-c02b-11e9-99f6-8a077000b195
STEP: Creating a pod to test consume secrets
Aug 16 13:41:30.806: INFO: Waiting up to 5m0s for pod "pod-secrets-8de12c28-c02b-11e9-99f6-8a077000b195" in namespace "e2e-tests-secrets-fkrsr" to be "success or failure"
Aug 16 13:41:30.812: INFO: Pod "pod-secrets-8de12c28-c02b-11e9-99f6-8a077000b195": Phase="Pending", Reason="", readiness=false. Elapsed: 5.686897ms
Aug 16 13:41:32.815: INFO: Pod "pod-secrets-8de12c28-c02b-11e9-99f6-8a077000b195": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009375632s
STEP: Saw pod success
Aug 16 13:41:32.815: INFO: Pod "pod-secrets-8de12c28-c02b-11e9-99f6-8a077000b195" satisfied condition "success or failure"
Aug 16 13:41:32.818: INFO: Trying to get logs from node worker-eab92000-c026-11e9-bfed-069795ba99e0 pod pod-secrets-8de12c28-c02b-11e9-99f6-8a077000b195 container secret-volume-test: <nil>
STEP: delete the pod
Aug 16 13:41:32.849: INFO: Waiting for pod pod-secrets-8de12c28-c02b-11e9-99f6-8a077000b195 to disappear
Aug 16 13:41:32.852: INFO: Pod pod-secrets-8de12c28-c02b-11e9-99f6-8a077000b195 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:41:32.852: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-fkrsr" for this suite.
Aug 16 13:41:38.869: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:41:38.924: INFO: namespace: e2e-tests-secrets-fkrsr, resource: bindings, ignored listing per whitelist
Aug 16 13:41:38.977: INFO: namespace e2e-tests-secrets-fkrsr deletion completed in 6.121803075s

• [SLOW TEST:8.233 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:41:38.977: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Aug 16 13:41:39.029: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Aug 16 13:41:39.038: INFO: Waiting for terminating namespaces to be deleted...
Aug 16 13:41:39.041: INFO: 
Logging pods the kubelet thinks is on node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 before test
Aug 16 13:41:39.046: INFO: sonobuoy-e2e-job-09d0aca292374f31 from sonobuoy started at 2019-08-16 13:07:46 +0000 UTC (2 container statuses recorded)
Aug 16 13:41:39.046: INFO: 	Container e2e ready: true, restart count 0
Aug 16 13:41:39.046: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 16 13:41:39.046: INFO: canal-node-1-13-6-6x8bh from vke-system started at 2019-08-16 13:07:21 +0000 UTC (3 container statuses recorded)
Aug 16 13:41:39.046: INFO: 	Container calico-node ready: true, restart count 0
Aug 16 13:41:39.046: INFO: 	Container flannel ready: true, restart count 0
Aug 16 13:41:39.046: INFO: 	Container install-calico-cni ready: true, restart count 0
Aug 16 13:41:39.046: INFO: sonobuoy from sonobuoy started at 2019-08-16 13:07:41 +0000 UTC (1 container statuses recorded)
Aug 16 13:41:39.046: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Aug 16 13:41:39.046: INFO: 
Logging pods the kubelet thinks is on node worker-eab92000-c026-11e9-bfed-069795ba99e0 before test
Aug 16 13:41:39.050: INFO: canal-node-1-13-6-4z9rh from vke-system started at 2019-08-16 13:10:22 +0000 UTC (3 container statuses recorded)
Aug 16 13:41:39.050: INFO: 	Container calico-node ready: true, restart count 0
Aug 16 13:41:39.050: INFO: 	Container flannel ready: true, restart count 0
Aug 16 13:41:39.050: INFO: 	Container install-calico-cni ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-94032188-c02b-11e9-99f6-8a077000b195 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-94032188-c02b-11e9-99f6-8a077000b195 off the node worker-eab92000-c026-11e9-bfed-069795ba99e0
STEP: verifying the node doesn't have the label kubernetes.io/e2e-94032188-c02b-11e9-99f6-8a077000b195
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:41:43.136: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-ms5dp" for this suite.
Aug 16 13:41:51.153: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:41:51.185: INFO: namespace: e2e-tests-sched-pred-ms5dp, resource: bindings, ignored listing per whitelist
Aug 16 13:41:51.269: INFO: namespace e2e-tests-sched-pred-ms5dp deletion completed in 8.130174372s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:12.292 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:41:51.269: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Aug 16 13:41:51.330: INFO: Waiting up to 5m0s for pod "pod-9a1ce5d8-c02b-11e9-99f6-8a077000b195" in namespace "e2e-tests-emptydir-bnk7c" to be "success or failure"
Aug 16 13:41:51.338: INFO: Pod "pod-9a1ce5d8-c02b-11e9-99f6-8a077000b195": Phase="Pending", Reason="", readiness=false. Elapsed: 8.269547ms
Aug 16 13:41:53.342: INFO: Pod "pod-9a1ce5d8-c02b-11e9-99f6-8a077000b195": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011880251s
STEP: Saw pod success
Aug 16 13:41:53.342: INFO: Pod "pod-9a1ce5d8-c02b-11e9-99f6-8a077000b195" satisfied condition "success or failure"
Aug 16 13:41:53.345: INFO: Trying to get logs from node worker-eab92000-c026-11e9-bfed-069795ba99e0 pod pod-9a1ce5d8-c02b-11e9-99f6-8a077000b195 container test-container: <nil>
STEP: delete the pod
Aug 16 13:41:53.371: INFO: Waiting for pod pod-9a1ce5d8-c02b-11e9-99f6-8a077000b195 to disappear
Aug 16 13:41:53.376: INFO: Pod pod-9a1ce5d8-c02b-11e9-99f6-8a077000b195 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:41:53.376: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-bnk7c" for this suite.
Aug 16 13:41:59.394: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:41:59.496: INFO: namespace: e2e-tests-emptydir-bnk7c, resource: bindings, ignored listing per whitelist
Aug 16 13:41:59.501: INFO: namespace e2e-tests-emptydir-bnk7c deletion completed in 6.121149767s

• [SLOW TEST:8.232 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:41:59.502: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-jvs5
STEP: Creating a pod to test atomic-volume-subpath
Aug 16 13:41:59.570: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-jvs5" in namespace "e2e-tests-subpath-5gsqz" to be "success or failure"
Aug 16 13:41:59.577: INFO: Pod "pod-subpath-test-configmap-jvs5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.875884ms
Aug 16 13:42:01.582: INFO: Pod "pod-subpath-test-configmap-jvs5": Phase="Running", Reason="", readiness=false. Elapsed: 2.012642688s
Aug 16 13:42:03.586: INFO: Pod "pod-subpath-test-configmap-jvs5": Phase="Running", Reason="", readiness=false. Elapsed: 4.016503549s
Aug 16 13:42:05.597: INFO: Pod "pod-subpath-test-configmap-jvs5": Phase="Running", Reason="", readiness=false. Elapsed: 6.026795246s
Aug 16 13:42:07.600: INFO: Pod "pod-subpath-test-configmap-jvs5": Phase="Running", Reason="", readiness=false. Elapsed: 8.030489415s
Aug 16 13:42:09.604: INFO: Pod "pod-subpath-test-configmap-jvs5": Phase="Running", Reason="", readiness=false. Elapsed: 10.03412896s
Aug 16 13:42:11.608: INFO: Pod "pod-subpath-test-configmap-jvs5": Phase="Running", Reason="", readiness=false. Elapsed: 12.037933081s
Aug 16 13:42:13.611: INFO: Pod "pod-subpath-test-configmap-jvs5": Phase="Running", Reason="", readiness=false. Elapsed: 14.041697459s
Aug 16 13:42:15.622: INFO: Pod "pod-subpath-test-configmap-jvs5": Phase="Running", Reason="", readiness=false. Elapsed: 16.05183069s
Aug 16 13:42:17.625: INFO: Pod "pod-subpath-test-configmap-jvs5": Phase="Running", Reason="", readiness=false. Elapsed: 18.055576243s
Aug 16 13:42:19.629: INFO: Pod "pod-subpath-test-configmap-jvs5": Phase="Running", Reason="", readiness=false. Elapsed: 20.059441252s
Aug 16 13:42:21.633: INFO: Pod "pod-subpath-test-configmap-jvs5": Phase="Running", Reason="", readiness=false. Elapsed: 22.063472102s
Aug 16 13:42:23.637: INFO: Pod "pod-subpath-test-configmap-jvs5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.067621288s
STEP: Saw pod success
Aug 16 13:42:23.637: INFO: Pod "pod-subpath-test-configmap-jvs5" satisfied condition "success or failure"
Aug 16 13:42:23.641: INFO: Trying to get logs from node worker-eab92000-c026-11e9-bfed-069795ba99e0 pod pod-subpath-test-configmap-jvs5 container test-container-subpath-configmap-jvs5: <nil>
STEP: delete the pod
Aug 16 13:42:23.672: INFO: Waiting for pod pod-subpath-test-configmap-jvs5 to disappear
Aug 16 13:42:23.678: INFO: Pod pod-subpath-test-configmap-jvs5 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-jvs5
Aug 16 13:42:23.678: INFO: Deleting pod "pod-subpath-test-configmap-jvs5" in namespace "e2e-tests-subpath-5gsqz"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:42:23.681: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-5gsqz" for this suite.
Aug 16 13:42:29.706: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:42:29.773: INFO: namespace: e2e-tests-subpath-5gsqz, resource: bindings, ignored listing per whitelist
Aug 16 13:42:29.815: INFO: namespace e2e-tests-subpath-5gsqz deletion completed in 6.130093059s

• [SLOW TEST:30.313 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:42:29.815: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-b1160eac-c02b-11e9-99f6-8a077000b195
STEP: Creating a pod to test consume secrets
Aug 16 13:42:29.878: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-b116c15c-c02b-11e9-99f6-8a077000b195" in namespace "e2e-tests-projected-b89ft" to be "success or failure"
Aug 16 13:42:29.882: INFO: Pod "pod-projected-secrets-b116c15c-c02b-11e9-99f6-8a077000b195": Phase="Pending", Reason="", readiness=false. Elapsed: 3.699837ms
Aug 16 13:42:31.886: INFO: Pod "pod-projected-secrets-b116c15c-c02b-11e9-99f6-8a077000b195": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007400718s
STEP: Saw pod success
Aug 16 13:42:31.886: INFO: Pod "pod-projected-secrets-b116c15c-c02b-11e9-99f6-8a077000b195" satisfied condition "success or failure"
Aug 16 13:42:31.889: INFO: Trying to get logs from node worker-eab92000-c026-11e9-bfed-069795ba99e0 pod pod-projected-secrets-b116c15c-c02b-11e9-99f6-8a077000b195 container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug 16 13:42:31.924: INFO: Waiting for pod pod-projected-secrets-b116c15c-c02b-11e9-99f6-8a077000b195 to disappear
Aug 16 13:42:31.927: INFO: Pod pod-projected-secrets-b116c15c-c02b-11e9-99f6-8a077000b195 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:42:31.927: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-b89ft" for this suite.
Aug 16 13:42:37.945: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:42:38.004: INFO: namespace: e2e-tests-projected-b89ft, resource: bindings, ignored listing per whitelist
Aug 16 13:42:38.067: INFO: namespace e2e-tests-projected-b89ft deletion completed in 6.13559027s

• [SLOW TEST:8.252 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:42:38.067: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-b600ee4b-c02b-11e9-99f6-8a077000b195
STEP: Creating a pod to test consume configMaps
Aug 16 13:42:38.128: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-b60180e2-c02b-11e9-99f6-8a077000b195" in namespace "e2e-tests-projected-chrx6" to be "success or failure"
Aug 16 13:42:38.133: INFO: Pod "pod-projected-configmaps-b60180e2-c02b-11e9-99f6-8a077000b195": Phase="Pending", Reason="", readiness=false. Elapsed: 4.886986ms
Aug 16 13:42:40.144: INFO: Pod "pod-projected-configmaps-b60180e2-c02b-11e9-99f6-8a077000b195": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015191112s
STEP: Saw pod success
Aug 16 13:42:40.144: INFO: Pod "pod-projected-configmaps-b60180e2-c02b-11e9-99f6-8a077000b195" satisfied condition "success or failure"
Aug 16 13:42:40.147: INFO: Trying to get logs from node worker-eab92000-c026-11e9-bfed-069795ba99e0 pod pod-projected-configmaps-b60180e2-c02b-11e9-99f6-8a077000b195 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 16 13:42:40.178: INFO: Waiting for pod pod-projected-configmaps-b60180e2-c02b-11e9-99f6-8a077000b195 to disappear
Aug 16 13:42:40.183: INFO: Pod pod-projected-configmaps-b60180e2-c02b-11e9-99f6-8a077000b195 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:42:40.183: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-chrx6" for this suite.
Aug 16 13:42:46.209: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:42:46.293: INFO: namespace: e2e-tests-projected-chrx6, resource: bindings, ignored listing per whitelist
Aug 16 13:42:46.318: INFO: namespace e2e-tests-projected-chrx6 deletion completed in 6.130560399s

• [SLOW TEST:8.251 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:42:46.320: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Aug 16 13:42:46.376: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-ktd7t,SelfLink:/api/v1/namespaces/e2e-tests-watch-ktd7t/configmaps/e2e-watch-test-configmap-a,UID:bae71a51-c02b-11e9-ae7d-02d5aa9cbbca,ResourceVersion:25571,Generation:0,CreationTimestamp:2019-08-16 13:42:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Aug 16 13:42:46.376: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-ktd7t,SelfLink:/api/v1/namespaces/e2e-tests-watch-ktd7t/configmaps/e2e-watch-test-configmap-a,UID:bae71a51-c02b-11e9-ae7d-02d5aa9cbbca,ResourceVersion:25571,Generation:0,CreationTimestamp:2019-08-16 13:42:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Aug 16 13:42:56.390: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-ktd7t,SelfLink:/api/v1/namespaces/e2e-tests-watch-ktd7t/configmaps/e2e-watch-test-configmap-a,UID:bae71a51-c02b-11e9-ae7d-02d5aa9cbbca,ResourceVersion:25606,Generation:0,CreationTimestamp:2019-08-16 13:42:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Aug 16 13:42:56.390: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-ktd7t,SelfLink:/api/v1/namespaces/e2e-tests-watch-ktd7t/configmaps/e2e-watch-test-configmap-a,UID:bae71a51-c02b-11e9-ae7d-02d5aa9cbbca,ResourceVersion:25606,Generation:0,CreationTimestamp:2019-08-16 13:42:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Aug 16 13:43:06.405: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-ktd7t,SelfLink:/api/v1/namespaces/e2e-tests-watch-ktd7t/configmaps/e2e-watch-test-configmap-a,UID:bae71a51-c02b-11e9-ae7d-02d5aa9cbbca,ResourceVersion:25641,Generation:0,CreationTimestamp:2019-08-16 13:42:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Aug 16 13:43:06.405: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-ktd7t,SelfLink:/api/v1/namespaces/e2e-tests-watch-ktd7t/configmaps/e2e-watch-test-configmap-a,UID:bae71a51-c02b-11e9-ae7d-02d5aa9cbbca,ResourceVersion:25641,Generation:0,CreationTimestamp:2019-08-16 13:42:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Aug 16 13:43:16.422: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-ktd7t,SelfLink:/api/v1/namespaces/e2e-tests-watch-ktd7t/configmaps/e2e-watch-test-configmap-a,UID:bae71a51-c02b-11e9-ae7d-02d5aa9cbbca,ResourceVersion:25676,Generation:0,CreationTimestamp:2019-08-16 13:42:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Aug 16 13:43:16.422: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-ktd7t,SelfLink:/api/v1/namespaces/e2e-tests-watch-ktd7t/configmaps/e2e-watch-test-configmap-a,UID:bae71a51-c02b-11e9-ae7d-02d5aa9cbbca,ResourceVersion:25676,Generation:0,CreationTimestamp:2019-08-16 13:42:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Aug 16 13:43:26.436: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-ktd7t,SelfLink:/api/v1/namespaces/e2e-tests-watch-ktd7t/configmaps/e2e-watch-test-configmap-b,UID:d2c6ea01-c02b-11e9-ae7d-02d5aa9cbbca,ResourceVersion:25711,Generation:0,CreationTimestamp:2019-08-16 13:43:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Aug 16 13:43:26.437: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-ktd7t,SelfLink:/api/v1/namespaces/e2e-tests-watch-ktd7t/configmaps/e2e-watch-test-configmap-b,UID:d2c6ea01-c02b-11e9-ae7d-02d5aa9cbbca,ResourceVersion:25711,Generation:0,CreationTimestamp:2019-08-16 13:43:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Aug 16 13:43:36.452: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-ktd7t,SelfLink:/api/v1/namespaces/e2e-tests-watch-ktd7t/configmaps/e2e-watch-test-configmap-b,UID:d2c6ea01-c02b-11e9-ae7d-02d5aa9cbbca,ResourceVersion:25747,Generation:0,CreationTimestamp:2019-08-16 13:43:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Aug 16 13:43:36.452: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-ktd7t,SelfLink:/api/v1/namespaces/e2e-tests-watch-ktd7t/configmaps/e2e-watch-test-configmap-b,UID:d2c6ea01-c02b-11e9-ae7d-02d5aa9cbbca,ResourceVersion:25747,Generation:0,CreationTimestamp:2019-08-16 13:43:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:43:46.452: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-ktd7t" for this suite.
Aug 16 13:43:52.477: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:43:52.577: INFO: namespace: e2e-tests-watch-ktd7t, resource: bindings, ignored listing per whitelist
Aug 16 13:43:52.588: INFO: namespace e2e-tests-watch-ktd7t deletion completed in 6.124380031s

• [SLOW TEST:66.268 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:43:52.588: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Aug 16 13:43:54.666: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-e26c387b-c02b-11e9-99f6-8a077000b195", GenerateName:"", Namespace:"e2e-tests-pods-rl8sw", SelfLink:"/api/v1/namespaces/e2e-tests-pods-rl8sw/pods/pod-submit-remove-e26c387b-c02b-11e9-99f6-8a077000b195", UID:"e266a041-c02b-11e9-ae7d-02d5aa9cbbca", ResourceVersion:"25824", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63701559832, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"638071395"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"10.2.4.106/32"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-gnktn", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc001a11fc0), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-gnktn", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc000bab938), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"worker-eab92000-c026-11e9-bfed-069795ba99e0", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc000d16ae0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc000bab970)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc000bab990)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc000bab998), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc000bab99c)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701559832, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701559833, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701559833, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701559832, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.1.161.42", PodIP:"10.2.4.106", StartTime:(*v1.Time)(0xc00093c1e0), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc00093c220), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"nginx:1.14-alpine", ImageID:"docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7", ContainerID:"docker://eefb13a362058d87648c02b0f29a8730fcdc6da6015c18951bf0e8b941276f79"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:44:02.233: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-rl8sw" for this suite.
Aug 16 13:44:08.251: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:44:08.355: INFO: namespace: e2e-tests-pods-rl8sw, resource: bindings, ignored listing per whitelist
Aug 16 13:44:08.363: INFO: namespace e2e-tests-pods-rl8sw deletion completed in 6.125852629s

• [SLOW TEST:15.776 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:44:08.364: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-ebd35efa-c02b-11e9-99f6-8a077000b195
STEP: Creating a pod to test consume configMaps
Aug 16 13:44:08.426: INFO: Waiting up to 5m0s for pod "pod-configmaps-ebd40839-c02b-11e9-99f6-8a077000b195" in namespace "e2e-tests-configmap-868gw" to be "success or failure"
Aug 16 13:44:08.431: INFO: Pod "pod-configmaps-ebd40839-c02b-11e9-99f6-8a077000b195": Phase="Pending", Reason="", readiness=false. Elapsed: 5.315191ms
Aug 16 13:44:10.442: INFO: Pod "pod-configmaps-ebd40839-c02b-11e9-99f6-8a077000b195": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016380105s
STEP: Saw pod success
Aug 16 13:44:10.442: INFO: Pod "pod-configmaps-ebd40839-c02b-11e9-99f6-8a077000b195" satisfied condition "success or failure"
Aug 16 13:44:10.445: INFO: Trying to get logs from node worker-eab92000-c026-11e9-bfed-069795ba99e0 pod pod-configmaps-ebd40839-c02b-11e9-99f6-8a077000b195 container configmap-volume-test: <nil>
STEP: delete the pod
Aug 16 13:44:10.470: INFO: Waiting for pod pod-configmaps-ebd40839-c02b-11e9-99f6-8a077000b195 to disappear
Aug 16 13:44:10.475: INFO: Pod pod-configmaps-ebd40839-c02b-11e9-99f6-8a077000b195 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:44:10.475: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-868gw" for this suite.
Aug 16 13:44:16.494: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:44:16.517: INFO: namespace: e2e-tests-configmap-868gw, resource: bindings, ignored listing per whitelist
Aug 16 13:44:16.604: INFO: namespace e2e-tests-configmap-868gw deletion completed in 6.124628221s

• [SLOW TEST:8.240 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:44:16.605: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Aug 16 13:44:16.677: INFO: Waiting up to 5m0s for pod "downward-api-f0bf2104-c02b-11e9-99f6-8a077000b195" in namespace "e2e-tests-downward-api-69rhg" to be "success or failure"
Aug 16 13:44:16.681: INFO: Pod "downward-api-f0bf2104-c02b-11e9-99f6-8a077000b195": Phase="Pending", Reason="", readiness=false. Elapsed: 3.708155ms
Aug 16 13:44:18.685: INFO: Pod "downward-api-f0bf2104-c02b-11e9-99f6-8a077000b195": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007328325s
STEP: Saw pod success
Aug 16 13:44:18.685: INFO: Pod "downward-api-f0bf2104-c02b-11e9-99f6-8a077000b195" satisfied condition "success or failure"
Aug 16 13:44:18.688: INFO: Trying to get logs from node worker-eab92000-c026-11e9-bfed-069795ba99e0 pod downward-api-f0bf2104-c02b-11e9-99f6-8a077000b195 container dapi-container: <nil>
STEP: delete the pod
Aug 16 13:44:18.717: INFO: Waiting for pod downward-api-f0bf2104-c02b-11e9-99f6-8a077000b195 to disappear
Aug 16 13:44:18.722: INFO: Pod downward-api-f0bf2104-c02b-11e9-99f6-8a077000b195 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:44:18.722: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-69rhg" for this suite.
Aug 16 13:44:24.742: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:44:24.771: INFO: namespace: e2e-tests-downward-api-69rhg, resource: bindings, ignored listing per whitelist
Aug 16 13:44:24.863: INFO: namespace e2e-tests-downward-api-69rhg deletion completed in 6.136940957s

• [SLOW TEST:8.259 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:44:24.864: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug 16 13:44:24.910: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 version'
Aug 16 13:44:24.962: INFO: stderr: ""
Aug 16 13:44:24.962: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.6\", GitCommit:\"abdda3f9fefa29172298a2e42f5102e777a8ec25\", GitTreeState:\"archive\", BuildDate:\"2019-08-13T21:59:16Z\", GoVersion:\"go1.11.9\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:44:24.962: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-bh8mj" for this suite.
Aug 16 13:44:30.988: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:44:31.079: INFO: namespace: e2e-tests-kubectl-bh8mj, resource: bindings, ignored listing per whitelist
Aug 16 13:44:31.106: INFO: namespace e2e-tests-kubectl-bh8mj deletion completed in 6.139234188s

• [SLOW TEST:6.243 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:44:31.106: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-djl5h
I0816 13:44:31.158698      15 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-djl5h, replica count: 1
I0816 13:44:32.208994      15 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0816 13:44:33.209133      15 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug 16 13:44:33.319: INFO: Created: latency-svc-79sz2
Aug 16 13:44:33.330: INFO: Got endpoints: latency-svc-79sz2 [21.366289ms]
Aug 16 13:44:33.347: INFO: Created: latency-svc-6mg8s
Aug 16 13:44:33.354: INFO: Got endpoints: latency-svc-6mg8s [23.354306ms]
Aug 16 13:44:33.359: INFO: Created: latency-svc-7rp7l
Aug 16 13:44:33.364: INFO: Created: latency-svc-tk5ms
Aug 16 13:44:33.365: INFO: Got endpoints: latency-svc-7rp7l [34.246281ms]
Aug 16 13:44:33.372: INFO: Got endpoints: latency-svc-tk5ms [41.126214ms]
Aug 16 13:44:33.373: INFO: Created: latency-svc-8vf2r
Aug 16 13:44:33.379: INFO: Got endpoints: latency-svc-8vf2r [48.543294ms]
Aug 16 13:44:33.384: INFO: Created: latency-svc-mc7wt
Aug 16 13:44:33.388: INFO: Got endpoints: latency-svc-mc7wt [57.298534ms]
Aug 16 13:44:33.392: INFO: Created: latency-svc-5wldq
Aug 16 13:44:33.399: INFO: Got endpoints: latency-svc-5wldq [68.412843ms]
Aug 16 13:44:33.400: INFO: Created: latency-svc-ls5kb
Aug 16 13:44:33.407: INFO: Got endpoints: latency-svc-ls5kb [76.224202ms]
Aug 16 13:44:33.412: INFO: Created: latency-svc-8mnc4
Aug 16 13:44:33.417: INFO: Got endpoints: latency-svc-8mnc4 [86.180818ms]
Aug 16 13:44:33.418: INFO: Created: latency-svc-dlc89
Aug 16 13:44:33.426: INFO: Got endpoints: latency-svc-dlc89 [94.80563ms]
Aug 16 13:44:33.432: INFO: Created: latency-svc-tgf6h
Aug 16 13:44:33.439: INFO: Got endpoints: latency-svc-tgf6h [107.671241ms]
Aug 16 13:44:33.441: INFO: Created: latency-svc-7nvdd
Aug 16 13:44:33.446: INFO: Got endpoints: latency-svc-7nvdd [115.200068ms]
Aug 16 13:44:33.451: INFO: Created: latency-svc-2fcwf
Aug 16 13:44:33.458: INFO: Got endpoints: latency-svc-2fcwf [126.474489ms]
Aug 16 13:44:33.464: INFO: Created: latency-svc-jkjs4
Aug 16 13:44:33.469: INFO: Got endpoints: latency-svc-jkjs4 [138.034979ms]
Aug 16 13:44:33.471: INFO: Created: latency-svc-zcjvq
Aug 16 13:44:33.475: INFO: Got endpoints: latency-svc-zcjvq [144.366121ms]
Aug 16 13:44:33.478: INFO: Created: latency-svc-2zcp7
Aug 16 13:44:33.486: INFO: Got endpoints: latency-svc-2zcp7 [155.144909ms]
Aug 16 13:44:33.488: INFO: Created: latency-svc-cqbb4
Aug 16 13:44:33.493: INFO: Got endpoints: latency-svc-cqbb4 [139.367316ms]
Aug 16 13:44:33.496: INFO: Created: latency-svc-x5kk6
Aug 16 13:44:33.508: INFO: Got endpoints: latency-svc-x5kk6 [142.740748ms]
Aug 16 13:44:33.508: INFO: Created: latency-svc-9n6d6
Aug 16 13:44:33.517: INFO: Got endpoints: latency-svc-9n6d6 [145.508356ms]
Aug 16 13:44:33.525: INFO: Created: latency-svc-lr4nz
Aug 16 13:44:33.530: INFO: Got endpoints: latency-svc-lr4nz [150.379676ms]
Aug 16 13:44:33.531: INFO: Created: latency-svc-hl6w2
Aug 16 13:44:33.536: INFO: Got endpoints: latency-svc-hl6w2 [147.543574ms]
Aug 16 13:44:33.540: INFO: Created: latency-svc-svwql
Aug 16 13:44:33.545: INFO: Got endpoints: latency-svc-svwql [146.35498ms]
Aug 16 13:44:33.551: INFO: Created: latency-svc-l69l7
Aug 16 13:44:33.558: INFO: Got endpoints: latency-svc-l69l7 [151.131305ms]
Aug 16 13:44:33.562: INFO: Created: latency-svc-m68g5
Aug 16 13:44:33.567: INFO: Created: latency-svc-7ws7k
Aug 16 13:44:33.568: INFO: Got endpoints: latency-svc-m68g5 [151.080233ms]
Aug 16 13:44:33.575: INFO: Got endpoints: latency-svc-7ws7k [149.072922ms]
Aug 16 13:44:33.578: INFO: Created: latency-svc-c95fn
Aug 16 13:44:33.592: INFO: Got endpoints: latency-svc-c95fn [153.106067ms]
Aug 16 13:44:33.598: INFO: Created: latency-svc-q9rml
Aug 16 13:44:33.600: INFO: Got endpoints: latency-svc-q9rml [153.749754ms]
Aug 16 13:44:33.604: INFO: Created: latency-svc-wh9ss
Aug 16 13:44:33.610: INFO: Got endpoints: latency-svc-wh9ss [152.796145ms]
Aug 16 13:44:33.616: INFO: Created: latency-svc-84bs5
Aug 16 13:44:33.621: INFO: Got endpoints: latency-svc-84bs5 [151.758057ms]
Aug 16 13:44:33.629: INFO: Created: latency-svc-mgxhn
Aug 16 13:44:33.636: INFO: Created: latency-svc-7qf7s
Aug 16 13:44:33.637: INFO: Got endpoints: latency-svc-mgxhn [161.451034ms]
Aug 16 13:44:33.643: INFO: Got endpoints: latency-svc-7qf7s [157.352028ms]
Aug 16 13:44:33.645: INFO: Created: latency-svc-6khr5
Aug 16 13:44:33.652: INFO: Got endpoints: latency-svc-6khr5 [159.416491ms]
Aug 16 13:44:33.664: INFO: Created: latency-svc-m9n8f
Aug 16 13:44:33.671: INFO: Got endpoints: latency-svc-m9n8f [163.375577ms]
Aug 16 13:44:33.676: INFO: Created: latency-svc-7rnpj
Aug 16 13:44:33.680: INFO: Got endpoints: latency-svc-7rnpj [163.067587ms]
Aug 16 13:44:33.685: INFO: Created: latency-svc-ct2wc
Aug 16 13:44:33.689: INFO: Got endpoints: latency-svc-ct2wc [159.619452ms]
Aug 16 13:44:33.692: INFO: Created: latency-svc-qsh5g
Aug 16 13:44:33.703: INFO: Got endpoints: latency-svc-qsh5g [166.875546ms]
Aug 16 13:44:33.704: INFO: Created: latency-svc-jffb6
Aug 16 13:44:33.709: INFO: Got endpoints: latency-svc-jffb6 [163.165995ms]
Aug 16 13:44:33.715: INFO: Created: latency-svc-zp6m4
Aug 16 13:44:33.725: INFO: Created: latency-svc-b9x25
Aug 16 13:44:33.728: INFO: Got endpoints: latency-svc-zp6m4 [169.905467ms]
Aug 16 13:44:33.738: INFO: Created: latency-svc-ctg5x
Aug 16 13:44:33.750: INFO: Created: latency-svc-mfhtv
Aug 16 13:44:33.766: INFO: Created: latency-svc-tkz4q
Aug 16 13:44:33.773: INFO: Created: latency-svc-bc6wz
Aug 16 13:44:33.776: INFO: Got endpoints: latency-svc-b9x25 [208.168759ms]
Aug 16 13:44:33.780: INFO: Created: latency-svc-tlbm9
Aug 16 13:44:33.789: INFO: Created: latency-svc-t47z6
Aug 16 13:44:33.798: INFO: Created: latency-svc-wg7vx
Aug 16 13:44:33.805: INFO: Created: latency-svc-xzqkk
Aug 16 13:44:33.813: INFO: Created: latency-svc-8cnrv
Aug 16 13:44:33.822: INFO: Created: latency-svc-wwwz2
Aug 16 13:44:33.827: INFO: Got endpoints: latency-svc-ctg5x [251.886358ms]
Aug 16 13:44:33.835: INFO: Created: latency-svc-6qzn2
Aug 16 13:44:33.841: INFO: Created: latency-svc-57p2m
Aug 16 13:44:33.849: INFO: Created: latency-svc-q2lrg
Aug 16 13:44:33.858: INFO: Created: latency-svc-qr5mk
Aug 16 13:44:33.865: INFO: Created: latency-svc-jlvf8
Aug 16 13:44:33.872: INFO: Created: latency-svc-x6psx
Aug 16 13:44:33.881: INFO: Got endpoints: latency-svc-mfhtv [289.144411ms]
Aug 16 13:44:33.893: INFO: Created: latency-svc-4kph2
Aug 16 13:44:33.926: INFO: Got endpoints: latency-svc-tkz4q [325.873462ms]
Aug 16 13:44:33.939: INFO: Created: latency-svc-4dh7v
Aug 16 13:44:33.976: INFO: Got endpoints: latency-svc-bc6wz [365.251059ms]
Aug 16 13:44:33.994: INFO: Created: latency-svc-klf65
Aug 16 13:44:34.026: INFO: Got endpoints: latency-svc-tlbm9 [405.190819ms]
Aug 16 13:44:34.041: INFO: Created: latency-svc-tsjhv
Aug 16 13:44:34.077: INFO: Got endpoints: latency-svc-t47z6 [439.506853ms]
Aug 16 13:44:34.092: INFO: Created: latency-svc-hzhx7
Aug 16 13:44:34.126: INFO: Got endpoints: latency-svc-wg7vx [482.214901ms]
Aug 16 13:44:34.137: INFO: Created: latency-svc-mdqxs
Aug 16 13:44:34.175: INFO: Got endpoints: latency-svc-xzqkk [522.308598ms]
Aug 16 13:44:34.187: INFO: Created: latency-svc-7gs66
Aug 16 13:44:34.227: INFO: Got endpoints: latency-svc-8cnrv [556.046326ms]
Aug 16 13:44:34.241: INFO: Created: latency-svc-cwtkt
Aug 16 13:44:34.275: INFO: Got endpoints: latency-svc-wwwz2 [594.431486ms]
Aug 16 13:44:34.288: INFO: Created: latency-svc-2fpbs
Aug 16 13:44:34.325: INFO: Got endpoints: latency-svc-6qzn2 [635.854309ms]
Aug 16 13:44:34.338: INFO: Created: latency-svc-6vwc7
Aug 16 13:44:34.378: INFO: Got endpoints: latency-svc-57p2m [674.902916ms]
Aug 16 13:44:34.391: INFO: Created: latency-svc-mrjz7
Aug 16 13:44:34.426: INFO: Got endpoints: latency-svc-q2lrg [717.401045ms]
Aug 16 13:44:34.444: INFO: Created: latency-svc-mmfpt
Aug 16 13:44:34.477: INFO: Got endpoints: latency-svc-qr5mk [749.28241ms]
Aug 16 13:44:34.492: INFO: Created: latency-svc-5hjxc
Aug 16 13:44:34.526: INFO: Got endpoints: latency-svc-jlvf8 [750.096812ms]
Aug 16 13:44:34.538: INFO: Created: latency-svc-954mx
Aug 16 13:44:34.576: INFO: Got endpoints: latency-svc-x6psx [749.862604ms]
Aug 16 13:44:34.588: INFO: Created: latency-svc-b82xj
Aug 16 13:44:34.627: INFO: Got endpoints: latency-svc-4kph2 [745.518078ms]
Aug 16 13:44:34.641: INFO: Created: latency-svc-28g45
Aug 16 13:44:34.676: INFO: Got endpoints: latency-svc-4dh7v [749.693055ms]
Aug 16 13:44:34.688: INFO: Created: latency-svc-cg5wk
Aug 16 13:44:34.726: INFO: Got endpoints: latency-svc-klf65 [750.300963ms]
Aug 16 13:44:34.738: INFO: Created: latency-svc-h82k4
Aug 16 13:44:34.776: INFO: Got endpoints: latency-svc-tsjhv [749.735418ms]
Aug 16 13:44:34.788: INFO: Created: latency-svc-vv7tp
Aug 16 13:44:34.825: INFO: Got endpoints: latency-svc-hzhx7 [748.295304ms]
Aug 16 13:44:34.841: INFO: Created: latency-svc-t7j92
Aug 16 13:44:34.876: INFO: Got endpoints: latency-svc-mdqxs [750.758735ms]
Aug 16 13:44:34.889: INFO: Created: latency-svc-7n56j
Aug 16 13:44:34.925: INFO: Got endpoints: latency-svc-7gs66 [749.777357ms]
Aug 16 13:44:34.936: INFO: Created: latency-svc-krxp2
Aug 16 13:44:34.975: INFO: Got endpoints: latency-svc-cwtkt [747.443582ms]
Aug 16 13:44:34.989: INFO: Created: latency-svc-f7tgg
Aug 16 13:44:35.024: INFO: Got endpoints: latency-svc-2fpbs [749.72374ms]
Aug 16 13:44:35.035: INFO: Created: latency-svc-mqrfp
Aug 16 13:44:35.075: INFO: Got endpoints: latency-svc-6vwc7 [749.619675ms]
Aug 16 13:44:35.088: INFO: Created: latency-svc-whd68
Aug 16 13:44:35.126: INFO: Got endpoints: latency-svc-mrjz7 [748.010451ms]
Aug 16 13:44:35.136: INFO: Created: latency-svc-mrwlj
Aug 16 13:44:35.175: INFO: Got endpoints: latency-svc-mmfpt [749.043788ms]
Aug 16 13:44:35.187: INFO: Created: latency-svc-lrnvs
Aug 16 13:44:35.225: INFO: Got endpoints: latency-svc-5hjxc [748.047812ms]
Aug 16 13:44:35.238: INFO: Created: latency-svc-4fn8k
Aug 16 13:44:35.275: INFO: Got endpoints: latency-svc-954mx [748.225054ms]
Aug 16 13:44:35.285: INFO: Created: latency-svc-7t7qc
Aug 16 13:44:35.325: INFO: Got endpoints: latency-svc-b82xj [748.380304ms]
Aug 16 13:44:35.337: INFO: Created: latency-svc-wsbld
Aug 16 13:44:35.376: INFO: Got endpoints: latency-svc-28g45 [749.264827ms]
Aug 16 13:44:35.388: INFO: Created: latency-svc-ch4v2
Aug 16 13:44:35.425: INFO: Got endpoints: latency-svc-cg5wk [749.795572ms]
Aug 16 13:44:35.437: INFO: Created: latency-svc-rphkp
Aug 16 13:44:35.476: INFO: Got endpoints: latency-svc-h82k4 [749.556732ms]
Aug 16 13:44:35.487: INFO: Created: latency-svc-4dp4d
Aug 16 13:44:35.524: INFO: Got endpoints: latency-svc-vv7tp [748.555112ms]
Aug 16 13:44:35.535: INFO: Created: latency-svc-cnzrd
Aug 16 13:44:35.575: INFO: Got endpoints: latency-svc-t7j92 [750.101298ms]
Aug 16 13:44:35.589: INFO: Created: latency-svc-45qg5
Aug 16 13:44:35.625: INFO: Got endpoints: latency-svc-7n56j [748.905475ms]
Aug 16 13:44:35.637: INFO: Created: latency-svc-xkl47
Aug 16 13:44:35.677: INFO: Got endpoints: latency-svc-krxp2 [751.855864ms]
Aug 16 13:44:35.688: INFO: Created: latency-svc-gpq2n
Aug 16 13:44:35.725: INFO: Got endpoints: latency-svc-f7tgg [750.856774ms]
Aug 16 13:44:35.739: INFO: Created: latency-svc-t2wr8
Aug 16 13:44:35.775: INFO: Got endpoints: latency-svc-mqrfp [750.945658ms]
Aug 16 13:44:35.789: INFO: Created: latency-svc-4w49d
Aug 16 13:44:35.826: INFO: Got endpoints: latency-svc-whd68 [751.19308ms]
Aug 16 13:44:35.838: INFO: Created: latency-svc-cgg6d
Aug 16 13:44:35.876: INFO: Got endpoints: latency-svc-mrwlj [749.955893ms]
Aug 16 13:44:35.892: INFO: Created: latency-svc-4svxk
Aug 16 13:44:35.925: INFO: Got endpoints: latency-svc-lrnvs [749.999225ms]
Aug 16 13:44:35.938: INFO: Created: latency-svc-xj6sz
Aug 16 13:44:35.976: INFO: Got endpoints: latency-svc-4fn8k [750.193611ms]
Aug 16 13:44:35.997: INFO: Created: latency-svc-v86nf
Aug 16 13:44:36.026: INFO: Got endpoints: latency-svc-7t7qc [751.645208ms]
Aug 16 13:44:36.039: INFO: Created: latency-svc-hcqf8
Aug 16 13:44:36.075: INFO: Got endpoints: latency-svc-wsbld [750.398947ms]
Aug 16 13:44:36.094: INFO: Created: latency-svc-f2ff8
Aug 16 13:44:36.127: INFO: Got endpoints: latency-svc-ch4v2 [751.030825ms]
Aug 16 13:44:36.144: INFO: Created: latency-svc-wbsmv
Aug 16 13:44:36.177: INFO: Got endpoints: latency-svc-rphkp [751.079109ms]
Aug 16 13:44:36.193: INFO: Created: latency-svc-twh6b
Aug 16 13:44:36.228: INFO: Got endpoints: latency-svc-4dp4d [751.879689ms]
Aug 16 13:44:36.240: INFO: Created: latency-svc-4zk5c
Aug 16 13:44:36.276: INFO: Got endpoints: latency-svc-cnzrd [751.618531ms]
Aug 16 13:44:36.291: INFO: Created: latency-svc-5cwrv
Aug 16 13:44:36.327: INFO: Got endpoints: latency-svc-45qg5 [751.610139ms]
Aug 16 13:44:36.340: INFO: Created: latency-svc-gr2b5
Aug 16 13:44:36.377: INFO: Got endpoints: latency-svc-xkl47 [751.428999ms]
Aug 16 13:44:36.389: INFO: Created: latency-svc-z7lzn
Aug 16 13:44:36.427: INFO: Got endpoints: latency-svc-gpq2n [750.591576ms]
Aug 16 13:44:36.446: INFO: Created: latency-svc-tbqmt
Aug 16 13:44:36.476: INFO: Got endpoints: latency-svc-t2wr8 [750.193031ms]
Aug 16 13:44:36.487: INFO: Created: latency-svc-p87p7
Aug 16 13:44:36.527: INFO: Got endpoints: latency-svc-4w49d [751.011311ms]
Aug 16 13:44:36.538: INFO: Created: latency-svc-mns5r
Aug 16 13:44:36.576: INFO: Got endpoints: latency-svc-cgg6d [749.632621ms]
Aug 16 13:44:36.590: INFO: Created: latency-svc-7nlxm
Aug 16 13:44:36.627: INFO: Got endpoints: latency-svc-4svxk [751.075108ms]
Aug 16 13:44:36.639: INFO: Created: latency-svc-kv6hg
Aug 16 13:44:36.676: INFO: Got endpoints: latency-svc-xj6sz [750.440415ms]
Aug 16 13:44:36.687: INFO: Created: latency-svc-lmqgm
Aug 16 13:44:36.731: INFO: Got endpoints: latency-svc-v86nf [755.133956ms]
Aug 16 13:44:36.744: INFO: Created: latency-svc-26dqq
Aug 16 13:44:36.776: INFO: Got endpoints: latency-svc-hcqf8 [749.208332ms]
Aug 16 13:44:36.788: INFO: Created: latency-svc-dz5d5
Aug 16 13:44:36.829: INFO: Got endpoints: latency-svc-f2ff8 [753.942253ms]
Aug 16 13:44:36.843: INFO: Created: latency-svc-w95z4
Aug 16 13:44:36.876: INFO: Got endpoints: latency-svc-wbsmv [748.942884ms]
Aug 16 13:44:36.889: INFO: Created: latency-svc-l4rxb
Aug 16 13:44:36.926: INFO: Got endpoints: latency-svc-twh6b [748.936888ms]
Aug 16 13:44:36.938: INFO: Created: latency-svc-9trsp
Aug 16 13:44:36.978: INFO: Got endpoints: latency-svc-4zk5c [750.194599ms]
Aug 16 13:44:36.995: INFO: Created: latency-svc-kfrt6
Aug 16 13:44:37.026: INFO: Got endpoints: latency-svc-5cwrv [750.162526ms]
Aug 16 13:44:37.039: INFO: Created: latency-svc-dxt9l
Aug 16 13:44:37.076: INFO: Got endpoints: latency-svc-gr2b5 [749.624964ms]
Aug 16 13:44:37.093: INFO: Created: latency-svc-447nl
Aug 16 13:44:37.126: INFO: Got endpoints: latency-svc-z7lzn [749.215973ms]
Aug 16 13:44:37.139: INFO: Created: latency-svc-l4f69
Aug 16 13:44:37.177: INFO: Got endpoints: latency-svc-tbqmt [749.528446ms]
Aug 16 13:44:37.188: INFO: Created: latency-svc-mwfrg
Aug 16 13:44:37.228: INFO: Got endpoints: latency-svc-p87p7 [751.815248ms]
Aug 16 13:44:37.242: INFO: Created: latency-svc-frhlg
Aug 16 13:44:37.275: INFO: Got endpoints: latency-svc-mns5r [748.707202ms]
Aug 16 13:44:37.288: INFO: Created: latency-svc-p242r
Aug 16 13:44:37.326: INFO: Got endpoints: latency-svc-7nlxm [749.930179ms]
Aug 16 13:44:37.338: INFO: Created: latency-svc-2rtfw
Aug 16 13:44:37.375: INFO: Got endpoints: latency-svc-kv6hg [748.477937ms]
Aug 16 13:44:37.389: INFO: Created: latency-svc-6rn87
Aug 16 13:44:37.426: INFO: Got endpoints: latency-svc-lmqgm [750.254144ms]
Aug 16 13:44:37.441: INFO: Created: latency-svc-gxpf6
Aug 16 13:44:37.477: INFO: Got endpoints: latency-svc-26dqq [746.184857ms]
Aug 16 13:44:37.489: INFO: Created: latency-svc-tz4d8
Aug 16 13:44:37.527: INFO: Got endpoints: latency-svc-dz5d5 [751.20933ms]
Aug 16 13:44:37.538: INFO: Created: latency-svc-tmtjc
Aug 16 13:44:37.576: INFO: Got endpoints: latency-svc-w95z4 [746.691079ms]
Aug 16 13:44:37.589: INFO: Created: latency-svc-hvp66
Aug 16 13:44:37.627: INFO: Got endpoints: latency-svc-l4rxb [750.862877ms]
Aug 16 13:44:37.639: INFO: Created: latency-svc-gppsz
Aug 16 13:44:37.676: INFO: Got endpoints: latency-svc-9trsp [750.230916ms]
Aug 16 13:44:37.689: INFO: Created: latency-svc-7mxst
Aug 16 13:44:37.726: INFO: Got endpoints: latency-svc-kfrt6 [748.239315ms]
Aug 16 13:44:37.740: INFO: Created: latency-svc-sn8xh
Aug 16 13:44:37.776: INFO: Got endpoints: latency-svc-dxt9l [750.110512ms]
Aug 16 13:44:37.789: INFO: Created: latency-svc-bwpxm
Aug 16 13:44:37.827: INFO: Got endpoints: latency-svc-447nl [750.999791ms]
Aug 16 13:44:37.839: INFO: Created: latency-svc-q95qw
Aug 16 13:44:37.877: INFO: Got endpoints: latency-svc-l4f69 [750.743722ms]
Aug 16 13:44:37.889: INFO: Created: latency-svc-tk6rw
Aug 16 13:44:37.926: INFO: Got endpoints: latency-svc-mwfrg [749.265403ms]
Aug 16 13:44:37.938: INFO: Created: latency-svc-r8mwd
Aug 16 13:44:37.976: INFO: Got endpoints: latency-svc-frhlg [748.340836ms]
Aug 16 13:44:37.998: INFO: Created: latency-svc-6gf4k
Aug 16 13:44:38.028: INFO: Got endpoints: latency-svc-p242r [752.410808ms]
Aug 16 13:44:38.054: INFO: Created: latency-svc-lf4tj
Aug 16 13:44:38.081: INFO: Got endpoints: latency-svc-2rtfw [755.267881ms]
Aug 16 13:44:38.094: INFO: Created: latency-svc-hmq7n
Aug 16 13:44:38.127: INFO: Got endpoints: latency-svc-6rn87 [751.570825ms]
Aug 16 13:44:38.142: INFO: Created: latency-svc-4v6mw
Aug 16 13:44:38.178: INFO: Got endpoints: latency-svc-gxpf6 [752.00615ms]
Aug 16 13:44:38.191: INFO: Created: latency-svc-rwj2s
Aug 16 13:44:38.231: INFO: Got endpoints: latency-svc-tz4d8 [753.443782ms]
Aug 16 13:44:38.241: INFO: Created: latency-svc-vpv2d
Aug 16 13:44:38.275: INFO: Got endpoints: latency-svc-tmtjc [748.531723ms]
Aug 16 13:44:38.287: INFO: Created: latency-svc-m4chq
Aug 16 13:44:38.329: INFO: Got endpoints: latency-svc-hvp66 [752.798ms]
Aug 16 13:44:38.342: INFO: Created: latency-svc-cv5ht
Aug 16 13:44:38.376: INFO: Got endpoints: latency-svc-gppsz [749.595128ms]
Aug 16 13:44:38.389: INFO: Created: latency-svc-9rt4l
Aug 16 13:44:38.425: INFO: Got endpoints: latency-svc-7mxst [749.368993ms]
Aug 16 13:44:38.446: INFO: Created: latency-svc-kz4lr
Aug 16 13:44:38.475: INFO: Got endpoints: latency-svc-sn8xh [749.07514ms]
Aug 16 13:44:38.488: INFO: Created: latency-svc-4db49
Aug 16 13:44:38.526: INFO: Got endpoints: latency-svc-bwpxm [749.860739ms]
Aug 16 13:44:38.551: INFO: Created: latency-svc-mmsrk
Aug 16 13:44:38.576: INFO: Got endpoints: latency-svc-q95qw [748.592163ms]
Aug 16 13:44:38.589: INFO: Created: latency-svc-gcwvb
Aug 16 13:44:38.626: INFO: Got endpoints: latency-svc-tk6rw [748.83991ms]
Aug 16 13:44:38.640: INFO: Created: latency-svc-2mkcp
Aug 16 13:44:38.675: INFO: Got endpoints: latency-svc-r8mwd [749.149385ms]
Aug 16 13:44:38.686: INFO: Created: latency-svc-m278b
Aug 16 13:44:38.726: INFO: Got endpoints: latency-svc-6gf4k [749.79311ms]
Aug 16 13:44:38.738: INFO: Created: latency-svc-r9sg2
Aug 16 13:44:38.775: INFO: Got endpoints: latency-svc-lf4tj [747.542979ms]
Aug 16 13:44:38.786: INFO: Created: latency-svc-j4nd2
Aug 16 13:44:38.826: INFO: Got endpoints: latency-svc-hmq7n [744.674428ms]
Aug 16 13:44:38.838: INFO: Created: latency-svc-4hljl
Aug 16 13:44:38.876: INFO: Got endpoints: latency-svc-4v6mw [748.809679ms]
Aug 16 13:44:38.886: INFO: Created: latency-svc-6bftr
Aug 16 13:44:38.925: INFO: Got endpoints: latency-svc-rwj2s [746.862854ms]
Aug 16 13:44:38.936: INFO: Created: latency-svc-8z8lx
Aug 16 13:44:38.976: INFO: Got endpoints: latency-svc-vpv2d [745.398655ms]
Aug 16 13:44:38.987: INFO: Created: latency-svc-4b4cv
Aug 16 13:44:39.025: INFO: Got endpoints: latency-svc-m4chq [749.890123ms]
Aug 16 13:44:39.036: INFO: Created: latency-svc-vdshc
Aug 16 13:44:39.076: INFO: Got endpoints: latency-svc-cv5ht [747.3927ms]
Aug 16 13:44:39.091: INFO: Created: latency-svc-2hwbr
Aug 16 13:44:39.127: INFO: Got endpoints: latency-svc-9rt4l [750.370687ms]
Aug 16 13:44:39.139: INFO: Created: latency-svc-gmxlj
Aug 16 13:44:39.178: INFO: Got endpoints: latency-svc-kz4lr [752.395178ms]
Aug 16 13:44:39.192: INFO: Created: latency-svc-7zzt2
Aug 16 13:44:39.233: INFO: Got endpoints: latency-svc-4db49 [757.475235ms]
Aug 16 13:44:39.246: INFO: Created: latency-svc-plp7n
Aug 16 13:44:39.277: INFO: Got endpoints: latency-svc-mmsrk [750.577991ms]
Aug 16 13:44:39.294: INFO: Created: latency-svc-zpkcc
Aug 16 13:44:39.326: INFO: Got endpoints: latency-svc-gcwvb [749.754533ms]
Aug 16 13:44:39.339: INFO: Created: latency-svc-zjvtd
Aug 16 13:44:39.377: INFO: Got endpoints: latency-svc-2mkcp [750.607452ms]
Aug 16 13:44:39.390: INFO: Created: latency-svc-kf8d4
Aug 16 13:44:39.430: INFO: Got endpoints: latency-svc-m278b [755.00041ms]
Aug 16 13:44:39.442: INFO: Created: latency-svc-5p6h7
Aug 16 13:44:39.476: INFO: Got endpoints: latency-svc-r9sg2 [750.39418ms]
Aug 16 13:44:39.490: INFO: Created: latency-svc-vfj6t
Aug 16 13:44:39.526: INFO: Got endpoints: latency-svc-j4nd2 [750.494442ms]
Aug 16 13:44:39.537: INFO: Created: latency-svc-8dvkz
Aug 16 13:44:39.576: INFO: Got endpoints: latency-svc-4hljl [750.638998ms]
Aug 16 13:44:39.590: INFO: Created: latency-svc-ps6zr
Aug 16 13:44:39.628: INFO: Got endpoints: latency-svc-6bftr [752.565456ms]
Aug 16 13:44:39.642: INFO: Created: latency-svc-zzj44
Aug 16 13:44:39.677: INFO: Got endpoints: latency-svc-8z8lx [751.819419ms]
Aug 16 13:44:39.690: INFO: Created: latency-svc-v4pks
Aug 16 13:44:39.727: INFO: Got endpoints: latency-svc-4b4cv [750.904151ms]
Aug 16 13:44:39.741: INFO: Created: latency-svc-phdkh
Aug 16 13:44:39.777: INFO: Got endpoints: latency-svc-vdshc [751.357605ms]
Aug 16 13:44:39.791: INFO: Created: latency-svc-btmtk
Aug 16 13:44:39.827: INFO: Got endpoints: latency-svc-2hwbr [750.350406ms]
Aug 16 13:44:39.838: INFO: Created: latency-svc-xjmck
Aug 16 13:44:39.876: INFO: Got endpoints: latency-svc-gmxlj [748.749098ms]
Aug 16 13:44:39.890: INFO: Created: latency-svc-rqc7w
Aug 16 13:44:39.926: INFO: Got endpoints: latency-svc-7zzt2 [748.612179ms]
Aug 16 13:44:39.942: INFO: Created: latency-svc-ttjdd
Aug 16 13:44:39.977: INFO: Got endpoints: latency-svc-plp7n [744.085677ms]
Aug 16 13:44:39.992: INFO: Created: latency-svc-hhwp7
Aug 16 13:44:40.026: INFO: Got endpoints: latency-svc-zpkcc [748.852237ms]
Aug 16 13:44:40.039: INFO: Created: latency-svc-mddgn
Aug 16 13:44:40.077: INFO: Got endpoints: latency-svc-zjvtd [751.193043ms]
Aug 16 13:44:40.090: INFO: Created: latency-svc-2l259
Aug 16 13:44:40.127: INFO: Got endpoints: latency-svc-kf8d4 [750.234253ms]
Aug 16 13:44:40.139: INFO: Created: latency-svc-cfkxv
Aug 16 13:44:40.176: INFO: Got endpoints: latency-svc-5p6h7 [746.029083ms]
Aug 16 13:44:40.190: INFO: Created: latency-svc-qq4lw
Aug 16 13:44:40.228: INFO: Got endpoints: latency-svc-vfj6t [751.894451ms]
Aug 16 13:44:40.241: INFO: Created: latency-svc-9thj7
Aug 16 13:44:40.278: INFO: Got endpoints: latency-svc-8dvkz [751.676162ms]
Aug 16 13:44:40.291: INFO: Created: latency-svc-bkhs5
Aug 16 13:44:40.326: INFO: Got endpoints: latency-svc-ps6zr [749.787536ms]
Aug 16 13:44:40.340: INFO: Created: latency-svc-695rc
Aug 16 13:44:40.377: INFO: Got endpoints: latency-svc-zzj44 [748.466774ms]
Aug 16 13:44:40.388: INFO: Created: latency-svc-qsprw
Aug 16 13:44:40.427: INFO: Got endpoints: latency-svc-v4pks [749.619165ms]
Aug 16 13:44:40.445: INFO: Created: latency-svc-tsxnc
Aug 16 13:44:40.478: INFO: Got endpoints: latency-svc-phdkh [750.56202ms]
Aug 16 13:44:40.493: INFO: Created: latency-svc-6bz54
Aug 16 13:44:40.527: INFO: Got endpoints: latency-svc-btmtk [750.161842ms]
Aug 16 13:44:40.540: INFO: Created: latency-svc-2xmg5
Aug 16 13:44:40.576: INFO: Got endpoints: latency-svc-xjmck [749.367198ms]
Aug 16 13:44:40.589: INFO: Created: latency-svc-btmh7
Aug 16 13:44:40.627: INFO: Got endpoints: latency-svc-rqc7w [751.011821ms]
Aug 16 13:44:40.638: INFO: Created: latency-svc-tw86x
Aug 16 13:44:40.676: INFO: Got endpoints: latency-svc-ttjdd [749.278516ms]
Aug 16 13:44:40.687: INFO: Created: latency-svc-cxf9n
Aug 16 13:44:40.726: INFO: Got endpoints: latency-svc-hhwp7 [749.201213ms]
Aug 16 13:44:40.738: INFO: Created: latency-svc-v2dtf
Aug 16 13:44:40.778: INFO: Got endpoints: latency-svc-mddgn [751.988777ms]
Aug 16 13:44:40.789: INFO: Created: latency-svc-dblkh
Aug 16 13:44:40.827: INFO: Got endpoints: latency-svc-2l259 [749.826322ms]
Aug 16 13:44:40.839: INFO: Created: latency-svc-8z4xl
Aug 16 13:44:40.876: INFO: Got endpoints: latency-svc-cfkxv [749.439925ms]
Aug 16 13:44:40.890: INFO: Created: latency-svc-l55wq
Aug 16 13:44:40.925: INFO: Got endpoints: latency-svc-qq4lw [748.569445ms]
Aug 16 13:44:40.939: INFO: Created: latency-svc-c7tgl
Aug 16 13:44:40.976: INFO: Got endpoints: latency-svc-9thj7 [747.726318ms]
Aug 16 13:44:40.995: INFO: Created: latency-svc-dqwl8
Aug 16 13:44:41.028: INFO: Got endpoints: latency-svc-bkhs5 [750.127172ms]
Aug 16 13:44:41.047: INFO: Created: latency-svc-fxklz
Aug 16 13:44:41.077: INFO: Got endpoints: latency-svc-695rc [750.565262ms]
Aug 16 13:44:41.088: INFO: Created: latency-svc-6ncxg
Aug 16 13:44:41.127: INFO: Got endpoints: latency-svc-qsprw [750.43448ms]
Aug 16 13:44:41.140: INFO: Created: latency-svc-977zr
Aug 16 13:44:41.176: INFO: Got endpoints: latency-svc-tsxnc [749.326451ms]
Aug 16 13:44:41.226: INFO: Got endpoints: latency-svc-6bz54 [748.467975ms]
Aug 16 13:44:41.276: INFO: Got endpoints: latency-svc-2xmg5 [748.639499ms]
Aug 16 13:44:41.327: INFO: Got endpoints: latency-svc-btmh7 [751.274859ms]
Aug 16 13:44:41.376: INFO: Got endpoints: latency-svc-tw86x [749.518466ms]
Aug 16 13:44:41.426: INFO: Got endpoints: latency-svc-cxf9n [749.980688ms]
Aug 16 13:44:41.475: INFO: Got endpoints: latency-svc-v2dtf [749.172714ms]
Aug 16 13:44:41.526: INFO: Got endpoints: latency-svc-dblkh [747.649182ms]
Aug 16 13:44:41.575: INFO: Got endpoints: latency-svc-8z4xl [748.345726ms]
Aug 16 13:44:41.626: INFO: Got endpoints: latency-svc-l55wq [749.29583ms]
Aug 16 13:44:41.676: INFO: Got endpoints: latency-svc-c7tgl [751.304772ms]
Aug 16 13:44:41.727: INFO: Got endpoints: latency-svc-dqwl8 [750.859261ms]
Aug 16 13:44:41.776: INFO: Got endpoints: latency-svc-fxklz [747.954034ms]
Aug 16 13:44:41.825: INFO: Got endpoints: latency-svc-6ncxg [748.560395ms]
Aug 16 13:44:41.876: INFO: Got endpoints: latency-svc-977zr [748.235705ms]
Aug 16 13:44:41.876: INFO: Latencies: [23.354306ms 34.246281ms 41.126214ms 48.543294ms 57.298534ms 68.412843ms 76.224202ms 86.180818ms 94.80563ms 107.671241ms 115.200068ms 126.474489ms 138.034979ms 139.367316ms 142.740748ms 144.366121ms 145.508356ms 146.35498ms 147.543574ms 149.072922ms 150.379676ms 151.080233ms 151.131305ms 151.758057ms 152.796145ms 153.106067ms 153.749754ms 155.144909ms 157.352028ms 159.416491ms 159.619452ms 161.451034ms 163.067587ms 163.165995ms 163.375577ms 166.875546ms 169.905467ms 208.168759ms 251.886358ms 289.144411ms 325.873462ms 365.251059ms 405.190819ms 439.506853ms 482.214901ms 522.308598ms 556.046326ms 594.431486ms 635.854309ms 674.902916ms 717.401045ms 744.085677ms 744.674428ms 745.398655ms 745.518078ms 746.029083ms 746.184857ms 746.691079ms 746.862854ms 747.3927ms 747.443582ms 747.542979ms 747.649182ms 747.726318ms 747.954034ms 748.010451ms 748.047812ms 748.225054ms 748.235705ms 748.239315ms 748.295304ms 748.340836ms 748.345726ms 748.380304ms 748.466774ms 748.467975ms 748.477937ms 748.531723ms 748.555112ms 748.560395ms 748.569445ms 748.592163ms 748.612179ms 748.639499ms 748.707202ms 748.749098ms 748.809679ms 748.83991ms 748.852237ms 748.905475ms 748.936888ms 748.942884ms 749.043788ms 749.07514ms 749.149385ms 749.172714ms 749.201213ms 749.208332ms 749.215973ms 749.264827ms 749.265403ms 749.278516ms 749.28241ms 749.29583ms 749.326451ms 749.367198ms 749.368993ms 749.439925ms 749.518466ms 749.528446ms 749.556732ms 749.595128ms 749.619165ms 749.619675ms 749.624964ms 749.632621ms 749.693055ms 749.72374ms 749.735418ms 749.754533ms 749.777357ms 749.787536ms 749.79311ms 749.795572ms 749.826322ms 749.860739ms 749.862604ms 749.890123ms 749.930179ms 749.955893ms 749.980688ms 749.999225ms 750.096812ms 750.101298ms 750.110512ms 750.127172ms 750.161842ms 750.162526ms 750.193031ms 750.193611ms 750.194599ms 750.230916ms 750.234253ms 750.254144ms 750.300963ms 750.350406ms 750.370687ms 750.39418ms 750.398947ms 750.43448ms 750.440415ms 750.494442ms 750.56202ms 750.565262ms 750.577991ms 750.591576ms 750.607452ms 750.638998ms 750.743722ms 750.758735ms 750.856774ms 750.859261ms 750.862877ms 750.904151ms 750.945658ms 750.999791ms 751.011311ms 751.011821ms 751.030825ms 751.075108ms 751.079109ms 751.193043ms 751.19308ms 751.20933ms 751.274859ms 751.304772ms 751.357605ms 751.428999ms 751.570825ms 751.610139ms 751.618531ms 751.645208ms 751.676162ms 751.815248ms 751.819419ms 751.855864ms 751.879689ms 751.894451ms 751.988777ms 752.00615ms 752.395178ms 752.410808ms 752.565456ms 752.798ms 753.443782ms 753.942253ms 755.00041ms 755.133956ms 755.267881ms 757.475235ms]
Aug 16 13:44:41.876: INFO: 50 %ile: 749.265403ms
Aug 16 13:44:41.876: INFO: 90 %ile: 751.618531ms
Aug 16 13:44:41.876: INFO: 99 %ile: 755.267881ms
Aug 16 13:44:41.876: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:44:41.876: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-djl5h" for this suite.
Aug 16 13:44:53.896: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:44:53.921: INFO: namespace: e2e-tests-svc-latency-djl5h, resource: bindings, ignored listing per whitelist
Aug 16 13:44:54.010: INFO: namespace e2e-tests-svc-latency-djl5h deletion completed in 12.12929728s

• [SLOW TEST:22.904 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:44:54.010: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug 16 13:44:54.092: INFO: Pod name rollover-pod: Found 0 pods out of 1
Aug 16 13:44:59.096: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Aug 16 13:44:59.096: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Aug 16 13:45:01.100: INFO: Creating deployment "test-rollover-deployment"
Aug 16 13:45:01.107: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Aug 16 13:45:03.120: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Aug 16 13:45:03.132: INFO: Ensure that both replica sets have 1 created replica
Aug 16 13:45:03.138: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Aug 16 13:45:03.146: INFO: Updating deployment test-rollover-deployment
Aug 16 13:45:03.146: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Aug 16 13:45:05.154: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Aug 16 13:45:05.161: INFO: Make sure deployment "test-rollover-deployment" is complete
Aug 16 13:45:05.168: INFO: all replica sets need to contain the pod-template-hash label
Aug 16 13:45:05.168: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701559901, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701559901, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701559904, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701559901, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 16 13:45:07.175: INFO: all replica sets need to contain the pod-template-hash label
Aug 16 13:45:07.175: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701559901, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701559901, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701559904, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701559901, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 16 13:45:09.175: INFO: all replica sets need to contain the pod-template-hash label
Aug 16 13:45:09.175: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701559901, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701559901, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701559904, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701559901, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 16 13:45:11.175: INFO: all replica sets need to contain the pod-template-hash label
Aug 16 13:45:11.175: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701559901, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701559901, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701559904, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701559901, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 16 13:45:13.181: INFO: all replica sets need to contain the pod-template-hash label
Aug 16 13:45:13.181: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701559901, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701559901, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701559904, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701559901, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 16 13:45:15.175: INFO: 
Aug 16 13:45:15.175: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Aug 16 13:45:15.187: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-zb8lw,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-zb8lw/deployments/test-rollover-deployment,UID:0b332742-c02c-11e9-ae7d-02d5aa9cbbca,ResourceVersion:27592,Generation:2,CreationTimestamp:2019-08-16 13:45:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-08-16 13:45:01 +0000 UTC 2019-08-16 13:45:01 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-08-16 13:45:14 +0000 UTC 2019-08-16 13:45:01 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-6b7f9d6597" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Aug 16 13:45:15.190: INFO: New ReplicaSet "test-rollover-deployment-6b7f9d6597" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597,GenerateName:,Namespace:e2e-tests-deployment-zb8lw,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-zb8lw/replicasets/test-rollover-deployment-6b7f9d6597,UID:0c6b5c51-c02c-11e9-ae7d-02d5aa9cbbca,ResourceVersion:27583,Generation:2,CreationTimestamp:2019-08-16 13:45:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 0b332742-c02c-11e9-ae7d-02d5aa9cbbca 0xc0020e7797 0xc0020e7798}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Aug 16 13:45:15.190: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Aug 16 13:45:15.190: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-zb8lw,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-zb8lw/replicasets/test-rollover-controller,UID:07048ff2-c02c-11e9-ae7d-02d5aa9cbbca,ResourceVersion:27591,Generation:2,CreationTimestamp:2019-08-16 13:44:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 0b332742-c02c-11e9-ae7d-02d5aa9cbbca 0xc0020e7587 0xc0020e7588}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug 16 13:45:15.190: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6586df867b,GenerateName:,Namespace:e2e-tests-deployment-zb8lw,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-zb8lw/replicasets/test-rollover-deployment-6586df867b,UID:0b35529a-c02c-11e9-ae7d-02d5aa9cbbca,ResourceVersion:27537,Generation:2,CreationTimestamp:2019-08-16 13:45:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 0b332742-c02c-11e9-ae7d-02d5aa9cbbca 0xc0020e7647 0xc0020e7648}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug 16 13:45:15.193: INFO: Pod "test-rollover-deployment-6b7f9d6597-w9xcw" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597-w9xcw,GenerateName:test-rollover-deployment-6b7f9d6597-,Namespace:e2e-tests-deployment-zb8lw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-zb8lw/pods/test-rollover-deployment-6b7f9d6597-w9xcw,UID:0c70bc89-c02c-11e9-ae7d-02d5aa9cbbca,ResourceVersion:27546,Generation:0,CreationTimestamp:2019-08-16 13:45:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.4.112/32,},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-6b7f9d6597 0c6b5c51-c02c-11e9-ae7d-02d5aa9cbbca 0xc00208a6f7 0xc00208a6f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-8vg24 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8vg24,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-8vg24 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-eab92000-c026-11e9-bfed-069795ba99e0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00208a760} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00208a780}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 13:45:03 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 13:45:04 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 13:45:04 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 13:45:03 +0000 UTC  }],Message:,Reason:,HostIP:10.1.161.42,PodIP:10.2.4.112,StartTime:2019-08-16 13:45:03 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-08-16 13:45:04 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://d6d798adeec61d12fbf1725bfd17f02a0730c5987a03fd4cf81aefca34068791}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:45:15.193: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-zb8lw" for this suite.
Aug 16 13:45:21.211: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:45:21.300: INFO: namespace: e2e-tests-deployment-zb8lw, resource: bindings, ignored listing per whitelist
Aug 16 13:45:21.325: INFO: namespace e2e-tests-deployment-zb8lw deletion completed in 6.127809351s

• [SLOW TEST:27.315 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:45:21.325: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-1750564d-c02c-11e9-99f6-8a077000b195
STEP: Creating a pod to test consume secrets
Aug 16 13:45:21.395: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-175131ba-c02c-11e9-99f6-8a077000b195" in namespace "e2e-tests-projected-k7h5q" to be "success or failure"
Aug 16 13:45:21.406: INFO: Pod "pod-projected-secrets-175131ba-c02c-11e9-99f6-8a077000b195": Phase="Pending", Reason="", readiness=false. Elapsed: 11.179736ms
Aug 16 13:45:23.421: INFO: Pod "pod-projected-secrets-175131ba-c02c-11e9-99f6-8a077000b195": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.025945035s
STEP: Saw pod success
Aug 16 13:45:23.421: INFO: Pod "pod-projected-secrets-175131ba-c02c-11e9-99f6-8a077000b195" satisfied condition "success or failure"
Aug 16 13:45:23.429: INFO: Trying to get logs from node worker-eab92000-c026-11e9-bfed-069795ba99e0 pod pod-projected-secrets-175131ba-c02c-11e9-99f6-8a077000b195 container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug 16 13:45:23.468: INFO: Waiting for pod pod-projected-secrets-175131ba-c02c-11e9-99f6-8a077000b195 to disappear
Aug 16 13:45:23.474: INFO: Pod pod-projected-secrets-175131ba-c02c-11e9-99f6-8a077000b195 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:45:23.474: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-k7h5q" for this suite.
Aug 16 13:45:29.497: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:45:29.536: INFO: namespace: e2e-tests-projected-k7h5q, resource: bindings, ignored listing per whitelist
Aug 16 13:45:29.612: INFO: namespace e2e-tests-projected-k7h5q deletion completed in 6.133309699s

• [SLOW TEST:8.287 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:45:29.612: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
Aug 16 13:45:29.677: INFO: Waiting up to 5m0s for pod "client-containers-1c411f44-c02c-11e9-99f6-8a077000b195" in namespace "e2e-tests-containers-ncjpt" to be "success or failure"
Aug 16 13:45:29.682: INFO: Pod "client-containers-1c411f44-c02c-11e9-99f6-8a077000b195": Phase="Pending", Reason="", readiness=false. Elapsed: 5.4193ms
Aug 16 13:45:31.686: INFO: Pod "client-containers-1c411f44-c02c-11e9-99f6-8a077000b195": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009112291s
STEP: Saw pod success
Aug 16 13:45:31.686: INFO: Pod "client-containers-1c411f44-c02c-11e9-99f6-8a077000b195" satisfied condition "success or failure"
Aug 16 13:45:31.690: INFO: Trying to get logs from node worker-eab92000-c026-11e9-bfed-069795ba99e0 pod client-containers-1c411f44-c02c-11e9-99f6-8a077000b195 container test-container: <nil>
STEP: delete the pod
Aug 16 13:45:31.715: INFO: Waiting for pod client-containers-1c411f44-c02c-11e9-99f6-8a077000b195 to disappear
Aug 16 13:45:31.719: INFO: Pod client-containers-1c411f44-c02c-11e9-99f6-8a077000b195 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:45:31.719: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-ncjpt" for this suite.
Aug 16 13:45:37.736: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:45:37.833: INFO: namespace: e2e-tests-containers-ncjpt, resource: bindings, ignored listing per whitelist
Aug 16 13:45:37.852: INFO: namespace e2e-tests-containers-ncjpt deletion completed in 6.128810676s

• [SLOW TEST:8.240 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:45:37.852: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
Aug 16 13:45:38.425: INFO: created pod pod-service-account-defaultsa
Aug 16 13:45:38.425: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Aug 16 13:45:38.434: INFO: created pod pod-service-account-mountsa
Aug 16 13:45:38.434: INFO: pod pod-service-account-mountsa service account token volume mount: true
Aug 16 13:45:38.443: INFO: created pod pod-service-account-nomountsa
Aug 16 13:45:38.443: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Aug 16 13:45:38.452: INFO: created pod pod-service-account-defaultsa-mountspec
Aug 16 13:45:38.452: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Aug 16 13:45:38.460: INFO: created pod pod-service-account-mountsa-mountspec
Aug 16 13:45:38.460: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Aug 16 13:45:38.476: INFO: created pod pod-service-account-nomountsa-mountspec
Aug 16 13:45:38.476: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Aug 16 13:45:38.486: INFO: created pod pod-service-account-defaultsa-nomountspec
Aug 16 13:45:38.487: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Aug 16 13:45:38.498: INFO: created pod pod-service-account-mountsa-nomountspec
Aug 16 13:45:38.498: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Aug 16 13:45:38.507: INFO: created pod pod-service-account-nomountsa-nomountspec
Aug 16 13:45:38.507: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:45:38.507: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-snvsk" for this suite.
Aug 16 13:45:44.544: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:45:44.635: INFO: namespace: e2e-tests-svcaccounts-snvsk, resource: bindings, ignored listing per whitelist
Aug 16 13:45:44.654: INFO: namespace e2e-tests-svcaccounts-snvsk deletion completed in 6.134024546s

• [SLOW TEST:6.802 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:45:44.654: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-2539979e-c02c-11e9-99f6-8a077000b195
STEP: Creating a pod to test consume configMaps
Aug 16 13:45:44.725: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-253a3876-c02c-11e9-99f6-8a077000b195" in namespace "e2e-tests-projected-4kzq2" to be "success or failure"
Aug 16 13:45:44.728: INFO: Pod "pod-projected-configmaps-253a3876-c02c-11e9-99f6-8a077000b195": Phase="Pending", Reason="", readiness=false. Elapsed: 3.258535ms
Aug 16 13:45:46.732: INFO: Pod "pod-projected-configmaps-253a3876-c02c-11e9-99f6-8a077000b195": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006812787s
STEP: Saw pod success
Aug 16 13:45:46.732: INFO: Pod "pod-projected-configmaps-253a3876-c02c-11e9-99f6-8a077000b195" satisfied condition "success or failure"
Aug 16 13:45:46.735: INFO: Trying to get logs from node worker-eab92000-c026-11e9-bfed-069795ba99e0 pod pod-projected-configmaps-253a3876-c02c-11e9-99f6-8a077000b195 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 16 13:45:46.759: INFO: Waiting for pod pod-projected-configmaps-253a3876-c02c-11e9-99f6-8a077000b195 to disappear
Aug 16 13:45:46.765: INFO: Pod pod-projected-configmaps-253a3876-c02c-11e9-99f6-8a077000b195 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:45:46.765: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-4kzq2" for this suite.
Aug 16 13:45:52.782: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:45:52.889: INFO: namespace: e2e-tests-projected-4kzq2, resource: bindings, ignored listing per whitelist
Aug 16 13:45:52.895: INFO: namespace e2e-tests-projected-4kzq2 deletion completed in 6.126508231s

• [SLOW TEST:8.241 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:45:52.896: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-xsd7s
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-xsd7s to expose endpoints map[]
Aug 16 13:45:53.019: INFO: Get endpoints failed (9.371453ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Aug 16 13:45:54.023: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-xsd7s exposes endpoints map[] (1.013040562s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-xsd7s
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-xsd7s to expose endpoints map[pod1:[100]]
Aug 16 13:45:56.060: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-xsd7s exposes endpoints map[pod1:[100]] (2.028811538s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-xsd7s
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-xsd7s to expose endpoints map[pod1:[100] pod2:[101]]
Aug 16 13:45:58.098: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-xsd7s exposes endpoints map[pod1:[100] pod2:[101]] (2.033607027s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-xsd7s
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-xsd7s to expose endpoints map[pod2:[101]]
Aug 16 13:45:58.122: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-xsd7s exposes endpoints map[pod2:[101]] (15.837021ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-xsd7s
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-xsd7s to expose endpoints map[]
Aug 16 13:45:59.138: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-xsd7s exposes endpoints map[] (1.00739534s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:45:59.168: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-xsd7s" for this suite.
Aug 16 13:46:05.196: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:46:05.228: INFO: namespace: e2e-tests-services-xsd7s, resource: bindings, ignored listing per whitelist
Aug 16 13:46:05.316: INFO: namespace e2e-tests-services-xsd7s deletion completed in 6.141738235s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:12.420 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:46:05.316: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-31897af1-c02c-11e9-99f6-8a077000b195
STEP: Creating secret with name s-test-opt-upd-31897b24-c02c-11e9-99f6-8a077000b195
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-31897af1-c02c-11e9-99f6-8a077000b195
STEP: Updating secret s-test-opt-upd-31897b24-c02c-11e9-99f6-8a077000b195
STEP: Creating secret with name s-test-opt-create-31897b37-c02c-11e9-99f6-8a077000b195
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:46:09.468: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-dm7vg" for this suite.
Aug 16 13:46:31.486: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:46:31.572: INFO: namespace: e2e-tests-secrets-dm7vg, resource: bindings, ignored listing per whitelist
Aug 16 13:46:31.599: INFO: namespace e2e-tests-secrets-dm7vg deletion completed in 22.12666728s

• [SLOW TEST:26.283 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:46:31.599: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Aug 16 13:46:36.737: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:46:37.760: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-fw9q2" for this suite.
Aug 16 13:46:59.784: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:46:59.794: INFO: namespace: e2e-tests-replicaset-fw9q2, resource: bindings, ignored listing per whitelist
Aug 16 13:46:59.895: INFO: namespace e2e-tests-replicaset-fw9q2 deletion completed in 22.130518767s

• [SLOW TEST:28.296 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:46:59.896: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-m9sjw
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Aug 16 13:46:59.956: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Aug 16 13:47:18.036: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.2.3.51:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-m9sjw PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 16 13:47:18.037: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
Aug 16 13:47:18.112: INFO: Found all expected endpoints: [netserver-0]
Aug 16 13:47:18.116: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.2.4.126:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-m9sjw PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 16 13:47:18.116: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
Aug 16 13:47:18.212: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:47:18.212: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-m9sjw" for this suite.
Aug 16 13:47:40.230: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:47:40.328: INFO: namespace: e2e-tests-pod-network-test-m9sjw, resource: bindings, ignored listing per whitelist
Aug 16 13:47:40.347: INFO: namespace e2e-tests-pod-network-test-m9sjw deletion completed in 22.130574738s

• [SLOW TEST:40.452 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:47:40.347: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-pq4h
STEP: Creating a pod to test atomic-volume-subpath
Aug 16 13:47:40.413: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-pq4h" in namespace "e2e-tests-subpath-qqn6p" to be "success or failure"
Aug 16 13:47:40.418: INFO: Pod "pod-subpath-test-projected-pq4h": Phase="Pending", Reason="", readiness=false. Elapsed: 5.803106ms
Aug 16 13:47:42.428: INFO: Pod "pod-subpath-test-projected-pq4h": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015575519s
Aug 16 13:47:44.432: INFO: Pod "pod-subpath-test-projected-pq4h": Phase="Running", Reason="", readiness=false. Elapsed: 4.019439348s
Aug 16 13:47:46.436: INFO: Pod "pod-subpath-test-projected-pq4h": Phase="Running", Reason="", readiness=false. Elapsed: 6.023438705s
Aug 16 13:47:48.440: INFO: Pod "pod-subpath-test-projected-pq4h": Phase="Running", Reason="", readiness=false. Elapsed: 8.027315016s
Aug 16 13:47:50.444: INFO: Pod "pod-subpath-test-projected-pq4h": Phase="Running", Reason="", readiness=false. Elapsed: 10.031088702s
Aug 16 13:47:52.454: INFO: Pod "pod-subpath-test-projected-pq4h": Phase="Running", Reason="", readiness=false. Elapsed: 12.041617625s
Aug 16 13:47:54.458: INFO: Pod "pod-subpath-test-projected-pq4h": Phase="Running", Reason="", readiness=false. Elapsed: 14.045606695s
Aug 16 13:47:56.462: INFO: Pod "pod-subpath-test-projected-pq4h": Phase="Running", Reason="", readiness=false. Elapsed: 16.049558305s
Aug 16 13:47:58.466: INFO: Pod "pod-subpath-test-projected-pq4h": Phase="Running", Reason="", readiness=false. Elapsed: 18.053285512s
Aug 16 13:48:00.470: INFO: Pod "pod-subpath-test-projected-pq4h": Phase="Running", Reason="", readiness=false. Elapsed: 20.057288s
Aug 16 13:48:02.480: INFO: Pod "pod-subpath-test-projected-pq4h": Phase="Running", Reason="", readiness=false. Elapsed: 22.067685821s
Aug 16 13:48:04.484: INFO: Pod "pod-subpath-test-projected-pq4h": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.071758966s
STEP: Saw pod success
Aug 16 13:48:04.484: INFO: Pod "pod-subpath-test-projected-pq4h" satisfied condition "success or failure"
Aug 16 13:48:04.488: INFO: Trying to get logs from node worker-eab92000-c026-11e9-bfed-069795ba99e0 pod pod-subpath-test-projected-pq4h container test-container-subpath-projected-pq4h: <nil>
STEP: delete the pod
Aug 16 13:48:04.512: INFO: Waiting for pod pod-subpath-test-projected-pq4h to disappear
Aug 16 13:48:04.516: INFO: Pod pod-subpath-test-projected-pq4h no longer exists
STEP: Deleting pod pod-subpath-test-projected-pq4h
Aug 16 13:48:04.516: INFO: Deleting pod "pod-subpath-test-projected-pq4h" in namespace "e2e-tests-subpath-qqn6p"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:48:04.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-qqn6p" for this suite.
Aug 16 13:48:10.537: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:48:10.638: INFO: namespace: e2e-tests-subpath-qqn6p, resource: bindings, ignored listing per whitelist
Aug 16 13:48:10.649: INFO: namespace e2e-tests-subpath-qqn6p deletion completed in 6.124830819s

• [SLOW TEST:30.301 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:48:10.649: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:48:10.728: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-tlwlp" for this suite.
Aug 16 13:48:16.746: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:48:16.820: INFO: namespace: e2e-tests-kubelet-test-tlwlp, resource: bindings, ignored listing per whitelist
Aug 16 13:48:16.855: INFO: namespace e2e-tests-kubelet-test-tlwlp deletion completed in 6.122692656s

• [SLOW TEST:6.206 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:48:16.855: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:48:20.924: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-shkm9" for this suite.
Aug 16 13:48:26.946: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:48:27.056: INFO: namespace: e2e-tests-kubelet-test-shkm9, resource: bindings, ignored listing per whitelist
Aug 16 13:48:27.066: INFO: namespace e2e-tests-kubelet-test-shkm9 deletion completed in 6.136018271s

• [SLOW TEST:10.211 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:48:27.066: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-86067037-c02c-11e9-99f6-8a077000b195
STEP: Creating a pod to test consume secrets
Aug 16 13:48:27.131: INFO: Waiting up to 5m0s for pod "pod-secrets-86072f0a-c02c-11e9-99f6-8a077000b195" in namespace "e2e-tests-secrets-j6xwd" to be "success or failure"
Aug 16 13:48:27.134: INFO: Pod "pod-secrets-86072f0a-c02c-11e9-99f6-8a077000b195": Phase="Pending", Reason="", readiness=false. Elapsed: 3.024515ms
Aug 16 13:48:29.137: INFO: Pod "pod-secrets-86072f0a-c02c-11e9-99f6-8a077000b195": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006927886s
STEP: Saw pod success
Aug 16 13:48:29.137: INFO: Pod "pod-secrets-86072f0a-c02c-11e9-99f6-8a077000b195" satisfied condition "success or failure"
Aug 16 13:48:29.141: INFO: Trying to get logs from node worker-eab92000-c026-11e9-bfed-069795ba99e0 pod pod-secrets-86072f0a-c02c-11e9-99f6-8a077000b195 container secret-volume-test: <nil>
STEP: delete the pod
Aug 16 13:48:29.170: INFO: Waiting for pod pod-secrets-86072f0a-c02c-11e9-99f6-8a077000b195 to disappear
Aug 16 13:48:29.173: INFO: Pod pod-secrets-86072f0a-c02c-11e9-99f6-8a077000b195 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:48:29.173: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-j6xwd" for this suite.
Aug 16 13:48:35.195: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:48:35.267: INFO: namespace: e2e-tests-secrets-j6xwd, resource: bindings, ignored listing per whitelist
Aug 16 13:48:35.313: INFO: namespace e2e-tests-secrets-j6xwd deletion completed in 6.135697999s

• [SLOW TEST:8.247 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:48:35.313: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Aug 16 13:48:35.388: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Aug 16 13:48:35.400: INFO: Waiting for terminating namespaces to be deleted...
Aug 16 13:48:35.403: INFO: 
Logging pods the kubelet thinks is on node worker-72b80c6a-c026-11e9-bfed-069795ba99e0 before test
Aug 16 13:48:35.408: INFO: canal-node-1-13-6-6x8bh from vke-system started at 2019-08-16 13:07:21 +0000 UTC (3 container statuses recorded)
Aug 16 13:48:35.408: INFO: 	Container calico-node ready: true, restart count 0
Aug 16 13:48:35.408: INFO: 	Container flannel ready: true, restart count 0
Aug 16 13:48:35.408: INFO: 	Container install-calico-cni ready: true, restart count 0
Aug 16 13:48:35.408: INFO: sonobuoy-e2e-job-09d0aca292374f31 from sonobuoy started at 2019-08-16 13:07:46 +0000 UTC (2 container statuses recorded)
Aug 16 13:48:35.408: INFO: 	Container e2e ready: true, restart count 0
Aug 16 13:48:35.408: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 16 13:48:35.408: INFO: sonobuoy from sonobuoy started at 2019-08-16 13:07:41 +0000 UTC (1 container statuses recorded)
Aug 16 13:48:35.408: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Aug 16 13:48:35.408: INFO: 
Logging pods the kubelet thinks is on node worker-eab92000-c026-11e9-bfed-069795ba99e0 before test
Aug 16 13:48:35.413: INFO: canal-node-1-13-6-4z9rh from vke-system started at 2019-08-16 13:10:22 +0000 UTC (3 container statuses recorded)
Aug 16 13:48:35.413: INFO: 	Container calico-node ready: true, restart count 0
Aug 16 13:48:35.413: INFO: 	Container flannel ready: true, restart count 0
Aug 16 13:48:35.413: INFO: 	Container install-calico-cni ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15bb6b56a6fe64f2], Reason = [FailedScheduling], Message = [0/5 nodes are available: 5 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:48:36.438: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-c9rrc" for this suite.
Aug 16 13:48:42.456: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:48:42.554: INFO: namespace: e2e-tests-sched-pred-c9rrc, resource: bindings, ignored listing per whitelist
Aug 16 13:48:42.568: INFO: namespace e2e-tests-sched-pred-c9rrc deletion completed in 6.126076838s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:7.255 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:48:42.568: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug 16 13:48:42.627: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8f436ade-c02c-11e9-99f6-8a077000b195" in namespace "e2e-tests-downward-api-qkllx" to be "success or failure"
Aug 16 13:48:42.630: INFO: Pod "downwardapi-volume-8f436ade-c02c-11e9-99f6-8a077000b195": Phase="Pending", Reason="", readiness=false. Elapsed: 3.072733ms
Aug 16 13:48:44.641: INFO: Pod "downwardapi-volume-8f436ade-c02c-11e9-99f6-8a077000b195": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01370564s
STEP: Saw pod success
Aug 16 13:48:44.641: INFO: Pod "downwardapi-volume-8f436ade-c02c-11e9-99f6-8a077000b195" satisfied condition "success or failure"
Aug 16 13:48:44.644: INFO: Trying to get logs from node worker-eab92000-c026-11e9-bfed-069795ba99e0 pod downwardapi-volume-8f436ade-c02c-11e9-99f6-8a077000b195 container client-container: <nil>
STEP: delete the pod
Aug 16 13:48:44.669: INFO: Waiting for pod downwardapi-volume-8f436ade-c02c-11e9-99f6-8a077000b195 to disappear
Aug 16 13:48:44.675: INFO: Pod downwardapi-volume-8f436ade-c02c-11e9-99f6-8a077000b195 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:48:44.675: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-qkllx" for this suite.
Aug 16 13:48:50.692: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:48:50.793: INFO: namespace: e2e-tests-downward-api-qkllx, resource: bindings, ignored listing per whitelist
Aug 16 13:48:50.807: INFO: namespace e2e-tests-downward-api-qkllx deletion completed in 6.128012005s

• [SLOW TEST:8.239 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:48:50.807: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Aug 16 13:48:50.877: INFO: Waiting up to 5m0s for pod "downward-api-942df86a-c02c-11e9-99f6-8a077000b195" in namespace "e2e-tests-downward-api-xd8qn" to be "success or failure"
Aug 16 13:48:50.884: INFO: Pod "downward-api-942df86a-c02c-11e9-99f6-8a077000b195": Phase="Pending", Reason="", readiness=false. Elapsed: 6.984269ms
Aug 16 13:48:52.890: INFO: Pod "downward-api-942df86a-c02c-11e9-99f6-8a077000b195": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012552398s
STEP: Saw pod success
Aug 16 13:48:52.890: INFO: Pod "downward-api-942df86a-c02c-11e9-99f6-8a077000b195" satisfied condition "success or failure"
Aug 16 13:48:52.894: INFO: Trying to get logs from node worker-eab92000-c026-11e9-bfed-069795ba99e0 pod downward-api-942df86a-c02c-11e9-99f6-8a077000b195 container dapi-container: <nil>
STEP: delete the pod
Aug 16 13:48:52.919: INFO: Waiting for pod downward-api-942df86a-c02c-11e9-99f6-8a077000b195 to disappear
Aug 16 13:48:52.923: INFO: Pod downward-api-942df86a-c02c-11e9-99f6-8a077000b195 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:48:52.923: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-xd8qn" for this suite.
Aug 16 13:48:58.944: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:48:59.033: INFO: namespace: e2e-tests-downward-api-xd8qn, resource: bindings, ignored listing per whitelist
Aug 16 13:48:59.052: INFO: namespace e2e-tests-downward-api-xd8qn deletion completed in 6.124799698s

• [SLOW TEST:8.244 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:48:59.052: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Aug 16 13:48:59.108: INFO: Waiting up to 5m0s for pod "pod-99169a22-c02c-11e9-99f6-8a077000b195" in namespace "e2e-tests-emptydir-xvjld" to be "success or failure"
Aug 16 13:48:59.114: INFO: Pod "pod-99169a22-c02c-11e9-99f6-8a077000b195": Phase="Pending", Reason="", readiness=false. Elapsed: 5.203415ms
Aug 16 13:49:01.117: INFO: Pod "pod-99169a22-c02c-11e9-99f6-8a077000b195": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00862068s
STEP: Saw pod success
Aug 16 13:49:01.117: INFO: Pod "pod-99169a22-c02c-11e9-99f6-8a077000b195" satisfied condition "success or failure"
Aug 16 13:49:01.121: INFO: Trying to get logs from node worker-eab92000-c026-11e9-bfed-069795ba99e0 pod pod-99169a22-c02c-11e9-99f6-8a077000b195 container test-container: <nil>
STEP: delete the pod
Aug 16 13:49:01.147: INFO: Waiting for pod pod-99169a22-c02c-11e9-99f6-8a077000b195 to disappear
Aug 16 13:49:01.150: INFO: Pod pod-99169a22-c02c-11e9-99f6-8a077000b195 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:49:01.150: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-xvjld" for this suite.
Aug 16 13:49:07.168: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:49:07.246: INFO: namespace: e2e-tests-emptydir-xvjld, resource: bindings, ignored listing per whitelist
Aug 16 13:49:07.288: INFO: namespace e2e-tests-emptydir-xvjld deletion completed in 6.133801056s

• [SLOW TEST:8.236 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:49:07.288: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Aug 16 13:49:09.877: INFO: Successfully updated pod "labelsupdate9dff59ca-c02c-11e9-99f6-8a077000b195"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:49:13.906: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-5vmqp" for this suite.
Aug 16 13:49:35.924: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:49:36.041: INFO: namespace: e2e-tests-projected-5vmqp, resource: bindings, ignored listing per whitelist
Aug 16 13:49:36.049: INFO: namespace e2e-tests-projected-5vmqp deletion completed in 22.139339469s

• [SLOW TEST:28.761 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:49:36.049: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug 16 13:49:36.108: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Aug 16 13:49:41.118: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Aug 16 13:49:41.119: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Aug 16 13:49:41.138: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-jq6qt,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-jq6qt/deployments/test-cleanup-deployment,UID:b2204138-c02c-11e9-ae7d-02d5aa9cbbca,ResourceVersion:29191,Generation:1,CreationTimestamp:2019-08-16 13:49:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Aug 16 13:49:41.142: INFO: New ReplicaSet "test-cleanup-deployment-7dbbfcf846" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-7dbbfcf846,GenerateName:,Namespace:e2e-tests-deployment-jq6qt,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-jq6qt/replicasets/test-cleanup-deployment-7dbbfcf846,UID:b22290db-c02c-11e9-ae7d-02d5aa9cbbca,ResourceVersion:29193,Generation:1,CreationTimestamp:2019-08-16 13:49:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 7dbbfcf846,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment b2204138-c02c-11e9-ae7d-02d5aa9cbbca 0xc002067fb7 0xc002067fb8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 7dbbfcf846,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 7dbbfcf846,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:0,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug 16 13:49:41.142: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Aug 16 13:49:41.142: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller,GenerateName:,Namespace:e2e-tests-deployment-jq6qt,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-jq6qt/replicasets/test-cleanup-controller,UID:af218fde-c02c-11e9-ae7d-02d5aa9cbbca,ResourceVersion:29192,Generation:1,CreationTimestamp:2019-08-16 13:49:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment b2204138-c02c-11e9-ae7d-02d5aa9cbbca 0xc002067d37 0xc002067d38}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Aug 16 13:49:41.147: INFO: Pod "test-cleanup-controller-q8p5r" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller-q8p5r,GenerateName:test-cleanup-controller-,Namespace:e2e-tests-deployment-jq6qt,SelfLink:/api/v1/namespaces/e2e-tests-deployment-jq6qt/pods/test-cleanup-controller-q8p5r,UID:af2327e8-c02c-11e9-ae7d-02d5aa9cbbca,ResourceVersion:29178,Generation:0,CreationTimestamp:2019-08-16 13:49:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.4.135/32,},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-controller af218fde-c02c-11e9-ae7d-02d5aa9cbbca 0xc001d41167 0xc001d41168}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9ltbk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9ltbk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9ltbk true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-eab92000-c026-11e9-bfed-069795ba99e0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001d411d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001d411f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 13:49:36 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 13:49:37 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 13:49:37 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 13:49:36 +0000 UTC  }],Message:,Reason:,HostIP:10.1.161.42,PodIP:10.2.4.135,StartTime:2019-08-16 13:49:36 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-16 13:49:36 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://8bf1434298f24432eb3f7f326a2bd3b0f392a4768d412064390796322a8dbfcf}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:49:41.147: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-jq6qt" for this suite.
Aug 16 13:49:47.181: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:49:47.207: INFO: namespace: e2e-tests-deployment-jq6qt, resource: bindings, ignored listing per whitelist
Aug 16 13:49:47.293: INFO: namespace e2e-tests-deployment-jq6qt deletion completed in 6.137883538s

• [SLOW TEST:11.244 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:49:47.293: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-b5d9154e-c02c-11e9-99f6-8a077000b195
STEP: Creating a pod to test consume secrets
Aug 16 13:49:47.363: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-b5d9bb18-c02c-11e9-99f6-8a077000b195" in namespace "e2e-tests-projected-zbr2n" to be "success or failure"
Aug 16 13:49:47.368: INFO: Pod "pod-projected-secrets-b5d9bb18-c02c-11e9-99f6-8a077000b195": Phase="Pending", Reason="", readiness=false. Elapsed: 4.46545ms
Aug 16 13:49:49.371: INFO: Pod "pod-projected-secrets-b5d9bb18-c02c-11e9-99f6-8a077000b195": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008216461s
STEP: Saw pod success
Aug 16 13:49:49.371: INFO: Pod "pod-projected-secrets-b5d9bb18-c02c-11e9-99f6-8a077000b195" satisfied condition "success or failure"
Aug 16 13:49:49.374: INFO: Trying to get logs from node worker-eab92000-c026-11e9-bfed-069795ba99e0 pod pod-projected-secrets-b5d9bb18-c02c-11e9-99f6-8a077000b195 container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug 16 13:49:49.402: INFO: Waiting for pod pod-projected-secrets-b5d9bb18-c02c-11e9-99f6-8a077000b195 to disappear
Aug 16 13:49:49.407: INFO: Pod pod-projected-secrets-b5d9bb18-c02c-11e9-99f6-8a077000b195 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:49:49.407: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-zbr2n" for this suite.
Aug 16 13:49:55.424: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:49:55.451: INFO: namespace: e2e-tests-projected-zbr2n, resource: bindings, ignored listing per whitelist
Aug 16 13:49:55.535: INFO: namespace e2e-tests-projected-zbr2n deletion completed in 6.123378225s

• [SLOW TEST:8.242 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:49:55.535: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Aug 16 13:49:58.127: INFO: Successfully updated pod "annotationupdatebac213d5-c02c-11e9-99f6-8a077000b195"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:50:02.166: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-nz6xj" for this suite.
Aug 16 13:50:24.194: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:50:24.205: INFO: namespace: e2e-tests-projected-nz6xj, resource: bindings, ignored listing per whitelist
Aug 16 13:50:24.308: INFO: namespace e2e-tests-projected-nz6xj deletion completed in 22.137849027s

• [SLOW TEST:28.773 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:50:24.308: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Aug 16 13:50:24.363: INFO: Waiting up to 5m0s for pod "pod-cbe7765f-c02c-11e9-99f6-8a077000b195" in namespace "e2e-tests-emptydir-gt6wn" to be "success or failure"
Aug 16 13:50:24.367: INFO: Pod "pod-cbe7765f-c02c-11e9-99f6-8a077000b195": Phase="Pending", Reason="", readiness=false. Elapsed: 3.795395ms
Aug 16 13:50:26.371: INFO: Pod "pod-cbe7765f-c02c-11e9-99f6-8a077000b195": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007697464s
STEP: Saw pod success
Aug 16 13:50:26.371: INFO: Pod "pod-cbe7765f-c02c-11e9-99f6-8a077000b195" satisfied condition "success or failure"
Aug 16 13:50:26.374: INFO: Trying to get logs from node worker-eab92000-c026-11e9-bfed-069795ba99e0 pod pod-cbe7765f-c02c-11e9-99f6-8a077000b195 container test-container: <nil>
STEP: delete the pod
Aug 16 13:50:26.397: INFO: Waiting for pod pod-cbe7765f-c02c-11e9-99f6-8a077000b195 to disappear
Aug 16 13:50:26.407: INFO: Pod pod-cbe7765f-c02c-11e9-99f6-8a077000b195 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:50:26.407: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-gt6wn" for this suite.
Aug 16 13:50:32.427: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:50:32.449: INFO: namespace: e2e-tests-emptydir-gt6wn, resource: bindings, ignored listing per whitelist
Aug 16 13:50:32.553: INFO: namespace e2e-tests-emptydir-gt6wn deletion completed in 6.142581197s

• [SLOW TEST:8.245 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:50:32.554: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug 16 13:50:32.666: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d0da8721-c02c-11e9-99f6-8a077000b195" in namespace "e2e-tests-downward-api-lqchq" to be "success or failure"
Aug 16 13:50:32.672: INFO: Pod "downwardapi-volume-d0da8721-c02c-11e9-99f6-8a077000b195": Phase="Pending", Reason="", readiness=false. Elapsed: 6.101282ms
Aug 16 13:50:34.683: INFO: Pod "downwardapi-volume-d0da8721-c02c-11e9-99f6-8a077000b195": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016563815s
STEP: Saw pod success
Aug 16 13:50:34.683: INFO: Pod "downwardapi-volume-d0da8721-c02c-11e9-99f6-8a077000b195" satisfied condition "success or failure"
Aug 16 13:50:34.686: INFO: Trying to get logs from node worker-eab92000-c026-11e9-bfed-069795ba99e0 pod downwardapi-volume-d0da8721-c02c-11e9-99f6-8a077000b195 container client-container: <nil>
STEP: delete the pod
Aug 16 13:50:34.711: INFO: Waiting for pod downwardapi-volume-d0da8721-c02c-11e9-99f6-8a077000b195 to disappear
Aug 16 13:50:34.716: INFO: Pod downwardapi-volume-d0da8721-c02c-11e9-99f6-8a077000b195 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:50:34.716: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-lqchq" for this suite.
Aug 16 13:50:40.735: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:50:40.806: INFO: namespace: e2e-tests-downward-api-lqchq, resource: bindings, ignored listing per whitelist
Aug 16 13:50:40.844: INFO: namespace e2e-tests-downward-api-lqchq deletion completed in 6.123365506s

• [SLOW TEST:8.290 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:50:40.844: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug 16 13:50:40.900: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d5c30b3d-c02c-11e9-99f6-8a077000b195" in namespace "e2e-tests-projected-nfwgp" to be "success or failure"
Aug 16 13:50:40.905: INFO: Pod "downwardapi-volume-d5c30b3d-c02c-11e9-99f6-8a077000b195": Phase="Pending", Reason="", readiness=false. Elapsed: 4.313566ms
Aug 16 13:50:42.908: INFO: Pod "downwardapi-volume-d5c30b3d-c02c-11e9-99f6-8a077000b195": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008017911s
STEP: Saw pod success
Aug 16 13:50:42.909: INFO: Pod "downwardapi-volume-d5c30b3d-c02c-11e9-99f6-8a077000b195" satisfied condition "success or failure"
Aug 16 13:50:42.912: INFO: Trying to get logs from node worker-eab92000-c026-11e9-bfed-069795ba99e0 pod downwardapi-volume-d5c30b3d-c02c-11e9-99f6-8a077000b195 container client-container: <nil>
STEP: delete the pod
Aug 16 13:50:42.940: INFO: Waiting for pod downwardapi-volume-d5c30b3d-c02c-11e9-99f6-8a077000b195 to disappear
Aug 16 13:50:42.943: INFO: Pod downwardapi-volume-d5c30b3d-c02c-11e9-99f6-8a077000b195 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:50:42.943: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-nfwgp" for this suite.
Aug 16 13:50:48.963: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:50:49.070: INFO: namespace: e2e-tests-projected-nfwgp, resource: bindings, ignored listing per whitelist
Aug 16 13:50:49.076: INFO: namespace e2e-tests-projected-nfwgp deletion completed in 6.128773217s

• [SLOW TEST:8.233 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:50:49.077: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Aug 16 13:50:49.154: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-n2d5w,SelfLink:/api/v1/namespaces/e2e-tests-watch-n2d5w/configmaps/e2e-watch-test-resource-version,UID:daa93100-c02c-11e9-ae7d-02d5aa9cbbca,ResourceVersion:29601,Generation:0,CreationTimestamp:2019-08-16 13:50:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Aug 16 13:50:49.155: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-n2d5w,SelfLink:/api/v1/namespaces/e2e-tests-watch-n2d5w/configmaps/e2e-watch-test-resource-version,UID:daa93100-c02c-11e9-ae7d-02d5aa9cbbca,ResourceVersion:29602,Generation:0,CreationTimestamp:2019-08-16 13:50:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:50:49.155: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-n2d5w" for this suite.
Aug 16 13:50:55.180: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:50:55.214: INFO: namespace: e2e-tests-watch-n2d5w, resource: bindings, ignored listing per whitelist
Aug 16 13:50:55.290: INFO: namespace e2e-tests-watch-n2d5w deletion completed in 6.131161743s

• [SLOW TEST:6.213 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:50:55.290: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-de5f9f29-c02c-11e9-99f6-8a077000b195
STEP: Creating a pod to test consume secrets
Aug 16 13:50:55.389: INFO: Waiting up to 5m0s for pod "pod-secrets-de65a164-c02c-11e9-99f6-8a077000b195" in namespace "e2e-tests-secrets-26h89" to be "success or failure"
Aug 16 13:50:55.392: INFO: Pod "pod-secrets-de65a164-c02c-11e9-99f6-8a077000b195": Phase="Pending", Reason="", readiness=false. Elapsed: 3.491824ms
Aug 16 13:50:57.396: INFO: Pod "pod-secrets-de65a164-c02c-11e9-99f6-8a077000b195": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007286313s
STEP: Saw pod success
Aug 16 13:50:57.396: INFO: Pod "pod-secrets-de65a164-c02c-11e9-99f6-8a077000b195" satisfied condition "success or failure"
Aug 16 13:50:57.399: INFO: Trying to get logs from node worker-eab92000-c026-11e9-bfed-069795ba99e0 pod pod-secrets-de65a164-c02c-11e9-99f6-8a077000b195 container secret-volume-test: <nil>
STEP: delete the pod
Aug 16 13:50:57.422: INFO: Waiting for pod pod-secrets-de65a164-c02c-11e9-99f6-8a077000b195 to disappear
Aug 16 13:50:57.427: INFO: Pod pod-secrets-de65a164-c02c-11e9-99f6-8a077000b195 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:50:57.427: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-26h89" for this suite.
Aug 16 13:51:03.445: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:51:03.502: INFO: namespace: e2e-tests-secrets-26h89, resource: bindings, ignored listing per whitelist
Aug 16 13:51:03.570: INFO: namespace e2e-tests-secrets-26h89 deletion completed in 6.138338352s
STEP: Destroying namespace "e2e-tests-secret-namespace-lpl7l" for this suite.
Aug 16 13:51:09.583: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:51:09.695: INFO: namespace: e2e-tests-secret-namespace-lpl7l, resource: bindings, ignored listing per whitelist
Aug 16 13:51:09.695: INFO: namespace e2e-tests-secret-namespace-lpl7l deletion completed in 6.12555122s

• [SLOW TEST:14.405 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:51:09.696: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Aug 16 13:51:09.744: INFO: namespace e2e-tests-kubectl-wfwtl
Aug 16 13:51:09.744: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 create -f - --namespace=e2e-tests-kubectl-wfwtl'
Aug 16 13:51:10.028: INFO: stderr: ""
Aug 16 13:51:10.028: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Aug 16 13:51:11.032: INFO: Selector matched 1 pods for map[app:redis]
Aug 16 13:51:11.032: INFO: Found 0 / 1
Aug 16 13:51:12.032: INFO: Selector matched 1 pods for map[app:redis]
Aug 16 13:51:12.032: INFO: Found 1 / 1
Aug 16 13:51:12.032: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Aug 16 13:51:12.035: INFO: Selector matched 1 pods for map[app:redis]
Aug 16 13:51:12.035: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Aug 16 13:51:12.035: INFO: wait on redis-master startup in e2e-tests-kubectl-wfwtl 
Aug 16 13:51:12.036: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 logs redis-master-llqcq redis-master --namespace=e2e-tests-kubectl-wfwtl'
Aug 16 13:51:12.106: INFO: stderr: ""
Aug 16 13:51:12.106: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 16 Aug 13:51:10.820 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 16 Aug 13:51:10.820 # Server started, Redis version 3.2.12\n1:M 16 Aug 13:51:10.820 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 16 Aug 13:51:10.820 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Aug 16 13:51:12.106: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-wfwtl'
Aug 16 13:51:12.187: INFO: stderr: ""
Aug 16 13:51:12.187: INFO: stdout: "service/rm2 exposed\n"
Aug 16 13:51:12.200: INFO: Service rm2 in namespace e2e-tests-kubectl-wfwtl found.
STEP: exposing service
Aug 16 13:51:14.206: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-wfwtl'
Aug 16 13:51:14.283: INFO: stderr: ""
Aug 16 13:51:14.283: INFO: stdout: "service/rm3 exposed\n"
Aug 16 13:51:14.287: INFO: Service rm3 in namespace e2e-tests-kubectl-wfwtl found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:51:16.300: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-wfwtl" for this suite.
Aug 16 13:51:38.327: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:51:38.438: INFO: namespace: e2e-tests-kubectl-wfwtl, resource: bindings, ignored listing per whitelist
Aug 16 13:51:38.441: INFO: namespace e2e-tests-kubectl-wfwtl deletion completed in 22.137406629s

• [SLOW TEST:28.745 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:51:38.441: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-f81a2a2a-c02c-11e9-99f6-8a077000b195
STEP: Creating a pod to test consume secrets
Aug 16 13:51:38.519: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-f81acf0f-c02c-11e9-99f6-8a077000b195" in namespace "e2e-tests-projected-wqqnq" to be "success or failure"
Aug 16 13:51:38.523: INFO: Pod "pod-projected-secrets-f81acf0f-c02c-11e9-99f6-8a077000b195": Phase="Pending", Reason="", readiness=false. Elapsed: 3.21014ms
Aug 16 13:51:40.526: INFO: Pod "pod-projected-secrets-f81acf0f-c02c-11e9-99f6-8a077000b195": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007099795s
STEP: Saw pod success
Aug 16 13:51:40.526: INFO: Pod "pod-projected-secrets-f81acf0f-c02c-11e9-99f6-8a077000b195" satisfied condition "success or failure"
Aug 16 13:51:40.529: INFO: Trying to get logs from node worker-eab92000-c026-11e9-bfed-069795ba99e0 pod pod-projected-secrets-f81acf0f-c02c-11e9-99f6-8a077000b195 container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug 16 13:51:40.567: INFO: Waiting for pod pod-projected-secrets-f81acf0f-c02c-11e9-99f6-8a077000b195 to disappear
Aug 16 13:51:40.573: INFO: Pod pod-projected-secrets-f81acf0f-c02c-11e9-99f6-8a077000b195 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:51:40.573: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-wqqnq" for this suite.
Aug 16 13:51:46.590: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:51:46.691: INFO: namespace: e2e-tests-projected-wqqnq, resource: bindings, ignored listing per whitelist
Aug 16 13:51:46.701: INFO: namespace e2e-tests-projected-wqqnq deletion completed in 6.123632195s

• [SLOW TEST:8.259 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:51:46.701: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-hdt28
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
Aug 16 13:51:46.778: INFO: Found 0 stateful pods, waiting for 3
Aug 16 13:51:56.789: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 16 13:51:56.789: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 16 13:51:56.789: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Aug 16 13:51:56.817: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Aug 16 13:52:06.860: INFO: Updating stateful set ss2
Aug 16 13:52:06.866: INFO: Waiting for Pod e2e-tests-statefulset-hdt28/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Aug 16 13:52:16.965: INFO: Found 2 stateful pods, waiting for 3
Aug 16 13:52:26.975: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 16 13:52:26.975: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 16 13:52:26.975: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Aug 16 13:52:27.002: INFO: Updating stateful set ss2
Aug 16 13:52:27.012: INFO: Waiting for Pod e2e-tests-statefulset-hdt28/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Aug 16 13:52:37.044: INFO: Updating stateful set ss2
Aug 16 13:52:37.059: INFO: Waiting for StatefulSet e2e-tests-statefulset-hdt28/ss2 to complete update
Aug 16 13:52:37.059: INFO: Waiting for Pod e2e-tests-statefulset-hdt28/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Aug 16 13:52:47.072: INFO: Deleting all statefulset in ns e2e-tests-statefulset-hdt28
Aug 16 13:52:47.075: INFO: Scaling statefulset ss2 to 0
Aug 16 13:53:07.091: INFO: Waiting for statefulset status.replicas updated to 0
Aug 16 13:53:07.094: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:53:07.119: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-hdt28" for this suite.
Aug 16 13:53:13.137: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:53:13.169: INFO: namespace: e2e-tests-statefulset-hdt28, resource: bindings, ignored listing per whitelist
Aug 16 13:53:13.256: INFO: namespace e2e-tests-statefulset-hdt28 deletion completed in 6.132195921s

• [SLOW TEST:86.555 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:53:13.256: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Aug 16 13:53:17.356: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 16 13:53:17.359: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 16 13:53:19.359: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 16 13:53:19.363: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 16 13:53:21.359: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 16 13:53:21.364: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 16 13:53:23.360: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 16 13:53:23.363: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 16 13:53:25.359: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 16 13:53:25.363: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 16 13:53:27.360: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 16 13:53:27.370: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 16 13:53:29.359: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 16 13:53:29.363: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 16 13:53:31.360: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 16 13:53:31.364: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 16 13:53:33.359: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 16 13:53:33.363: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 16 13:53:35.359: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 16 13:53:35.363: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 16 13:53:37.360: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 16 13:53:37.363: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 16 13:53:39.360: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 16 13:53:39.372: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 16 13:53:41.360: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 16 13:53:41.363: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 16 13:53:43.359: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 16 13:53:43.363: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:53:43.372: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-klws4" for this suite.
Aug 16 13:54:05.394: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:54:05.428: INFO: namespace: e2e-tests-container-lifecycle-hook-klws4, resource: bindings, ignored listing per whitelist
Aug 16 13:54:05.511: INFO: namespace e2e-tests-container-lifecycle-hook-klws4 deletion completed in 22.135156636s

• [SLOW TEST:52.255 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:54:05.511: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Aug 16 13:54:05.560: INFO: PodSpec: initContainers in spec.initContainers
Aug 16 13:54:44.916: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-4fc0b3e1-c02d-11e9-99f6-8a077000b195", GenerateName:"", Namespace:"e2e-tests-init-container-s6hn8", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-s6hn8/pods/pod-init-4fc0b3e1-c02d-11e9-99f6-8a077000b195", UID:"4fc02048-c02d-11e9-ae7d-02d5aa9cbbca", ResourceVersion:"30857", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63701560445, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"time":"560117128", "name":"foo"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"10.2.4.153/32"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-77nb2", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc001a10c00), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-77nb2", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-77nb2", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-77nb2", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc001c09488), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"worker-eab92000-c026-11e9-bfed-069795ba99e0", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc001cf3680), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001c09500)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001c09520)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc001c09528), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc001c0952c)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701560445, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701560445, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701560445, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701560445, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.1.161.42", PodIP:"10.2.4.153", StartTime:(*v1.Time)(0xc000cfc060), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0005b3030)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0005b3180)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://2993f56bd96048969d8d6dd06946e8d2d767557306e724c095fd7fa48996bfcd"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc000cfc0a0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc000cfc080), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:54:44.916: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-s6hn8" for this suite.
Aug 16 13:55:06.954: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:55:07.018: INFO: namespace: e2e-tests-init-container-s6hn8, resource: bindings, ignored listing per whitelist
Aug 16 13:55:07.062: INFO: namespace e2e-tests-init-container-s6hn8 deletion completed in 22.129996532s

• [SLOW TEST:61.551 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:55:07.062: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Aug 16 13:55:11.154: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-qjhql PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 16 13:55:11.154: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
Aug 16 13:55:11.223: INFO: Exec stderr: ""
Aug 16 13:55:11.223: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-qjhql PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 16 13:55:11.223: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
Aug 16 13:55:11.296: INFO: Exec stderr: ""
Aug 16 13:55:11.296: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-qjhql PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 16 13:55:11.296: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
Aug 16 13:55:11.369: INFO: Exec stderr: ""
Aug 16 13:55:11.369: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-qjhql PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 16 13:55:11.369: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
Aug 16 13:55:11.436: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Aug 16 13:55:11.436: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-qjhql PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 16 13:55:11.436: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
Aug 16 13:55:11.503: INFO: Exec stderr: ""
Aug 16 13:55:11.503: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-qjhql PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 16 13:55:11.503: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
Aug 16 13:55:11.580: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Aug 16 13:55:11.580: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-qjhql PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 16 13:55:11.580: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
Aug 16 13:55:11.656: INFO: Exec stderr: ""
Aug 16 13:55:11.656: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-qjhql PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 16 13:55:11.656: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
Aug 16 13:55:11.742: INFO: Exec stderr: ""
Aug 16 13:55:11.742: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-qjhql PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 16 13:55:11.742: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
Aug 16 13:55:11.820: INFO: Exec stderr: ""
Aug 16 13:55:11.820: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-qjhql PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 16 13:55:11.820: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
Aug 16 13:55:11.891: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:55:11.891: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-qjhql" for this suite.
Aug 16 13:55:53.918: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:55:53.981: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-qjhql, resource: bindings, ignored listing per whitelist
Aug 16 13:55:54.030: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-qjhql deletion completed in 42.133295774s

• [SLOW TEST:46.968 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:55:54.030: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
Aug 16 13:55:54.086: INFO: Waiting up to 5m0s for pod "client-containers-906f7288-c02d-11e9-99f6-8a077000b195" in namespace "e2e-tests-containers-r28mk" to be "success or failure"
Aug 16 13:55:54.090: INFO: Pod "client-containers-906f7288-c02d-11e9-99f6-8a077000b195": Phase="Pending", Reason="", readiness=false. Elapsed: 3.808944ms
Aug 16 13:55:56.093: INFO: Pod "client-containers-906f7288-c02d-11e9-99f6-8a077000b195": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007405321s
STEP: Saw pod success
Aug 16 13:55:56.093: INFO: Pod "client-containers-906f7288-c02d-11e9-99f6-8a077000b195" satisfied condition "success or failure"
Aug 16 13:55:56.097: INFO: Trying to get logs from node worker-eab92000-c026-11e9-bfed-069795ba99e0 pod client-containers-906f7288-c02d-11e9-99f6-8a077000b195 container test-container: <nil>
STEP: delete the pod
Aug 16 13:55:56.118: INFO: Waiting for pod client-containers-906f7288-c02d-11e9-99f6-8a077000b195 to disappear
Aug 16 13:55:56.124: INFO: Pod client-containers-906f7288-c02d-11e9-99f6-8a077000b195 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:55:56.125: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-r28mk" for this suite.
Aug 16 13:56:02.142: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:56:02.160: INFO: namespace: e2e-tests-containers-r28mk, resource: bindings, ignored listing per whitelist
Aug 16 13:56:02.258: INFO: namespace e2e-tests-containers-r28mk deletion completed in 6.12961445s

• [SLOW TEST:8.228 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:56:02.258: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-9557dd78-c02d-11e9-99f6-8a077000b195
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:56:04.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-lswjn" for this suite.
Aug 16 13:56:26.387: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:56:26.397: INFO: namespace: e2e-tests-configmap-lswjn, resource: bindings, ignored listing per whitelist
Aug 16 13:56:26.508: INFO: namespace e2e-tests-configmap-lswjn deletion completed in 22.145147047s

• [SLOW TEST:24.249 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:56:26.508: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1527
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug 16 13:56:26.564: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-6nkcl'
Aug 16 13:56:26.642: INFO: stderr: ""
Aug 16 13:56:26.642: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1532
Aug 16 13:56:26.649: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-6nkcl'
Aug 16 13:56:32.209: INFO: stderr: ""
Aug 16 13:56:32.209: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:56:32.209: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-6nkcl" for this suite.
Aug 16 13:56:38.233: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:56:38.297: INFO: namespace: e2e-tests-kubectl-6nkcl, resource: bindings, ignored listing per whitelist
Aug 16 13:56:38.345: INFO: namespace e2e-tests-kubectl-6nkcl deletion completed in 6.131061375s

• [SLOW TEST:11.837 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:56:38.345: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-78j98
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
Aug 16 13:56:38.473: INFO: Found 0 stateful pods, waiting for 3
Aug 16 13:56:48.483: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 16 13:56:48.483: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 16 13:56:48.483: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Aug 16 13:56:48.493: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 exec --namespace=e2e-tests-statefulset-78j98 ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 16 13:56:48.625: INFO: stderr: ""
Aug 16 13:56:48.625: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 16 13:56:48.625: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Aug 16 13:56:58.666: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Aug 16 13:57:08.690: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 exec --namespace=e2e-tests-statefulset-78j98 ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 16 13:57:08.822: INFO: stderr: ""
Aug 16 13:57:08.822: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 16 13:57:08.822: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 16 13:57:18.848: INFO: Waiting for StatefulSet e2e-tests-statefulset-78j98/ss2 to complete update
Aug 16 13:57:18.848: INFO: Waiting for Pod e2e-tests-statefulset-78j98/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Aug 16 13:57:18.848: INFO: Waiting for Pod e2e-tests-statefulset-78j98/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Aug 16 13:57:18.848: INFO: Waiting for Pod e2e-tests-statefulset-78j98/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
Aug 16 13:57:28.862: INFO: Waiting for StatefulSet e2e-tests-statefulset-78j98/ss2 to complete update
Aug 16 13:57:28.862: INFO: Waiting for Pod e2e-tests-statefulset-78j98/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Aug 16 13:57:28.862: INFO: Waiting for Pod e2e-tests-statefulset-78j98/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Aug 16 13:57:38.855: INFO: Waiting for StatefulSet e2e-tests-statefulset-78j98/ss2 to complete update
Aug 16 13:57:38.855: INFO: Waiting for Pod e2e-tests-statefulset-78j98/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Rolling back to a previous revision
Aug 16 13:57:48.861: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 exec --namespace=e2e-tests-statefulset-78j98 ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 16 13:57:49.000: INFO: stderr: ""
Aug 16 13:57:49.000: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 16 13:57:49.000: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 16 13:57:59.041: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Aug 16 13:58:09.066: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 exec --namespace=e2e-tests-statefulset-78j98 ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 16 13:58:09.199: INFO: stderr: ""
Aug 16 13:58:09.199: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 16 13:58:09.199: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 16 13:58:19.226: INFO: Waiting for StatefulSet e2e-tests-statefulset-78j98/ss2 to complete update
Aug 16 13:58:19.226: INFO: Waiting for Pod e2e-tests-statefulset-78j98/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Aug 16 13:58:19.226: INFO: Waiting for Pod e2e-tests-statefulset-78j98/ss2-1 to have revision ss2-787997d666 update revision ss2-c79899b9
Aug 16 13:58:19.226: INFO: Waiting for Pod e2e-tests-statefulset-78j98/ss2-2 to have revision ss2-787997d666 update revision ss2-c79899b9
Aug 16 13:58:29.240: INFO: Waiting for StatefulSet e2e-tests-statefulset-78j98/ss2 to complete update
Aug 16 13:58:29.240: INFO: Waiting for Pod e2e-tests-statefulset-78j98/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Aug 16 13:58:29.240: INFO: Waiting for Pod e2e-tests-statefulset-78j98/ss2-1 to have revision ss2-787997d666 update revision ss2-c79899b9
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Aug 16 13:58:39.237: INFO: Deleting all statefulset in ns e2e-tests-statefulset-78j98
Aug 16 13:58:39.247: INFO: Scaling statefulset ss2 to 0
Aug 16 13:58:59.261: INFO: Waiting for statefulset status.replicas updated to 0
Aug 16 13:58:59.265: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:58:59.290: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-78j98" for this suite.
Aug 16 13:59:05.310: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:59:05.358: INFO: namespace: e2e-tests-statefulset-78j98, resource: bindings, ignored listing per whitelist
Aug 16 13:59:05.425: INFO: namespace e2e-tests-statefulset-78j98 deletion completed in 6.130022342s

• [SLOW TEST:147.080 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:59:05.425: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-0284875b-c02e-11e9-99f6-8a077000b195
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-0284875b-c02e-11e9-99f6-8a077000b195
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:59:09.541: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-mcszx" for this suite.
Aug 16 13:59:31.565: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:59:31.577: INFO: namespace: e2e-tests-configmap-mcszx, resource: bindings, ignored listing per whitelist
Aug 16 13:59:31.684: INFO: namespace e2e-tests-configmap-mcszx deletion completed in 22.139407596s

• [SLOW TEST:26.259 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:59:31.685: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug 16 13:59:31.741: INFO: Waiting up to 5m0s for pod "downwardapi-volume-122ae2fd-c02e-11e9-99f6-8a077000b195" in namespace "e2e-tests-downward-api-f7vbv" to be "success or failure"
Aug 16 13:59:31.746: INFO: Pod "downwardapi-volume-122ae2fd-c02e-11e9-99f6-8a077000b195": Phase="Pending", Reason="", readiness=false. Elapsed: 4.54232ms
Aug 16 13:59:33.750: INFO: Pod "downwardapi-volume-122ae2fd-c02e-11e9-99f6-8a077000b195": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008410914s
STEP: Saw pod success
Aug 16 13:59:33.750: INFO: Pod "downwardapi-volume-122ae2fd-c02e-11e9-99f6-8a077000b195" satisfied condition "success or failure"
Aug 16 13:59:33.753: INFO: Trying to get logs from node worker-eab92000-c026-11e9-bfed-069795ba99e0 pod downwardapi-volume-122ae2fd-c02e-11e9-99f6-8a077000b195 container client-container: <nil>
STEP: delete the pod
Aug 16 13:59:33.778: INFO: Waiting for pod downwardapi-volume-122ae2fd-c02e-11e9-99f6-8a077000b195 to disappear
Aug 16 13:59:33.785: INFO: Pod downwardapi-volume-122ae2fd-c02e-11e9-99f6-8a077000b195 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 13:59:33.785: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-f7vbv" for this suite.
Aug 16 13:59:39.803: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 13:59:39.907: INFO: namespace: e2e-tests-downward-api-f7vbv, resource: bindings, ignored listing per whitelist
Aug 16 13:59:39.910: INFO: namespace e2e-tests-downward-api-f7vbv deletion completed in 6.120742125s

• [SLOW TEST:8.225 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 13:59:39.910: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 14:00:05.298: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-runtime-278qh" for this suite.
Aug 16 14:00:11.316: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 14:00:11.419: INFO: namespace: e2e-tests-container-runtime-278qh, resource: bindings, ignored listing per whitelist
Aug 16 14:00:11.430: INFO: namespace e2e-tests-container-runtime-278qh deletion completed in 6.127927294s

• [SLOW TEST:31.520 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  blackbox test
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37
    when starting a container that exits
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 14:00:11.430: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug 16 14:00:11.513: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"29da4d7e-c02e-11e9-ae7d-02d5aa9cbbca", Controller:(*bool)(0xc00205f6c6), BlockOwnerDeletion:(*bool)(0xc00205f6c7)}}
Aug 16 14:00:11.519: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"29d888b5-c02e-11e9-ae7d-02d5aa9cbbca", Controller:(*bool)(0xc001b7fd5e), BlockOwnerDeletion:(*bool)(0xc001b7fd5f)}}
Aug 16 14:00:11.529: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"29d95df4-c02e-11e9-ae7d-02d5aa9cbbca", Controller:(*bool)(0xc00205f99e), BlockOwnerDeletion:(*bool)(0xc00205f99f)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 14:00:16.551: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-8x9l8" for this suite.
Aug 16 14:00:22.568: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 14:00:22.626: INFO: namespace: e2e-tests-gc-8x9l8, resource: bindings, ignored listing per whitelist
Aug 16 14:00:22.691: INFO: namespace e2e-tests-gc-8x9l8 deletion completed in 6.135772024s

• [SLOW TEST:11.260 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 14:00:22.691: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 14:00:22.821: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-mqnw8" for this suite.
Aug 16 14:00:44.850: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 14:00:44.868: INFO: namespace: e2e-tests-pods-mqnw8, resource: bindings, ignored listing per whitelist
Aug 16 14:00:44.965: INFO: namespace e2e-tests-pods-mqnw8 deletion completed in 22.1370115s

• [SLOW TEST:22.274 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 14:00:44.965: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug 16 14:00:45.066: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 14:00:51.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-sc96r" for this suite.
Aug 16 14:00:57.130: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 14:00:57.213: INFO: namespace: e2e-tests-custom-resource-definition-sc96r, resource: bindings, ignored listing per whitelist
Aug 16 14:00:57.242: INFO: namespace e2e-tests-custom-resource-definition-sc96r deletion completed in 6.125618589s

• [SLOW TEST:12.277 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 14:00:57.242: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0816 14:01:07.327429      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Aug 16 14:01:07.327: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 14:01:07.327: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-8jhpq" for this suite.
Aug 16 14:01:13.351: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 14:01:13.444: INFO: namespace: e2e-tests-gc-8jhpq, resource: bindings, ignored listing per whitelist
Aug 16 14:01:13.470: INFO: namespace e2e-tests-gc-8jhpq deletion completed in 6.139206893s

• [SLOW TEST:16.228 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 14:01:13.470: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Aug 16 14:01:13.542: INFO: Waiting up to 5m0s for pod "pod-4ed76ebf-c02e-11e9-99f6-8a077000b195" in namespace "e2e-tests-emptydir-6t87x" to be "success or failure"
Aug 16 14:01:13.550: INFO: Pod "pod-4ed76ebf-c02e-11e9-99f6-8a077000b195": Phase="Pending", Reason="", readiness=false. Elapsed: 8.663896ms
Aug 16 14:01:15.554: INFO: Pod "pod-4ed76ebf-c02e-11e9-99f6-8a077000b195": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012494036s
STEP: Saw pod success
Aug 16 14:01:15.554: INFO: Pod "pod-4ed76ebf-c02e-11e9-99f6-8a077000b195" satisfied condition "success or failure"
Aug 16 14:01:15.557: INFO: Trying to get logs from node worker-eab92000-c026-11e9-bfed-069795ba99e0 pod pod-4ed76ebf-c02e-11e9-99f6-8a077000b195 container test-container: <nil>
STEP: delete the pod
Aug 16 14:01:15.590: INFO: Waiting for pod pod-4ed76ebf-c02e-11e9-99f6-8a077000b195 to disappear
Aug 16 14:01:15.593: INFO: Pod pod-4ed76ebf-c02e-11e9-99f6-8a077000b195 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 14:01:15.593: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-6t87x" for this suite.
Aug 16 14:01:21.613: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 14:01:21.641: INFO: namespace: e2e-tests-emptydir-6t87x, resource: bindings, ignored listing per whitelist
Aug 16 14:01:21.745: INFO: namespace e2e-tests-emptydir-6t87x deletion completed in 6.14722024s

• [SLOW TEST:8.275 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 14:01:21.745: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Aug 16 14:01:21.808: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 14:01:25.191: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-62qf9" for this suite.
Aug 16 14:01:47.225: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 14:01:47.235: INFO: namespace: e2e-tests-init-container-62qf9, resource: bindings, ignored listing per whitelist
Aug 16 14:01:47.337: INFO: namespace e2e-tests-init-container-62qf9 deletion completed in 22.134413539s

• [SLOW TEST:25.592 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 14:01:47.338: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-7p9k2/secret-test-6305a1e4-c02e-11e9-99f6-8a077000b195
STEP: Creating a pod to test consume secrets
Aug 16 14:01:47.399: INFO: Waiting up to 5m0s for pod "pod-configmaps-6306393d-c02e-11e9-99f6-8a077000b195" in namespace "e2e-tests-secrets-7p9k2" to be "success or failure"
Aug 16 14:01:47.407: INFO: Pod "pod-configmaps-6306393d-c02e-11e9-99f6-8a077000b195": Phase="Pending", Reason="", readiness=false. Elapsed: 7.344319ms
Aug 16 14:01:49.411: INFO: Pod "pod-configmaps-6306393d-c02e-11e9-99f6-8a077000b195": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011245486s
STEP: Saw pod success
Aug 16 14:01:49.411: INFO: Pod "pod-configmaps-6306393d-c02e-11e9-99f6-8a077000b195" satisfied condition "success or failure"
Aug 16 14:01:49.414: INFO: Trying to get logs from node worker-eab92000-c026-11e9-bfed-069795ba99e0 pod pod-configmaps-6306393d-c02e-11e9-99f6-8a077000b195 container env-test: <nil>
STEP: delete the pod
Aug 16 14:01:49.439: INFO: Waiting for pod pod-configmaps-6306393d-c02e-11e9-99f6-8a077000b195 to disappear
Aug 16 14:01:49.445: INFO: Pod pod-configmaps-6306393d-c02e-11e9-99f6-8a077000b195 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 14:01:49.445: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-7p9k2" for this suite.
Aug 16 14:01:55.463: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 14:01:55.513: INFO: namespace: e2e-tests-secrets-7p9k2, resource: bindings, ignored listing per whitelist
Aug 16 14:01:55.574: INFO: namespace e2e-tests-secrets-7p9k2 deletion completed in 6.125114974s

• [SLOW TEST:8.236 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 14:01:55.574: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 14:01:55.626: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-pk8rx" for this suite.
Aug 16 14:02:01.650: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 14:02:01.662: INFO: namespace: e2e-tests-services-pk8rx, resource: bindings, ignored listing per whitelist
Aug 16 14:02:01.762: INFO: namespace e2e-tests-services-pk8rx deletion completed in 6.131884387s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:6.188 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 14:02:01.763: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Aug 16 14:02:04.349: INFO: Successfully updated pod "pod-update-6b9f9c35-c02e-11e9-99f6-8a077000b195"
STEP: verifying the updated pod is in kubernetes
Aug 16 14:02:04.356: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 14:02:04.356: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-f6xhr" for this suite.
Aug 16 14:02:26.373: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 14:02:26.464: INFO: namespace: e2e-tests-pods-f6xhr, resource: bindings, ignored listing per whitelist
Aug 16 14:02:26.483: INFO: namespace e2e-tests-pods-f6xhr deletion completed in 22.123008999s

• [SLOW TEST:24.720 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 14:02:26.483: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
Aug 16 14:02:26.535: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Aug 16 14:02:26.536: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 create -f - --namespace=e2e-tests-kubectl-pz7cs'
Aug 16 14:02:26.843: INFO: stderr: ""
Aug 16 14:02:26.843: INFO: stdout: "service/redis-slave created\n"
Aug 16 14:02:26.843: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Aug 16 14:02:26.843: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 create -f - --namespace=e2e-tests-kubectl-pz7cs'
Aug 16 14:02:26.999: INFO: stderr: ""
Aug 16 14:02:26.999: INFO: stdout: "service/redis-master created\n"
Aug 16 14:02:26.999: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Aug 16 14:02:26.999: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 create -f - --namespace=e2e-tests-kubectl-pz7cs'
Aug 16 14:02:27.153: INFO: stderr: ""
Aug 16 14:02:27.153: INFO: stdout: "service/frontend created\n"
Aug 16 14:02:27.153: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Aug 16 14:02:27.153: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 create -f - --namespace=e2e-tests-kubectl-pz7cs'
Aug 16 14:02:27.312: INFO: stderr: ""
Aug 16 14:02:27.312: INFO: stdout: "deployment.extensions/frontend created\n"
Aug 16 14:02:27.313: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Aug 16 14:02:27.313: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 create -f - --namespace=e2e-tests-kubectl-pz7cs'
Aug 16 14:02:27.447: INFO: stderr: ""
Aug 16 14:02:27.447: INFO: stdout: "deployment.extensions/redis-master created\n"
Aug 16 14:02:27.447: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Aug 16 14:02:27.447: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 create -f - --namespace=e2e-tests-kubectl-pz7cs'
Aug 16 14:02:27.570: INFO: stderr: ""
Aug 16 14:02:27.570: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Aug 16 14:02:27.570: INFO: Waiting for all frontend pods to be Running.
Aug 16 14:02:42.621: INFO: Waiting for frontend to serve content.
Aug 16 14:02:47.644: INFO: Failed to get response from guestbook. err: <nil>, response: <br />
<b>Fatal error</b>:  Uncaught exception 'Predis\Connection\ConnectionException' with message 'Connection timed out [tcp://redis-slave:6379]' in /usr/local/lib/php/Predis/Connection/AbstractConnection.php:155
Stack trace:
#0 /usr/local/lib/php/Predis/Connection/StreamConnection.php(128): Predis\Connection\AbstractConnection-&gt;onConnectionError('Connection time...', 110)
#1 /usr/local/lib/php/Predis/Connection/StreamConnection.php(178): Predis\Connection\StreamConnection-&gt;createStreamSocket(Object(Predis\Connection\Parameters), 'tcp://redis-sla...', 4)
#2 /usr/local/lib/php/Predis/Connection/StreamConnection.php(100): Predis\Connection\StreamConnection-&gt;tcpStreamInitializer(Object(Predis\Connection\Parameters))
#3 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(81): Predis\Connection\StreamConnection-&gt;createResource()
#4 /usr/local/lib/php/Predis/Connection/StreamConnection.php(258): Predis\Connection\AbstractConnection-&gt;connect()
#5 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(180): Predis\Connection\Stre in <b>/usr/local/lib/php/Predis/Connection/AbstractConnection.php</b> on line <b>155</b><br />

Aug 16 14:02:52.662: INFO: Trying to add a new entry to the guestbook.
Aug 16 14:02:52.671: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Aug 16 14:02:52.680: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-pz7cs'
Aug 16 14:02:52.764: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 16 14:02:52.764: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Aug 16 14:02:52.764: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-pz7cs'
Aug 16 14:02:52.870: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 16 14:02:52.870: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Aug 16 14:02:52.870: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-pz7cs'
Aug 16 14:02:52.964: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 16 14:02:52.964: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Aug 16 14:02:52.964: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-pz7cs'
Aug 16 14:02:53.043: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 16 14:02:53.043: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Aug 16 14:02:53.043: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-pz7cs'
Aug 16 14:02:53.141: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 16 14:02:53.141: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Aug 16 14:02:53.141: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-pz7cs'
Aug 16 14:02:53.210: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 16 14:02:53.210: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 14:02:53.210: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-pz7cs" for this suite.
Aug 16 14:03:33.237: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 14:03:33.246: INFO: namespace: e2e-tests-kubectl-pz7cs, resource: bindings, ignored listing per whitelist
Aug 16 14:03:33.353: INFO: namespace e2e-tests-kubectl-pz7cs deletion completed in 40.136569796s

• [SLOW TEST:66.870 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 14:03:33.353: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-5tq2s A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-5tq2s;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-5tq2s A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-5tq2s;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-5tq2s.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-5tq2s.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-5tq2s.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-5tq2s.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-5tq2s.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-5tq2s.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-5tq2s.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-5tq2s.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-5tq2s.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-5tq2s.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-5tq2s.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-5tq2s.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-5tq2s.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 246.0.0.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.0.0.246_udp@PTR;check="$$(dig +tcp +noall +answer +search 246.0.0.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.0.0.246_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-5tq2s A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-5tq2s;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-5tq2s A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-5tq2s;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-5tq2s.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-5tq2s.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-5tq2s.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-5tq2s.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-5tq2s.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-5tq2s.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-5tq2s.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-5tq2s.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-5tq2s.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-5tq2s.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-5tq2s.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-5tq2s.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-5tq2s.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 246.0.0.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.0.0.246_udp@PTR;check="$$(dig +tcp +noall +answer +search 246.0.0.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.0.0.246_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug 16 14:03:35.459: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-5tq2s/dns-test-a23967f8-c02e-11e9-99f6-8a077000b195: the server could not find the requested resource (get pods dns-test-a23967f8-c02e-11e9-99f6-8a077000b195)
Aug 16 14:03:35.465: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-5tq2s from pod e2e-tests-dns-5tq2s/dns-test-a23967f8-c02e-11e9-99f6-8a077000b195: the server could not find the requested resource (get pods dns-test-a23967f8-c02e-11e9-99f6-8a077000b195)
Aug 16 14:03:35.472: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-5tq2s.svc from pod e2e-tests-dns-5tq2s/dns-test-a23967f8-c02e-11e9-99f6-8a077000b195: the server could not find the requested resource (get pods dns-test-a23967f8-c02e-11e9-99f6-8a077000b195)
Aug 16 14:03:35.478: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-5tq2s.svc from pod e2e-tests-dns-5tq2s/dns-test-a23967f8-c02e-11e9-99f6-8a077000b195: the server could not find the requested resource (get pods dns-test-a23967f8-c02e-11e9-99f6-8a077000b195)
Aug 16 14:03:35.500: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-5tq2s/dns-test-a23967f8-c02e-11e9-99f6-8a077000b195: the server could not find the requested resource (get pods dns-test-a23967f8-c02e-11e9-99f6-8a077000b195)
Aug 16 14:03:35.503: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-5tq2s/dns-test-a23967f8-c02e-11e9-99f6-8a077000b195: the server could not find the requested resource (get pods dns-test-a23967f8-c02e-11e9-99f6-8a077000b195)
Aug 16 14:03:35.506: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-5tq2s from pod e2e-tests-dns-5tq2s/dns-test-a23967f8-c02e-11e9-99f6-8a077000b195: the server could not find the requested resource (get pods dns-test-a23967f8-c02e-11e9-99f6-8a077000b195)
Aug 16 14:03:35.510: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-5tq2s from pod e2e-tests-dns-5tq2s/dns-test-a23967f8-c02e-11e9-99f6-8a077000b195: the server could not find the requested resource (get pods dns-test-a23967f8-c02e-11e9-99f6-8a077000b195)
Aug 16 14:03:35.513: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-5tq2s.svc from pod e2e-tests-dns-5tq2s/dns-test-a23967f8-c02e-11e9-99f6-8a077000b195: the server could not find the requested resource (get pods dns-test-a23967f8-c02e-11e9-99f6-8a077000b195)
Aug 16 14:03:35.516: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-5tq2s.svc from pod e2e-tests-dns-5tq2s/dns-test-a23967f8-c02e-11e9-99f6-8a077000b195: the server could not find the requested resource (get pods dns-test-a23967f8-c02e-11e9-99f6-8a077000b195)
Aug 16 14:03:35.519: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-5tq2s.svc from pod e2e-tests-dns-5tq2s/dns-test-a23967f8-c02e-11e9-99f6-8a077000b195: the server could not find the requested resource (get pods dns-test-a23967f8-c02e-11e9-99f6-8a077000b195)
Aug 16 14:03:35.523: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-5tq2s.svc from pod e2e-tests-dns-5tq2s/dns-test-a23967f8-c02e-11e9-99f6-8a077000b195: the server could not find the requested resource (get pods dns-test-a23967f8-c02e-11e9-99f6-8a077000b195)
Aug 16 14:03:35.542: INFO: Lookups using e2e-tests-dns-5tq2s/dns-test-a23967f8-c02e-11e9-99f6-8a077000b195 failed for: [wheezy_tcp@dns-test-service wheezy_tcp@dns-test-service.e2e-tests-dns-5tq2s wheezy_tcp@dns-test-service.e2e-tests-dns-5tq2s.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-5tq2s.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-5tq2s jessie_tcp@dns-test-service.e2e-tests-dns-5tq2s jessie_udp@dns-test-service.e2e-tests-dns-5tq2s.svc jessie_tcp@dns-test-service.e2e-tests-dns-5tq2s.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-5tq2s.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-5tq2s.svc]

Aug 16 14:03:40.556: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-5tq2s/dns-test-a23967f8-c02e-11e9-99f6-8a077000b195: the server could not find the requested resource (get pods dns-test-a23967f8-c02e-11e9-99f6-8a077000b195)
Aug 16 14:03:40.563: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-5tq2s from pod e2e-tests-dns-5tq2s/dns-test-a23967f8-c02e-11e9-99f6-8a077000b195: the server could not find the requested resource (get pods dns-test-a23967f8-c02e-11e9-99f6-8a077000b195)
Aug 16 14:03:40.569: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-5tq2s.svc from pod e2e-tests-dns-5tq2s/dns-test-a23967f8-c02e-11e9-99f6-8a077000b195: the server could not find the requested resource (get pods dns-test-a23967f8-c02e-11e9-99f6-8a077000b195)
Aug 16 14:03:40.575: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-5tq2s.svc from pod e2e-tests-dns-5tq2s/dns-test-a23967f8-c02e-11e9-99f6-8a077000b195: the server could not find the requested resource (get pods dns-test-a23967f8-c02e-11e9-99f6-8a077000b195)
Aug 16 14:03:40.597: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-5tq2s/dns-test-a23967f8-c02e-11e9-99f6-8a077000b195: the server could not find the requested resource (get pods dns-test-a23967f8-c02e-11e9-99f6-8a077000b195)
Aug 16 14:03:40.600: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-5tq2s/dns-test-a23967f8-c02e-11e9-99f6-8a077000b195: the server could not find the requested resource (get pods dns-test-a23967f8-c02e-11e9-99f6-8a077000b195)
Aug 16 14:03:40.604: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-5tq2s from pod e2e-tests-dns-5tq2s/dns-test-a23967f8-c02e-11e9-99f6-8a077000b195: the server could not find the requested resource (get pods dns-test-a23967f8-c02e-11e9-99f6-8a077000b195)
Aug 16 14:03:40.607: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-5tq2s from pod e2e-tests-dns-5tq2s/dns-test-a23967f8-c02e-11e9-99f6-8a077000b195: the server could not find the requested resource (get pods dns-test-a23967f8-c02e-11e9-99f6-8a077000b195)
Aug 16 14:03:40.610: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-5tq2s.svc from pod e2e-tests-dns-5tq2s/dns-test-a23967f8-c02e-11e9-99f6-8a077000b195: the server could not find the requested resource (get pods dns-test-a23967f8-c02e-11e9-99f6-8a077000b195)
Aug 16 14:03:40.613: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-5tq2s.svc from pod e2e-tests-dns-5tq2s/dns-test-a23967f8-c02e-11e9-99f6-8a077000b195: the server could not find the requested resource (get pods dns-test-a23967f8-c02e-11e9-99f6-8a077000b195)
Aug 16 14:03:40.616: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-5tq2s.svc from pod e2e-tests-dns-5tq2s/dns-test-a23967f8-c02e-11e9-99f6-8a077000b195: the server could not find the requested resource (get pods dns-test-a23967f8-c02e-11e9-99f6-8a077000b195)
Aug 16 14:03:40.619: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-5tq2s.svc from pod e2e-tests-dns-5tq2s/dns-test-a23967f8-c02e-11e9-99f6-8a077000b195: the server could not find the requested resource (get pods dns-test-a23967f8-c02e-11e9-99f6-8a077000b195)
Aug 16 14:03:40.638: INFO: Lookups using e2e-tests-dns-5tq2s/dns-test-a23967f8-c02e-11e9-99f6-8a077000b195 failed for: [wheezy_tcp@dns-test-service wheezy_tcp@dns-test-service.e2e-tests-dns-5tq2s wheezy_tcp@dns-test-service.e2e-tests-dns-5tq2s.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-5tq2s.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-5tq2s jessie_tcp@dns-test-service.e2e-tests-dns-5tq2s jessie_udp@dns-test-service.e2e-tests-dns-5tq2s.svc jessie_tcp@dns-test-service.e2e-tests-dns-5tq2s.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-5tq2s.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-5tq2s.svc]

Aug 16 14:03:45.550: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-5tq2s/dns-test-a23967f8-c02e-11e9-99f6-8a077000b195: the server could not find the requested resource (get pods dns-test-a23967f8-c02e-11e9-99f6-8a077000b195)
Aug 16 14:03:45.557: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-5tq2s from pod e2e-tests-dns-5tq2s/dns-test-a23967f8-c02e-11e9-99f6-8a077000b195: the server could not find the requested resource (get pods dns-test-a23967f8-c02e-11e9-99f6-8a077000b195)
Aug 16 14:03:45.563: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-5tq2s.svc from pod e2e-tests-dns-5tq2s/dns-test-a23967f8-c02e-11e9-99f6-8a077000b195: the server could not find the requested resource (get pods dns-test-a23967f8-c02e-11e9-99f6-8a077000b195)
Aug 16 14:03:45.569: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-5tq2s.svc from pod e2e-tests-dns-5tq2s/dns-test-a23967f8-c02e-11e9-99f6-8a077000b195: the server could not find the requested resource (get pods dns-test-a23967f8-c02e-11e9-99f6-8a077000b195)
Aug 16 14:03:45.591: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-5tq2s/dns-test-a23967f8-c02e-11e9-99f6-8a077000b195: the server could not find the requested resource (get pods dns-test-a23967f8-c02e-11e9-99f6-8a077000b195)
Aug 16 14:03:45.595: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-5tq2s/dns-test-a23967f8-c02e-11e9-99f6-8a077000b195: the server could not find the requested resource (get pods dns-test-a23967f8-c02e-11e9-99f6-8a077000b195)
Aug 16 14:03:45.598: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-5tq2s from pod e2e-tests-dns-5tq2s/dns-test-a23967f8-c02e-11e9-99f6-8a077000b195: the server could not find the requested resource (get pods dns-test-a23967f8-c02e-11e9-99f6-8a077000b195)
Aug 16 14:03:45.601: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-5tq2s from pod e2e-tests-dns-5tq2s/dns-test-a23967f8-c02e-11e9-99f6-8a077000b195: the server could not find the requested resource (get pods dns-test-a23967f8-c02e-11e9-99f6-8a077000b195)
Aug 16 14:03:45.604: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-5tq2s.svc from pod e2e-tests-dns-5tq2s/dns-test-a23967f8-c02e-11e9-99f6-8a077000b195: the server could not find the requested resource (get pods dns-test-a23967f8-c02e-11e9-99f6-8a077000b195)
Aug 16 14:03:45.607: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-5tq2s.svc from pod e2e-tests-dns-5tq2s/dns-test-a23967f8-c02e-11e9-99f6-8a077000b195: the server could not find the requested resource (get pods dns-test-a23967f8-c02e-11e9-99f6-8a077000b195)
Aug 16 14:03:45.611: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-5tq2s.svc from pod e2e-tests-dns-5tq2s/dns-test-a23967f8-c02e-11e9-99f6-8a077000b195: the server could not find the requested resource (get pods dns-test-a23967f8-c02e-11e9-99f6-8a077000b195)
Aug 16 14:03:45.615: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-5tq2s.svc from pod e2e-tests-dns-5tq2s/dns-test-a23967f8-c02e-11e9-99f6-8a077000b195: the server could not find the requested resource (get pods dns-test-a23967f8-c02e-11e9-99f6-8a077000b195)
Aug 16 14:03:45.634: INFO: Lookups using e2e-tests-dns-5tq2s/dns-test-a23967f8-c02e-11e9-99f6-8a077000b195 failed for: [wheezy_tcp@dns-test-service wheezy_tcp@dns-test-service.e2e-tests-dns-5tq2s wheezy_tcp@dns-test-service.e2e-tests-dns-5tq2s.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-5tq2s.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-5tq2s jessie_tcp@dns-test-service.e2e-tests-dns-5tq2s jessie_udp@dns-test-service.e2e-tests-dns-5tq2s.svc jessie_tcp@dns-test-service.e2e-tests-dns-5tq2s.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-5tq2s.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-5tq2s.svc]

Aug 16 14:03:50.551: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-5tq2s/dns-test-a23967f8-c02e-11e9-99f6-8a077000b195: the server could not find the requested resource (get pods dns-test-a23967f8-c02e-11e9-99f6-8a077000b195)
Aug 16 14:03:50.564: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-5tq2s from pod e2e-tests-dns-5tq2s/dns-test-a23967f8-c02e-11e9-99f6-8a077000b195: the server could not find the requested resource (get pods dns-test-a23967f8-c02e-11e9-99f6-8a077000b195)
Aug 16 14:03:50.571: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-5tq2s.svc from pod e2e-tests-dns-5tq2s/dns-test-a23967f8-c02e-11e9-99f6-8a077000b195: the server could not find the requested resource (get pods dns-test-a23967f8-c02e-11e9-99f6-8a077000b195)
Aug 16 14:03:50.577: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-5tq2s.svc from pod e2e-tests-dns-5tq2s/dns-test-a23967f8-c02e-11e9-99f6-8a077000b195: the server could not find the requested resource (get pods dns-test-a23967f8-c02e-11e9-99f6-8a077000b195)
Aug 16 14:03:50.606: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-5tq2s/dns-test-a23967f8-c02e-11e9-99f6-8a077000b195: the server could not find the requested resource (get pods dns-test-a23967f8-c02e-11e9-99f6-8a077000b195)
Aug 16 14:03:50.609: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-5tq2s/dns-test-a23967f8-c02e-11e9-99f6-8a077000b195: the server could not find the requested resource (get pods dns-test-a23967f8-c02e-11e9-99f6-8a077000b195)
Aug 16 14:03:50.613: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-5tq2s from pod e2e-tests-dns-5tq2s/dns-test-a23967f8-c02e-11e9-99f6-8a077000b195: the server could not find the requested resource (get pods dns-test-a23967f8-c02e-11e9-99f6-8a077000b195)
Aug 16 14:03:50.616: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-5tq2s from pod e2e-tests-dns-5tq2s/dns-test-a23967f8-c02e-11e9-99f6-8a077000b195: the server could not find the requested resource (get pods dns-test-a23967f8-c02e-11e9-99f6-8a077000b195)
Aug 16 14:03:50.619: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-5tq2s.svc from pod e2e-tests-dns-5tq2s/dns-test-a23967f8-c02e-11e9-99f6-8a077000b195: the server could not find the requested resource (get pods dns-test-a23967f8-c02e-11e9-99f6-8a077000b195)
Aug 16 14:03:50.622: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-5tq2s.svc from pod e2e-tests-dns-5tq2s/dns-test-a23967f8-c02e-11e9-99f6-8a077000b195: the server could not find the requested resource (get pods dns-test-a23967f8-c02e-11e9-99f6-8a077000b195)
Aug 16 14:03:50.626: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-5tq2s.svc from pod e2e-tests-dns-5tq2s/dns-test-a23967f8-c02e-11e9-99f6-8a077000b195: the server could not find the requested resource (get pods dns-test-a23967f8-c02e-11e9-99f6-8a077000b195)
Aug 16 14:03:50.629: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-5tq2s.svc from pod e2e-tests-dns-5tq2s/dns-test-a23967f8-c02e-11e9-99f6-8a077000b195: the server could not find the requested resource (get pods dns-test-a23967f8-c02e-11e9-99f6-8a077000b195)
Aug 16 14:03:50.649: INFO: Lookups using e2e-tests-dns-5tq2s/dns-test-a23967f8-c02e-11e9-99f6-8a077000b195 failed for: [wheezy_tcp@dns-test-service wheezy_tcp@dns-test-service.e2e-tests-dns-5tq2s wheezy_tcp@dns-test-service.e2e-tests-dns-5tq2s.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-5tq2s.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-5tq2s jessie_tcp@dns-test-service.e2e-tests-dns-5tq2s jessie_udp@dns-test-service.e2e-tests-dns-5tq2s.svc jessie_tcp@dns-test-service.e2e-tests-dns-5tq2s.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-5tq2s.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-5tq2s.svc]

Aug 16 14:03:55.550: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-5tq2s/dns-test-a23967f8-c02e-11e9-99f6-8a077000b195: the server could not find the requested resource (get pods dns-test-a23967f8-c02e-11e9-99f6-8a077000b195)
Aug 16 14:03:55.556: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-5tq2s from pod e2e-tests-dns-5tq2s/dns-test-a23967f8-c02e-11e9-99f6-8a077000b195: the server could not find the requested resource (get pods dns-test-a23967f8-c02e-11e9-99f6-8a077000b195)
Aug 16 14:03:55.563: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-5tq2s.svc from pod e2e-tests-dns-5tq2s/dns-test-a23967f8-c02e-11e9-99f6-8a077000b195: the server could not find the requested resource (get pods dns-test-a23967f8-c02e-11e9-99f6-8a077000b195)
Aug 16 14:03:55.569: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-5tq2s.svc from pod e2e-tests-dns-5tq2s/dns-test-a23967f8-c02e-11e9-99f6-8a077000b195: the server could not find the requested resource (get pods dns-test-a23967f8-c02e-11e9-99f6-8a077000b195)
Aug 16 14:03:55.591: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-5tq2s/dns-test-a23967f8-c02e-11e9-99f6-8a077000b195: the server could not find the requested resource (get pods dns-test-a23967f8-c02e-11e9-99f6-8a077000b195)
Aug 16 14:03:55.595: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-5tq2s/dns-test-a23967f8-c02e-11e9-99f6-8a077000b195: the server could not find the requested resource (get pods dns-test-a23967f8-c02e-11e9-99f6-8a077000b195)
Aug 16 14:03:55.598: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-5tq2s from pod e2e-tests-dns-5tq2s/dns-test-a23967f8-c02e-11e9-99f6-8a077000b195: the server could not find the requested resource (get pods dns-test-a23967f8-c02e-11e9-99f6-8a077000b195)
Aug 16 14:03:55.601: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-5tq2s from pod e2e-tests-dns-5tq2s/dns-test-a23967f8-c02e-11e9-99f6-8a077000b195: the server could not find the requested resource (get pods dns-test-a23967f8-c02e-11e9-99f6-8a077000b195)
Aug 16 14:03:55.604: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-5tq2s.svc from pod e2e-tests-dns-5tq2s/dns-test-a23967f8-c02e-11e9-99f6-8a077000b195: the server could not find the requested resource (get pods dns-test-a23967f8-c02e-11e9-99f6-8a077000b195)
Aug 16 14:03:55.607: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-5tq2s.svc from pod e2e-tests-dns-5tq2s/dns-test-a23967f8-c02e-11e9-99f6-8a077000b195: the server could not find the requested resource (get pods dns-test-a23967f8-c02e-11e9-99f6-8a077000b195)
Aug 16 14:03:55.610: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-5tq2s.svc from pod e2e-tests-dns-5tq2s/dns-test-a23967f8-c02e-11e9-99f6-8a077000b195: the server could not find the requested resource (get pods dns-test-a23967f8-c02e-11e9-99f6-8a077000b195)
Aug 16 14:03:55.614: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-5tq2s.svc from pod e2e-tests-dns-5tq2s/dns-test-a23967f8-c02e-11e9-99f6-8a077000b195: the server could not find the requested resource (get pods dns-test-a23967f8-c02e-11e9-99f6-8a077000b195)
Aug 16 14:03:55.633: INFO: Lookups using e2e-tests-dns-5tq2s/dns-test-a23967f8-c02e-11e9-99f6-8a077000b195 failed for: [wheezy_tcp@dns-test-service wheezy_tcp@dns-test-service.e2e-tests-dns-5tq2s wheezy_tcp@dns-test-service.e2e-tests-dns-5tq2s.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-5tq2s.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-5tq2s jessie_tcp@dns-test-service.e2e-tests-dns-5tq2s jessie_udp@dns-test-service.e2e-tests-dns-5tq2s.svc jessie_tcp@dns-test-service.e2e-tests-dns-5tq2s.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-5tq2s.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-5tq2s.svc]

Aug 16 14:04:00.550: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-5tq2s/dns-test-a23967f8-c02e-11e9-99f6-8a077000b195: the server could not find the requested resource (get pods dns-test-a23967f8-c02e-11e9-99f6-8a077000b195)
Aug 16 14:04:00.557: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-5tq2s from pod e2e-tests-dns-5tq2s/dns-test-a23967f8-c02e-11e9-99f6-8a077000b195: the server could not find the requested resource (get pods dns-test-a23967f8-c02e-11e9-99f6-8a077000b195)
Aug 16 14:04:00.570: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-5tq2s.svc from pod e2e-tests-dns-5tq2s/dns-test-a23967f8-c02e-11e9-99f6-8a077000b195: the server could not find the requested resource (get pods dns-test-a23967f8-c02e-11e9-99f6-8a077000b195)
Aug 16 14:04:00.576: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-5tq2s.svc from pod e2e-tests-dns-5tq2s/dns-test-a23967f8-c02e-11e9-99f6-8a077000b195: the server could not find the requested resource (get pods dns-test-a23967f8-c02e-11e9-99f6-8a077000b195)
Aug 16 14:04:00.599: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-5tq2s/dns-test-a23967f8-c02e-11e9-99f6-8a077000b195: the server could not find the requested resource (get pods dns-test-a23967f8-c02e-11e9-99f6-8a077000b195)
Aug 16 14:04:00.603: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-5tq2s/dns-test-a23967f8-c02e-11e9-99f6-8a077000b195: the server could not find the requested resource (get pods dns-test-a23967f8-c02e-11e9-99f6-8a077000b195)
Aug 16 14:04:00.606: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-5tq2s from pod e2e-tests-dns-5tq2s/dns-test-a23967f8-c02e-11e9-99f6-8a077000b195: the server could not find the requested resource (get pods dns-test-a23967f8-c02e-11e9-99f6-8a077000b195)
Aug 16 14:04:00.609: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-5tq2s from pod e2e-tests-dns-5tq2s/dns-test-a23967f8-c02e-11e9-99f6-8a077000b195: the server could not find the requested resource (get pods dns-test-a23967f8-c02e-11e9-99f6-8a077000b195)
Aug 16 14:04:00.612: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-5tq2s.svc from pod e2e-tests-dns-5tq2s/dns-test-a23967f8-c02e-11e9-99f6-8a077000b195: the server could not find the requested resource (get pods dns-test-a23967f8-c02e-11e9-99f6-8a077000b195)
Aug 16 14:04:00.616: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-5tq2s.svc from pod e2e-tests-dns-5tq2s/dns-test-a23967f8-c02e-11e9-99f6-8a077000b195: the server could not find the requested resource (get pods dns-test-a23967f8-c02e-11e9-99f6-8a077000b195)
Aug 16 14:04:00.619: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-5tq2s.svc from pod e2e-tests-dns-5tq2s/dns-test-a23967f8-c02e-11e9-99f6-8a077000b195: the server could not find the requested resource (get pods dns-test-a23967f8-c02e-11e9-99f6-8a077000b195)
Aug 16 14:04:00.622: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-5tq2s.svc from pod e2e-tests-dns-5tq2s/dns-test-a23967f8-c02e-11e9-99f6-8a077000b195: the server could not find the requested resource (get pods dns-test-a23967f8-c02e-11e9-99f6-8a077000b195)
Aug 16 14:04:00.642: INFO: Lookups using e2e-tests-dns-5tq2s/dns-test-a23967f8-c02e-11e9-99f6-8a077000b195 failed for: [wheezy_tcp@dns-test-service wheezy_tcp@dns-test-service.e2e-tests-dns-5tq2s wheezy_tcp@dns-test-service.e2e-tests-dns-5tq2s.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-5tq2s.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-5tq2s jessie_tcp@dns-test-service.e2e-tests-dns-5tq2s jessie_udp@dns-test-service.e2e-tests-dns-5tq2s.svc jessie_tcp@dns-test-service.e2e-tests-dns-5tq2s.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-5tq2s.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-5tq2s.svc]

Aug 16 14:04:05.632: INFO: DNS probes using e2e-tests-dns-5tq2s/dns-test-a23967f8-c02e-11e9-99f6-8a077000b195 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 14:04:05.723: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-5tq2s" for this suite.
Aug 16 14:04:11.750: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 14:04:11.810: INFO: namespace: e2e-tests-dns-5tq2s, resource: bindings, ignored listing per whitelist
Aug 16 14:04:11.862: INFO: namespace e2e-tests-dns-5tq2s deletion completed in 6.134280175s

• [SLOW TEST:38.510 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 14:04:11.863: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Aug 16 14:04:11.931: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-mvmj2,SelfLink:/api/v1/namespaces/e2e-tests-watch-mvmj2/configmaps/e2e-watch-test-label-changed,UID:b926dca5-c02e-11e9-ae7d-02d5aa9cbbca,ResourceVersion:33952,Generation:0,CreationTimestamp:2019-08-16 14:04:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Aug 16 14:04:11.931: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-mvmj2,SelfLink:/api/v1/namespaces/e2e-tests-watch-mvmj2/configmaps/e2e-watch-test-label-changed,UID:b926dca5-c02e-11e9-ae7d-02d5aa9cbbca,ResourceVersion:33953,Generation:0,CreationTimestamp:2019-08-16 14:04:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Aug 16 14:04:11.931: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-mvmj2,SelfLink:/api/v1/namespaces/e2e-tests-watch-mvmj2/configmaps/e2e-watch-test-label-changed,UID:b926dca5-c02e-11e9-ae7d-02d5aa9cbbca,ResourceVersion:33954,Generation:0,CreationTimestamp:2019-08-16 14:04:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Aug 16 14:04:21.974: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-mvmj2,SelfLink:/api/v1/namespaces/e2e-tests-watch-mvmj2/configmaps/e2e-watch-test-label-changed,UID:b926dca5-c02e-11e9-ae7d-02d5aa9cbbca,ResourceVersion:33990,Generation:0,CreationTimestamp:2019-08-16 14:04:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Aug 16 14:04:21.974: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-mvmj2,SelfLink:/api/v1/namespaces/e2e-tests-watch-mvmj2/configmaps/e2e-watch-test-label-changed,UID:b926dca5-c02e-11e9-ae7d-02d5aa9cbbca,ResourceVersion:33991,Generation:0,CreationTimestamp:2019-08-16 14:04:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Aug 16 14:04:21.974: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-mvmj2,SelfLink:/api/v1/namespaces/e2e-tests-watch-mvmj2/configmaps/e2e-watch-test-label-changed,UID:b926dca5-c02e-11e9-ae7d-02d5aa9cbbca,ResourceVersion:33992,Generation:0,CreationTimestamp:2019-08-16 14:04:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 14:04:21.974: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-mvmj2" for this suite.
Aug 16 14:04:27.992: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 14:04:28.129: INFO: namespace: e2e-tests-watch-mvmj2, resource: bindings, ignored listing per whitelist
Aug 16 14:04:28.145: INFO: namespace e2e-tests-watch-mvmj2 deletion completed in 6.166459564s

• [SLOW TEST:16.282 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 14:04:28.145: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug 16 14:04:50.211: INFO: Container started at 2019-08-16 14:04:28 +0000 UTC, pod became ready at 2019-08-16 14:04:49 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 14:04:50.212: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-jlbks" for this suite.
Aug 16 14:05:12.230: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 14:05:12.284: INFO: namespace: e2e-tests-container-probe-jlbks, resource: bindings, ignored listing per whitelist
Aug 16 14:05:12.341: INFO: namespace e2e-tests-container-probe-jlbks deletion completed in 22.125212877s

• [SLOW TEST:44.196 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 14:05:12.341: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Aug 16 14:05:12.416: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-msb69,SelfLink:/api/v1/namespaces/e2e-tests-watch-msb69/configmaps/e2e-watch-test-watch-closed,UID:dd3518cd-c02e-11e9-ae7d-02d5aa9cbbca,ResourceVersion:34201,Generation:0,CreationTimestamp:2019-08-16 14:05:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Aug 16 14:05:12.417: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-msb69,SelfLink:/api/v1/namespaces/e2e-tests-watch-msb69/configmaps/e2e-watch-test-watch-closed,UID:dd3518cd-c02e-11e9-ae7d-02d5aa9cbbca,ResourceVersion:34202,Generation:0,CreationTimestamp:2019-08-16 14:05:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Aug 16 14:05:12.434: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-msb69,SelfLink:/api/v1/namespaces/e2e-tests-watch-msb69/configmaps/e2e-watch-test-watch-closed,UID:dd3518cd-c02e-11e9-ae7d-02d5aa9cbbca,ResourceVersion:34203,Generation:0,CreationTimestamp:2019-08-16 14:05:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Aug 16 14:05:12.434: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-msb69,SelfLink:/api/v1/namespaces/e2e-tests-watch-msb69/configmaps/e2e-watch-test-watch-closed,UID:dd3518cd-c02e-11e9-ae7d-02d5aa9cbbca,ResourceVersion:34204,Generation:0,CreationTimestamp:2019-08-16 14:05:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 14:05:12.434: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-msb69" for this suite.
Aug 16 14:05:18.452: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 14:05:18.556: INFO: namespace: e2e-tests-watch-msb69, resource: bindings, ignored listing per whitelist
Aug 16 14:05:18.567: INFO: namespace e2e-tests-watch-msb69 deletion completed in 6.128866399s

• [SLOW TEST:6.226 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 14:05:18.567: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 14:05:20.686: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-wsblp" for this suite.
Aug 16 14:05:26.711: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 14:05:26.757: INFO: namespace: e2e-tests-emptydir-wrapper-wsblp, resource: bindings, ignored listing per whitelist
Aug 16 14:05:26.821: INFO: namespace e2e-tests-emptydir-wrapper-wsblp deletion completed in 6.130113011s

• [SLOW TEST:8.253 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 14:05:26.821: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Aug 16 14:05:28.899: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-e5d9a64b-c02e-11e9-99f6-8a077000b195,GenerateName:,Namespace:e2e-tests-events-tdbf8,SelfLink:/api/v1/namespaces/e2e-tests-events-tdbf8/pods/send-events-e5d9a64b-c02e-11e9-99f6-8a077000b195,UID:e5d5d334-c02e-11e9-ae7d-02d5aa9cbbca,ResourceVersion:34310,Generation:0,CreationTimestamp:2019-08-16 14:05:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 878578673,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.2.4.182/32,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dmnqr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dmnqr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-dmnqr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-eab92000-c026-11e9-bfed-069795ba99e0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00118f700} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00118f720}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 14:05:26 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 14:05:28 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 14:05:28 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 14:05:26 +0000 UTC  }],Message:,Reason:,HostIP:10.1.161.42,PodIP:10.2.4.182,StartTime:2019-08-16 14:05:26 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-08-16 14:05:27 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://8e8550f0a7c8bbe4fc1b1a2a06ce57d6e29c4db96d8c7ffb6983daf2233cf2a6}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Aug 16 14:05:30.903: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Aug 16 14:05:32.907: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 14:05:32.915: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-tdbf8" for this suite.
Aug 16 14:06:18.936: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 14:06:18.982: INFO: namespace: e2e-tests-events-tdbf8, resource: bindings, ignored listing per whitelist
Aug 16 14:06:19.048: INFO: namespace e2e-tests-events-tdbf8 deletion completed in 46.126081159s

• [SLOW TEST:52.227 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 14:06:19.048: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug 16 14:06:21.140: INFO: Waiting up to 5m0s for pod "client-envvars-062f7e6a-c02f-11e9-99f6-8a077000b195" in namespace "e2e-tests-pods-c77fx" to be "success or failure"
Aug 16 14:06:21.143: INFO: Pod "client-envvars-062f7e6a-c02f-11e9-99f6-8a077000b195": Phase="Pending", Reason="", readiness=false. Elapsed: 3.692192ms
Aug 16 14:06:23.154: INFO: Pod "client-envvars-062f7e6a-c02f-11e9-99f6-8a077000b195": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013940402s
STEP: Saw pod success
Aug 16 14:06:23.154: INFO: Pod "client-envvars-062f7e6a-c02f-11e9-99f6-8a077000b195" satisfied condition "success or failure"
Aug 16 14:06:23.157: INFO: Trying to get logs from node worker-eab92000-c026-11e9-bfed-069795ba99e0 pod client-envvars-062f7e6a-c02f-11e9-99f6-8a077000b195 container env3cont: <nil>
STEP: delete the pod
Aug 16 14:06:23.184: INFO: Waiting for pod client-envvars-062f7e6a-c02f-11e9-99f6-8a077000b195 to disappear
Aug 16 14:06:23.190: INFO: Pod client-envvars-062f7e6a-c02f-11e9-99f6-8a077000b195 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 14:06:23.190: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-c77fx" for this suite.
Aug 16 14:07:03.209: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 14:07:03.249: INFO: namespace: e2e-tests-pods-c77fx, resource: bindings, ignored listing per whitelist
Aug 16 14:07:03.323: INFO: namespace e2e-tests-pods-c77fx deletion completed in 40.129055862s

• [SLOW TEST:44.275 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 14:07:03.323: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
Aug 16 14:07:03.371: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 cluster-info'
Aug 16 14:07:03.429: INFO: stderr: ""
Aug 16 14:07:03.429: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.0.0.1:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 14:07:03.429: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-h5mh5" for this suite.
Aug 16 14:07:09.457: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 14:07:09.497: INFO: namespace: e2e-tests-kubectl-h5mh5, resource: bindings, ignored listing per whitelist
Aug 16 14:07:09.574: INFO: namespace e2e-tests-kubectl-h5mh5 deletion completed in 6.141157162s

• [SLOW TEST:6.251 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 14:07:09.574: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 14:08:09.685: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-wrnwn" for this suite.
Aug 16 14:08:31.712: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 14:08:31.722: INFO: namespace: e2e-tests-container-probe-wrnwn, resource: bindings, ignored listing per whitelist
Aug 16 14:08:31.825: INFO: namespace e2e-tests-container-probe-wrnwn deletion completed in 22.135873844s

• [SLOW TEST:82.251 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 14:08:31.825: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug 16 14:08:31.880: INFO: Waiting up to 5m0s for pod "downwardapi-volume-541d859f-c02f-11e9-99f6-8a077000b195" in namespace "e2e-tests-downward-api-mc7rb" to be "success or failure"
Aug 16 14:08:31.888: INFO: Pod "downwardapi-volume-541d859f-c02f-11e9-99f6-8a077000b195": Phase="Pending", Reason="", readiness=false. Elapsed: 7.177922ms
Aug 16 14:08:33.891: INFO: Pod "downwardapi-volume-541d859f-c02f-11e9-99f6-8a077000b195": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010996252s
STEP: Saw pod success
Aug 16 14:08:33.891: INFO: Pod "downwardapi-volume-541d859f-c02f-11e9-99f6-8a077000b195" satisfied condition "success or failure"
Aug 16 14:08:33.895: INFO: Trying to get logs from node worker-eab92000-c026-11e9-bfed-069795ba99e0 pod downwardapi-volume-541d859f-c02f-11e9-99f6-8a077000b195 container client-container: <nil>
STEP: delete the pod
Aug 16 14:08:33.919: INFO: Waiting for pod downwardapi-volume-541d859f-c02f-11e9-99f6-8a077000b195 to disappear
Aug 16 14:08:33.925: INFO: Pod downwardapi-volume-541d859f-c02f-11e9-99f6-8a077000b195 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 14:08:33.925: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-mc7rb" for this suite.
Aug 16 14:08:39.943: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 14:08:39.949: INFO: namespace: e2e-tests-downward-api-mc7rb, resource: bindings, ignored listing per whitelist
Aug 16 14:08:40.058: INFO: namespace e2e-tests-downward-api-mc7rb deletion completed in 6.12956487s

• [SLOW TEST:8.233 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 14:08:40.058: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug 16 14:08:40.126: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5906e20c-c02f-11e9-99f6-8a077000b195" in namespace "e2e-tests-projected-6jwvx" to be "success or failure"
Aug 16 14:08:40.135: INFO: Pod "downwardapi-volume-5906e20c-c02f-11e9-99f6-8a077000b195": Phase="Pending", Reason="", readiness=false. Elapsed: 9.264025ms
Aug 16 14:08:42.145: INFO: Pod "downwardapi-volume-5906e20c-c02f-11e9-99f6-8a077000b195": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019407544s
STEP: Saw pod success
Aug 16 14:08:42.145: INFO: Pod "downwardapi-volume-5906e20c-c02f-11e9-99f6-8a077000b195" satisfied condition "success or failure"
Aug 16 14:08:42.148: INFO: Trying to get logs from node worker-eab92000-c026-11e9-bfed-069795ba99e0 pod downwardapi-volume-5906e20c-c02f-11e9-99f6-8a077000b195 container client-container: <nil>
STEP: delete the pod
Aug 16 14:08:42.172: INFO: Waiting for pod downwardapi-volume-5906e20c-c02f-11e9-99f6-8a077000b195 to disappear
Aug 16 14:08:42.179: INFO: Pod downwardapi-volume-5906e20c-c02f-11e9-99f6-8a077000b195 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 14:08:42.179: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-6jwvx" for this suite.
Aug 16 14:08:48.203: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 14:08:48.265: INFO: namespace: e2e-tests-projected-6jwvx, resource: bindings, ignored listing per whitelist
Aug 16 14:08:48.315: INFO: namespace e2e-tests-projected-6jwvx deletion completed in 6.132230737s

• [SLOW TEST:8.257 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 14:08:48.316: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1052
STEP: creating the pod
Aug 16 14:08:48.366: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 create -f - --namespace=e2e-tests-kubectl-7q5dk'
Aug 16 14:08:48.489: INFO: stderr: ""
Aug 16 14:08:48.489: INFO: stdout: "pod/pause created\n"
Aug 16 14:08:48.489: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Aug 16 14:08:48.489: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-7q5dk" to be "running and ready"
Aug 16 14:08:48.493: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 3.320606ms
Aug 16 14:08:50.496: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.007000744s
Aug 16 14:08:50.496: INFO: Pod "pause" satisfied condition "running and ready"
Aug 16 14:08:50.496: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
Aug 16 14:08:50.497: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-7q5dk'
Aug 16 14:08:50.559: INFO: stderr: ""
Aug 16 14:08:50.559: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Aug 16 14:08:50.559: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 get pod pause -L testing-label --namespace=e2e-tests-kubectl-7q5dk'
Aug 16 14:08:50.615: INFO: stderr: ""
Aug 16 14:08:50.615: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Aug 16 14:08:50.615: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 label pods pause testing-label- --namespace=e2e-tests-kubectl-7q5dk'
Aug 16 14:08:50.677: INFO: stderr: ""
Aug 16 14:08:50.677: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Aug 16 14:08:50.677: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 get pod pause -L testing-label --namespace=e2e-tests-kubectl-7q5dk'
Aug 16 14:08:50.741: INFO: stderr: ""
Aug 16 14:08:50.741: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1059
STEP: using delete to clean up resources
Aug 16 14:08:50.741: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-7q5dk'
Aug 16 14:08:50.815: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 16 14:08:50.815: INFO: stdout: "pod \"pause\" force deleted\n"
Aug 16 14:08:50.815: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-7q5dk'
Aug 16 14:08:50.878: INFO: stderr: "No resources found.\n"
Aug 16 14:08:50.878: INFO: stdout: ""
Aug 16 14:08:50.878: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 get pods -l name=pause --namespace=e2e-tests-kubectl-7q5dk -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug 16 14:08:50.934: INFO: stderr: ""
Aug 16 14:08:50.934: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 14:08:50.934: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-7q5dk" for this suite.
Aug 16 14:08:56.955: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 14:08:57.056: INFO: namespace: e2e-tests-kubectl-7q5dk, resource: bindings, ignored listing per whitelist
Aug 16 14:08:57.068: INFO: namespace e2e-tests-kubectl-7q5dk deletion completed in 6.129404004s

• [SLOW TEST:8.752 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 14:08:57.068: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Aug 16 14:08:57.115: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 14:09:00.229: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-rxnkk" for this suite.
Aug 16 14:09:06.253: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 14:09:06.311: INFO: namespace: e2e-tests-init-container-rxnkk, resource: bindings, ignored listing per whitelist
Aug 16 14:09:06.371: INFO: namespace e2e-tests-init-container-rxnkk deletion completed in 6.132754146s

• [SLOW TEST:9.304 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 14:09:06.372: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 14:09:08.449: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-m7nps" for this suite.
Aug 16 14:09:54.467: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 14:09:54.480: INFO: namespace: e2e-tests-kubelet-test-m7nps, resource: bindings, ignored listing per whitelist
Aug 16 14:09:54.578: INFO: namespace e2e-tests-kubelet-test-m7nps deletion completed in 46.124794397s

• [SLOW TEST:48.206 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 14:09:54.578: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Aug 16 14:09:54.641: INFO: Waiting up to 5m0s for pod "pod-85712828-c02f-11e9-99f6-8a077000b195" in namespace "e2e-tests-emptydir-pjsr5" to be "success or failure"
Aug 16 14:09:54.647: INFO: Pod "pod-85712828-c02f-11e9-99f6-8a077000b195": Phase="Pending", Reason="", readiness=false. Elapsed: 6.415302ms
Aug 16 14:09:56.651: INFO: Pod "pod-85712828-c02f-11e9-99f6-8a077000b195": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010853734s
STEP: Saw pod success
Aug 16 14:09:56.651: INFO: Pod "pod-85712828-c02f-11e9-99f6-8a077000b195" satisfied condition "success or failure"
Aug 16 14:09:56.655: INFO: Trying to get logs from node worker-eab92000-c026-11e9-bfed-069795ba99e0 pod pod-85712828-c02f-11e9-99f6-8a077000b195 container test-container: <nil>
STEP: delete the pod
Aug 16 14:09:56.683: INFO: Waiting for pod pod-85712828-c02f-11e9-99f6-8a077000b195 to disappear
Aug 16 14:09:56.689: INFO: Pod pod-85712828-c02f-11e9-99f6-8a077000b195 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 14:09:56.689: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-pjsr5" for this suite.
Aug 16 14:10:02.706: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 14:10:02.738: INFO: namespace: e2e-tests-emptydir-pjsr5, resource: bindings, ignored listing per whitelist
Aug 16 14:10:02.821: INFO: namespace e2e-tests-emptydir-pjsr5 deletion completed in 6.127567158s

• [SLOW TEST:8.243 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 14:10:02.821: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 pods, got 2 pods
STEP: expected 0 rs, got 1 rs
STEP: Gathering metrics
W0816 14:10:03.918372      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Aug 16 14:10:03.918: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 14:10:03.918: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-6mclv" for this suite.
Aug 16 14:10:09.937: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 14:10:09.949: INFO: namespace: e2e-tests-gc-6mclv, resource: bindings, ignored listing per whitelist
Aug 16 14:10:10.047: INFO: namespace e2e-tests-gc-6mclv deletion completed in 6.12569072s

• [SLOW TEST:7.226 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 14:10:10.047: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-8eabaad6-c02f-11e9-99f6-8a077000b195
STEP: Creating a pod to test consume secrets
Aug 16 14:10:10.125: INFO: Waiting up to 5m0s for pod "pod-secrets-8eac529f-c02f-11e9-99f6-8a077000b195" in namespace "e2e-tests-secrets-jbzjx" to be "success or failure"
Aug 16 14:10:10.129: INFO: Pod "pod-secrets-8eac529f-c02f-11e9-99f6-8a077000b195": Phase="Pending", Reason="", readiness=false. Elapsed: 3.844903ms
Aug 16 14:10:12.139: INFO: Pod "pod-secrets-8eac529f-c02f-11e9-99f6-8a077000b195": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01400715s
STEP: Saw pod success
Aug 16 14:10:12.139: INFO: Pod "pod-secrets-8eac529f-c02f-11e9-99f6-8a077000b195" satisfied condition "success or failure"
Aug 16 14:10:12.142: INFO: Trying to get logs from node worker-eab92000-c026-11e9-bfed-069795ba99e0 pod pod-secrets-8eac529f-c02f-11e9-99f6-8a077000b195 container secret-volume-test: <nil>
STEP: delete the pod
Aug 16 14:10:12.169: INFO: Waiting for pod pod-secrets-8eac529f-c02f-11e9-99f6-8a077000b195 to disappear
Aug 16 14:10:12.173: INFO: Pod pod-secrets-8eac529f-c02f-11e9-99f6-8a077000b195 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 14:10:12.174: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-jbzjx" for this suite.
Aug 16 14:10:18.191: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 14:10:18.238: INFO: namespace: e2e-tests-secrets-jbzjx, resource: bindings, ignored listing per whitelist
Aug 16 14:10:18.306: INFO: namespace e2e-tests-secrets-jbzjx deletion completed in 6.127919613s

• [SLOW TEST:8.258 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 14:10:18.306: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Aug 16 14:10:18.352: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 create -f - --namespace=e2e-tests-kubectl-5xqzv'
Aug 16 14:10:18.483: INFO: stderr: ""
Aug 16 14:10:18.483: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Aug 16 14:10:19.487: INFO: Selector matched 1 pods for map[app:redis]
Aug 16 14:10:19.487: INFO: Found 0 / 1
Aug 16 14:10:20.487: INFO: Selector matched 1 pods for map[app:redis]
Aug 16 14:10:20.487: INFO: Found 1 / 1
Aug 16 14:10:20.487: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Aug 16 14:10:20.490: INFO: Selector matched 1 pods for map[app:redis]
Aug 16 14:10:20.490: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Aug 16 14:10:20.490: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 patch pod redis-master-27jzq --namespace=e2e-tests-kubectl-5xqzv -p {"metadata":{"annotations":{"x":"y"}}}'
Aug 16 14:10:20.553: INFO: stderr: ""
Aug 16 14:10:20.553: INFO: stdout: "pod/redis-master-27jzq patched\n"
STEP: checking annotations
Aug 16 14:10:20.557: INFO: Selector matched 1 pods for map[app:redis]
Aug 16 14:10:20.557: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 14:10:20.557: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-5xqzv" for this suite.
Aug 16 14:10:42.574: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 14:10:42.631: INFO: namespace: e2e-tests-kubectl-5xqzv, resource: bindings, ignored listing per whitelist
Aug 16 14:10:42.686: INFO: namespace e2e-tests-kubectl-5xqzv deletion completed in 22.124875235s

• [SLOW TEST:24.380 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 14:10:42.686: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
Aug 16 14:10:42.744: INFO: Waiting up to 5m0s for pod "var-expansion-a21ddc13-c02f-11e9-99f6-8a077000b195" in namespace "e2e-tests-var-expansion-6t85k" to be "success or failure"
Aug 16 14:10:42.748: INFO: Pod "var-expansion-a21ddc13-c02f-11e9-99f6-8a077000b195": Phase="Pending", Reason="", readiness=false. Elapsed: 3.977493ms
Aug 16 14:10:44.758: INFO: Pod "var-expansion-a21ddc13-c02f-11e9-99f6-8a077000b195": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014263634s
STEP: Saw pod success
Aug 16 14:10:44.758: INFO: Pod "var-expansion-a21ddc13-c02f-11e9-99f6-8a077000b195" satisfied condition "success or failure"
Aug 16 14:10:44.761: INFO: Trying to get logs from node worker-eab92000-c026-11e9-bfed-069795ba99e0 pod var-expansion-a21ddc13-c02f-11e9-99f6-8a077000b195 container dapi-container: <nil>
STEP: delete the pod
Aug 16 14:10:44.787: INFO: Waiting for pod var-expansion-a21ddc13-c02f-11e9-99f6-8a077000b195 to disappear
Aug 16 14:10:44.793: INFO: Pod var-expansion-a21ddc13-c02f-11e9-99f6-8a077000b195 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 14:10:44.793: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-6t85k" for this suite.
Aug 16 14:10:50.813: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 14:10:50.932: INFO: namespace: e2e-tests-var-expansion-6t85k, resource: bindings, ignored listing per whitelist
Aug 16 14:10:50.936: INFO: namespace e2e-tests-var-expansion-6t85k deletion completed in 6.138622583s

• [SLOW TEST:8.249 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 14:10:50.936: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Aug 16 14:10:51.038: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 create -f - --namespace=e2e-tests-kubectl-dvsts'
Aug 16 14:10:51.168: INFO: stderr: ""
Aug 16 14:10:51.168: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug 16 14:10:51.168: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-dvsts'
Aug 16 14:10:51.236: INFO: stderr: ""
Aug 16 14:10:51.236: INFO: stdout: "update-demo-nautilus-mjwsg update-demo-nautilus-rnkgc "
Aug 16 14:10:51.236: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 get pods update-demo-nautilus-mjwsg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-dvsts'
Aug 16 14:10:51.299: INFO: stderr: ""
Aug 16 14:10:51.299: INFO: stdout: ""
Aug 16 14:10:51.299: INFO: update-demo-nautilus-mjwsg is created but not running
Aug 16 14:10:56.300: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-dvsts'
Aug 16 14:10:56.364: INFO: stderr: ""
Aug 16 14:10:56.364: INFO: stdout: "update-demo-nautilus-mjwsg update-demo-nautilus-rnkgc "
Aug 16 14:10:56.364: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 get pods update-demo-nautilus-mjwsg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-dvsts'
Aug 16 14:10:56.419: INFO: stderr: ""
Aug 16 14:10:56.419: INFO: stdout: "true"
Aug 16 14:10:56.419: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 get pods update-demo-nautilus-mjwsg -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-dvsts'
Aug 16 14:10:56.475: INFO: stderr: ""
Aug 16 14:10:56.475: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 16 14:10:56.475: INFO: validating pod update-demo-nautilus-mjwsg
Aug 16 14:10:56.479: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 16 14:10:56.479: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 16 14:10:56.479: INFO: update-demo-nautilus-mjwsg is verified up and running
Aug 16 14:10:56.479: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 get pods update-demo-nautilus-rnkgc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-dvsts'
Aug 16 14:10:56.536: INFO: stderr: ""
Aug 16 14:10:56.536: INFO: stdout: "true"
Aug 16 14:10:56.536: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 get pods update-demo-nautilus-rnkgc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-dvsts'
Aug 16 14:10:56.591: INFO: stderr: ""
Aug 16 14:10:56.591: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 16 14:10:56.591: INFO: validating pod update-demo-nautilus-rnkgc
Aug 16 14:10:56.596: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 16 14:10:56.596: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 16 14:10:56.596: INFO: update-demo-nautilus-rnkgc is verified up and running
STEP: using delete to clean up resources
Aug 16 14:10:56.596: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-dvsts'
Aug 16 14:10:56.658: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 16 14:10:56.658: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Aug 16 14:10:56.658: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-dvsts'
Aug 16 14:10:56.761: INFO: stderr: "No resources found.\n"
Aug 16 14:10:56.761: INFO: stdout: ""
Aug 16 14:10:56.761: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 get pods -l name=update-demo --namespace=e2e-tests-kubectl-dvsts -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug 16 14:10:56.884: INFO: stderr: ""
Aug 16 14:10:56.884: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 14:10:56.884: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-dvsts" for this suite.
Aug 16 14:11:18.908: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 14:11:19.006: INFO: namespace: e2e-tests-kubectl-dvsts, resource: bindings, ignored listing per whitelist
Aug 16 14:11:19.017: INFO: namespace e2e-tests-kubectl-dvsts deletion completed in 22.128734794s

• [SLOW TEST:28.081 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 14:11:19.017: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug 16 14:11:19.115: INFO: Creating deployment "test-recreate-deployment"
Aug 16 14:11:19.122: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Aug 16 14:11:19.130: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Aug 16 14:11:21.136: INFO: Waiting deployment "test-recreate-deployment" to complete
Aug 16 14:11:21.139: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Aug 16 14:11:21.150: INFO: Updating deployment test-recreate-deployment
Aug 16 14:11:21.150: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Aug 16 14:11:21.235: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-tlppv,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-tlppv/deployments/test-recreate-deployment,UID:b7c7d2ee-c02f-11e9-ae7d-02d5aa9cbbca,ResourceVersion:36020,Generation:2,CreationTimestamp:2019-08-16 14:11:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-08-16 14:11:21 +0000 UTC 2019-08-16 14:11:21 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-08-16 14:11:21 +0000 UTC 2019-08-16 14:11:19 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-697fbf54bf" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Aug 16 14:11:21.239: INFO: New ReplicaSet "test-recreate-deployment-697fbf54bf" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf,GenerateName:,Namespace:e2e-tests-deployment-tlppv,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-tlppv/replicasets/test-recreate-deployment-697fbf54bf,UID:b90436bc-c02f-11e9-ae7d-02d5aa9cbbca,ResourceVersion:36019,Generation:1,CreationTimestamp:2019-08-16 14:11:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment b7c7d2ee-c02f-11e9-ae7d-02d5aa9cbbca 0xc00299b6e7 0xc00299b6e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug 16 14:11:21.239: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Aug 16 14:11:21.239: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5dfdcc846d,GenerateName:,Namespace:e2e-tests-deployment-tlppv,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-tlppv/replicasets/test-recreate-deployment-5dfdcc846d,UID:b7c8a1ad-c02f-11e9-ae7d-02d5aa9cbbca,ResourceVersion:36009,Generation:2,CreationTimestamp:2019-08-16 14:11:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment b7c7d2ee-c02f-11e9-ae7d-02d5aa9cbbca 0xc00299b627 0xc00299b628}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug 16 14:11:21.242: INFO: Pod "test-recreate-deployment-697fbf54bf-6zznp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf-6zznp,GenerateName:test-recreate-deployment-697fbf54bf-,Namespace:e2e-tests-deployment-tlppv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-tlppv/pods/test-recreate-deployment-697fbf54bf-6zznp,UID:b90522a4-c02f-11e9-ae7d-02d5aa9cbbca,ResourceVersion:36021,Generation:0,CreationTimestamp:2019-08-16 14:11:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-697fbf54bf b90436bc-c02f-11e9-ae7d-02d5aa9cbbca 0xc00299bf57 0xc00299bf58}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-q4ppd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-q4ppd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-q4ppd true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker-eab92000-c026-11e9-bfed-069795ba99e0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00299bfc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00299bfe0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 14:11:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-16 14:11:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-16 14:11:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 14:11:21 +0000 UTC  }],Message:,Reason:,HostIP:10.1.161.42,PodIP:,StartTime:2019-08-16 14:11:21 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 14:11:21.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-tlppv" for this suite.
Aug 16 14:11:27.261: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 14:11:27.298: INFO: namespace: e2e-tests-deployment-tlppv, resource: bindings, ignored listing per whitelist
Aug 16 14:11:27.395: INFO: namespace e2e-tests-deployment-tlppv deletion completed in 6.148921956s

• [SLOW TEST:8.378 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 14:11:27.398: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-8qtxw
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-8qtxw
STEP: Deleting pre-stop pod
Aug 16 14:11:38.510: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 14:11:38.522: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-8qtxw" for this suite.
Aug 16 14:12:16.554: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 14:12:16.657: INFO: namespace: e2e-tests-prestop-8qtxw, resource: bindings, ignored listing per whitelist
Aug 16 14:12:16.669: INFO: namespace e2e-tests-prestop-8qtxw deletion completed in 38.142425505s

• [SLOW TEST:49.271 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 14:12:16.669: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-da21eb95-c02f-11e9-99f6-8a077000b195
STEP: Creating a pod to test consume configMaps
Aug 16 14:12:16.727: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-da22a514-c02f-11e9-99f6-8a077000b195" in namespace "e2e-tests-projected-xnp5z" to be "success or failure"
Aug 16 14:12:16.732: INFO: Pod "pod-projected-configmaps-da22a514-c02f-11e9-99f6-8a077000b195": Phase="Pending", Reason="", readiness=false. Elapsed: 4.233131ms
Aug 16 14:12:18.735: INFO: Pod "pod-projected-configmaps-da22a514-c02f-11e9-99f6-8a077000b195": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00793545s
STEP: Saw pod success
Aug 16 14:12:18.735: INFO: Pod "pod-projected-configmaps-da22a514-c02f-11e9-99f6-8a077000b195" satisfied condition "success or failure"
Aug 16 14:12:18.738: INFO: Trying to get logs from node worker-eab92000-c026-11e9-bfed-069795ba99e0 pod pod-projected-configmaps-da22a514-c02f-11e9-99f6-8a077000b195 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 16 14:12:18.768: INFO: Waiting for pod pod-projected-configmaps-da22a514-c02f-11e9-99f6-8a077000b195 to disappear
Aug 16 14:12:18.774: INFO: Pod pod-projected-configmaps-da22a514-c02f-11e9-99f6-8a077000b195 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 14:12:18.774: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-xnp5z" for this suite.
Aug 16 14:12:24.791: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 14:12:24.861: INFO: namespace: e2e-tests-projected-xnp5z, resource: bindings, ignored listing per whitelist
Aug 16 14:12:24.905: INFO: namespace e2e-tests-projected-xnp5z deletion completed in 6.127234966s

• [SLOW TEST:8.236 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 14:12:24.905: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
Aug 16 14:12:24.961: INFO: Waiting up to 5m0s for pod "pod-df0ace0c-c02f-11e9-99f6-8a077000b195" in namespace "e2e-tests-emptydir-bmsn5" to be "success or failure"
Aug 16 14:12:24.967: INFO: Pod "pod-df0ace0c-c02f-11e9-99f6-8a077000b195": Phase="Pending", Reason="", readiness=false. Elapsed: 5.920999ms
Aug 16 14:12:26.978: INFO: Pod "pod-df0ace0c-c02f-11e9-99f6-8a077000b195": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0162127s
STEP: Saw pod success
Aug 16 14:12:26.978: INFO: Pod "pod-df0ace0c-c02f-11e9-99f6-8a077000b195" satisfied condition "success or failure"
Aug 16 14:12:26.981: INFO: Trying to get logs from node worker-eab92000-c026-11e9-bfed-069795ba99e0 pod pod-df0ace0c-c02f-11e9-99f6-8a077000b195 container test-container: <nil>
STEP: delete the pod
Aug 16 14:12:27.006: INFO: Waiting for pod pod-df0ace0c-c02f-11e9-99f6-8a077000b195 to disappear
Aug 16 14:12:27.012: INFO: Pod pod-df0ace0c-c02f-11e9-99f6-8a077000b195 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 14:12:27.012: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-bmsn5" for this suite.
Aug 16 14:12:33.030: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 14:12:33.039: INFO: namespace: e2e-tests-emptydir-bmsn5, resource: bindings, ignored listing per whitelist
Aug 16 14:12:33.141: INFO: namespace e2e-tests-emptydir-bmsn5 deletion completed in 6.125105195s

• [SLOW TEST:8.236 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 14:12:33.141: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Aug 16 14:12:33.200: INFO: Waiting up to 5m0s for pod "pod-e3f426e2-c02f-11e9-99f6-8a077000b195" in namespace "e2e-tests-emptydir-hphdz" to be "success or failure"
Aug 16 14:12:33.204: INFO: Pod "pod-e3f426e2-c02f-11e9-99f6-8a077000b195": Phase="Pending", Reason="", readiness=false. Elapsed: 4.353164ms
Aug 16 14:12:35.208: INFO: Pod "pod-e3f426e2-c02f-11e9-99f6-8a077000b195": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007992724s
STEP: Saw pod success
Aug 16 14:12:35.208: INFO: Pod "pod-e3f426e2-c02f-11e9-99f6-8a077000b195" satisfied condition "success or failure"
Aug 16 14:12:35.211: INFO: Trying to get logs from node worker-eab92000-c026-11e9-bfed-069795ba99e0 pod pod-e3f426e2-c02f-11e9-99f6-8a077000b195 container test-container: <nil>
STEP: delete the pod
Aug 16 14:12:35.237: INFO: Waiting for pod pod-e3f426e2-c02f-11e9-99f6-8a077000b195 to disappear
Aug 16 14:12:35.243: INFO: Pod pod-e3f426e2-c02f-11e9-99f6-8a077000b195 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 14:12:35.243: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-hphdz" for this suite.
Aug 16 14:12:41.260: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 14:12:41.281: INFO: namespace: e2e-tests-emptydir-hphdz, resource: bindings, ignored listing per whitelist
Aug 16 14:12:41.371: INFO: namespace e2e-tests-emptydir-hphdz deletion completed in 6.124128867s

• [SLOW TEST:8.230 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 14:12:41.371: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-48mr
STEP: Creating a pod to test atomic-volume-subpath
Aug 16 14:12:41.451: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-48mr" in namespace "e2e-tests-subpath-kpwdz" to be "success or failure"
Aug 16 14:12:41.457: INFO: Pod "pod-subpath-test-downwardapi-48mr": Phase="Pending", Reason="", readiness=false. Elapsed: 5.816564ms
Aug 16 14:12:43.461: INFO: Pod "pod-subpath-test-downwardapi-48mr": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009805453s
Aug 16 14:12:45.465: INFO: Pod "pod-subpath-test-downwardapi-48mr": Phase="Running", Reason="", readiness=false. Elapsed: 4.01367881s
Aug 16 14:12:47.475: INFO: Pod "pod-subpath-test-downwardapi-48mr": Phase="Running", Reason="", readiness=false. Elapsed: 6.023992272s
Aug 16 14:12:49.479: INFO: Pod "pod-subpath-test-downwardapi-48mr": Phase="Running", Reason="", readiness=false. Elapsed: 8.027777334s
Aug 16 14:12:51.483: INFO: Pod "pod-subpath-test-downwardapi-48mr": Phase="Running", Reason="", readiness=false. Elapsed: 10.031413675s
Aug 16 14:12:53.486: INFO: Pod "pod-subpath-test-downwardapi-48mr": Phase="Running", Reason="", readiness=false. Elapsed: 12.035047991s
Aug 16 14:12:55.490: INFO: Pod "pod-subpath-test-downwardapi-48mr": Phase="Running", Reason="", readiness=false. Elapsed: 14.038704483s
Aug 16 14:12:57.500: INFO: Pod "pod-subpath-test-downwardapi-48mr": Phase="Running", Reason="", readiness=false. Elapsed: 16.048747869s
Aug 16 14:12:59.504: INFO: Pod "pod-subpath-test-downwardapi-48mr": Phase="Running", Reason="", readiness=false. Elapsed: 18.052780527s
Aug 16 14:13:01.508: INFO: Pod "pod-subpath-test-downwardapi-48mr": Phase="Running", Reason="", readiness=false. Elapsed: 20.056722976s
Aug 16 14:13:03.512: INFO: Pod "pod-subpath-test-downwardapi-48mr": Phase="Running", Reason="", readiness=false. Elapsed: 22.060570556s
Aug 16 14:13:05.516: INFO: Pod "pod-subpath-test-downwardapi-48mr": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.064353552s
STEP: Saw pod success
Aug 16 14:13:05.516: INFO: Pod "pod-subpath-test-downwardapi-48mr" satisfied condition "success or failure"
Aug 16 14:13:05.519: INFO: Trying to get logs from node worker-eab92000-c026-11e9-bfed-069795ba99e0 pod pod-subpath-test-downwardapi-48mr container test-container-subpath-downwardapi-48mr: <nil>
STEP: delete the pod
Aug 16 14:13:05.544: INFO: Waiting for pod pod-subpath-test-downwardapi-48mr to disappear
Aug 16 14:13:05.549: INFO: Pod pod-subpath-test-downwardapi-48mr no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-48mr
Aug 16 14:13:05.549: INFO: Deleting pod "pod-subpath-test-downwardapi-48mr" in namespace "e2e-tests-subpath-kpwdz"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 14:13:05.552: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-kpwdz" for this suite.
Aug 16 14:13:11.574: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 14:13:11.639: INFO: namespace: e2e-tests-subpath-kpwdz, resource: bindings, ignored listing per whitelist
Aug 16 14:13:11.700: INFO: namespace e2e-tests-subpath-kpwdz deletion completed in 6.143606595s

• [SLOW TEST:30.329 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 14:13:11.700: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Aug 16 14:13:11.971: INFO: Pod name wrapped-volume-race-fb0ed0eb-c02f-11e9-99f6-8a077000b195: Found 0 pods out of 5
Aug 16 14:13:16.977: INFO: Pod name wrapped-volume-race-fb0ed0eb-c02f-11e9-99f6-8a077000b195: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-fb0ed0eb-c02f-11e9-99f6-8a077000b195 in namespace e2e-tests-emptydir-wrapper-kdjfs, will wait for the garbage collector to delete the pods
Aug 16 14:15:19.073: INFO: Deleting ReplicationController wrapped-volume-race-fb0ed0eb-c02f-11e9-99f6-8a077000b195 took: 14.502422ms
Aug 16 14:15:19.173: INFO: Terminating ReplicationController wrapped-volume-race-fb0ed0eb-c02f-11e9-99f6-8a077000b195 pods took: 100.13651ms
STEP: Creating RC which spawns configmap-volume pods
Aug 16 14:16:01.562: INFO: Pod name wrapped-volume-race-601934b8-c030-11e9-99f6-8a077000b195: Found 0 pods out of 5
Aug 16 14:16:06.567: INFO: Pod name wrapped-volume-race-601934b8-c030-11e9-99f6-8a077000b195: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-601934b8-c030-11e9-99f6-8a077000b195 in namespace e2e-tests-emptydir-wrapper-kdjfs, will wait for the garbage collector to delete the pods
Aug 16 14:18:00.657: INFO: Deleting ReplicationController wrapped-volume-race-601934b8-c030-11e9-99f6-8a077000b195 took: 9.45686ms
Aug 16 14:18:00.757: INFO: Terminating ReplicationController wrapped-volume-race-601934b8-c030-11e9-99f6-8a077000b195 pods took: 100.143126ms
STEP: Creating RC which spawns configmap-volume pods
Aug 16 14:18:41.783: INFO: Pod name wrapped-volume-race-bfa2862d-c030-11e9-99f6-8a077000b195: Found 0 pods out of 5
Aug 16 14:18:46.795: INFO: Pod name wrapped-volume-race-bfa2862d-c030-11e9-99f6-8a077000b195: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-bfa2862d-c030-11e9-99f6-8a077000b195 in namespace e2e-tests-emptydir-wrapper-kdjfs, will wait for the garbage collector to delete the pods
Aug 16 14:21:22.879: INFO: Deleting ReplicationController wrapped-volume-race-bfa2862d-c030-11e9-99f6-8a077000b195 took: 10.32147ms
Aug 16 14:21:22.979: INFO: Terminating ReplicationController wrapped-volume-race-bfa2862d-c030-11e9-99f6-8a077000b195 pods took: 100.164289ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 14:22:01.917: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-kdjfs" for this suite.
Aug 16 14:22:07.934: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 14:22:07.965: INFO: namespace: e2e-tests-emptydir-wrapper-kdjfs, resource: bindings, ignored listing per whitelist
Aug 16 14:22:08.048: INFO: namespace e2e-tests-emptydir-wrapper-kdjfs deletion completed in 6.127778263s

• [SLOW TEST:536.348 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 14:22:08.048: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Aug 16 14:22:08.106: INFO: Waiting up to 5m0s for pod "pod-3a9fcdaf-c031-11e9-99f6-8a077000b195" in namespace "e2e-tests-emptydir-4hqbg" to be "success or failure"
Aug 16 14:22:08.110: INFO: Pod "pod-3a9fcdaf-c031-11e9-99f6-8a077000b195": Phase="Pending", Reason="", readiness=false. Elapsed: 4.628944ms
Aug 16 14:22:10.114: INFO: Pod "pod-3a9fcdaf-c031-11e9-99f6-8a077000b195": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008620173s
STEP: Saw pod success
Aug 16 14:22:10.114: INFO: Pod "pod-3a9fcdaf-c031-11e9-99f6-8a077000b195" satisfied condition "success or failure"
Aug 16 14:22:10.117: INFO: Trying to get logs from node worker-eab92000-c026-11e9-bfed-069795ba99e0 pod pod-3a9fcdaf-c031-11e9-99f6-8a077000b195 container test-container: <nil>
STEP: delete the pod
Aug 16 14:22:10.143: INFO: Waiting for pod pod-3a9fcdaf-c031-11e9-99f6-8a077000b195 to disappear
Aug 16 14:22:10.149: INFO: Pod pod-3a9fcdaf-c031-11e9-99f6-8a077000b195 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 14:22:10.150: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-4hqbg" for this suite.
Aug 16 14:22:16.167: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 14:22:16.173: INFO: namespace: e2e-tests-emptydir-4hqbg, resource: bindings, ignored listing per whitelist
Aug 16 14:22:16.280: INFO: namespace e2e-tests-emptydir-4hqbg deletion completed in 6.125912638s

• [SLOW TEST:8.231 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 14:22:16.280: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Aug 16 14:22:16.331: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 14:22:19.009: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-qv6pk" for this suite.
Aug 16 14:22:25.029: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 14:22:25.157: INFO: namespace: e2e-tests-init-container-qv6pk, resource: bindings, ignored listing per whitelist
Aug 16 14:22:25.158: INFO: namespace e2e-tests-init-container-qv6pk deletion completed in 6.143456878s

• [SLOW TEST:8.878 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 14:22:25.158: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
Aug 16 14:22:25.207: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-739526127 proxy --unix-socket=/tmp/kubectl-proxy-unix473079426/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 14:22:25.249: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-qxk26" for this suite.
Aug 16 14:22:31.274: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 14:22:31.402: INFO: namespace: e2e-tests-kubectl-qxk26, resource: bindings, ignored listing per whitelist
Aug 16 14:22:31.402: INFO: namespace e2e-tests-kubectl-qxk26 deletion completed in 6.148535856s

• [SLOW TEST:6.245 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 14:22:31.403: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Aug 16 14:22:33.989: INFO: Successfully updated pod "pod-update-activedeadlineseconds-488b290d-c031-11e9-99f6-8a077000b195"
Aug 16 14:22:33.989: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-488b290d-c031-11e9-99f6-8a077000b195" in namespace "e2e-tests-pods-vrnng" to be "terminated due to deadline exceeded"
Aug 16 14:22:33.995: INFO: Pod "pod-update-activedeadlineseconds-488b290d-c031-11e9-99f6-8a077000b195": Phase="Running", Reason="", readiness=true. Elapsed: 5.730997ms
Aug 16 14:22:35.998: INFO: Pod "pod-update-activedeadlineseconds-488b290d-c031-11e9-99f6-8a077000b195": Phase="Running", Reason="", readiness=true. Elapsed: 2.009525664s
Aug 16 14:22:38.002: INFO: Pod "pod-update-activedeadlineseconds-488b290d-c031-11e9-99f6-8a077000b195": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.013213436s
Aug 16 14:22:38.002: INFO: Pod "pod-update-activedeadlineseconds-488b290d-c031-11e9-99f6-8a077000b195" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 14:22:38.002: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-vrnng" for this suite.
Aug 16 14:22:44.027: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 14:22:44.124: INFO: namespace: e2e-tests-pods-vrnng, resource: bindings, ignored listing per whitelist
Aug 16 14:22:44.137: INFO: namespace e2e-tests-pods-vrnng deletion completed in 6.130845288s

• [SLOW TEST:12.735 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 14:22:44.137: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Aug 16 14:22:44.196: INFO: Waiting up to 5m0s for pod "pod-50223a63-c031-11e9-99f6-8a077000b195" in namespace "e2e-tests-emptydir-kgqth" to be "success or failure"
Aug 16 14:22:44.203: INFO: Pod "pod-50223a63-c031-11e9-99f6-8a077000b195": Phase="Pending", Reason="", readiness=false. Elapsed: 6.865434ms
Aug 16 14:22:46.207: INFO: Pod "pod-50223a63-c031-11e9-99f6-8a077000b195": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010669598s
STEP: Saw pod success
Aug 16 14:22:46.207: INFO: Pod "pod-50223a63-c031-11e9-99f6-8a077000b195" satisfied condition "success or failure"
Aug 16 14:22:46.211: INFO: Trying to get logs from node worker-eab92000-c026-11e9-bfed-069795ba99e0 pod pod-50223a63-c031-11e9-99f6-8a077000b195 container test-container: <nil>
STEP: delete the pod
Aug 16 14:22:46.237: INFO: Waiting for pod pod-50223a63-c031-11e9-99f6-8a077000b195 to disappear
Aug 16 14:22:46.241: INFO: Pod pod-50223a63-c031-11e9-99f6-8a077000b195 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 14:22:46.241: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-kgqth" for this suite.
Aug 16 14:22:52.259: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 14:22:52.331: INFO: namespace: e2e-tests-emptydir-kgqth, resource: bindings, ignored listing per whitelist
Aug 16 14:22:52.376: INFO: namespace e2e-tests-emptydir-kgqth deletion completed in 6.130432266s

• [SLOW TEST:8.239 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 14:22:52.376: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-550b8640-c031-11e9-99f6-8a077000b195
STEP: Creating a pod to test consume secrets
Aug 16 14:22:52.439: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-550c208d-c031-11e9-99f6-8a077000b195" in namespace "e2e-tests-projected-tc9vd" to be "success or failure"
Aug 16 14:22:52.442: INFO: Pod "pod-projected-secrets-550c208d-c031-11e9-99f6-8a077000b195": Phase="Pending", Reason="", readiness=false. Elapsed: 3.279037ms
Aug 16 14:22:54.453: INFO: Pod "pod-projected-secrets-550c208d-c031-11e9-99f6-8a077000b195": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013929072s
STEP: Saw pod success
Aug 16 14:22:54.453: INFO: Pod "pod-projected-secrets-550c208d-c031-11e9-99f6-8a077000b195" satisfied condition "success or failure"
Aug 16 14:22:54.456: INFO: Trying to get logs from node worker-eab92000-c026-11e9-bfed-069795ba99e0 pod pod-projected-secrets-550c208d-c031-11e9-99f6-8a077000b195 container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug 16 14:22:54.486: INFO: Waiting for pod pod-projected-secrets-550c208d-c031-11e9-99f6-8a077000b195 to disappear
Aug 16 14:22:54.492: INFO: Pod pod-projected-secrets-550c208d-c031-11e9-99f6-8a077000b195 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 14:22:54.492: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-tc9vd" for this suite.
Aug 16 14:23:00.513: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 14:23:00.606: INFO: namespace: e2e-tests-projected-tc9vd, resource: bindings, ignored listing per whitelist
Aug 16 14:23:00.631: INFO: namespace e2e-tests-projected-tc9vd deletion completed in 6.134257403s

• [SLOW TEST:8.255 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 14:23:00.631: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-qmwhq
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-qmwhq
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-qmwhq
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-qmwhq
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-qmwhq
Aug 16 14:23:04.743: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-qmwhq, name: ss-0, uid: 5c414271-c031-11e9-ae7d-02d5aa9cbbca, status phase: Pending. Waiting for statefulset controller to delete.
Aug 16 14:23:05.121: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-qmwhq, name: ss-0, uid: 5c414271-c031-11e9-ae7d-02d5aa9cbbca, status phase: Failed. Waiting for statefulset controller to delete.
Aug 16 14:23:05.130: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-qmwhq, name: ss-0, uid: 5c414271-c031-11e9-ae7d-02d5aa9cbbca, status phase: Failed. Waiting for statefulset controller to delete.
Aug 16 14:23:05.138: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-qmwhq
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-qmwhq
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-qmwhq and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Aug 16 14:23:09.178: INFO: Deleting all statefulset in ns e2e-tests-statefulset-qmwhq
Aug 16 14:23:09.181: INFO: Scaling statefulset ss to 0
Aug 16 14:23:19.203: INFO: Waiting for statefulset status.replicas updated to 0
Aug 16 14:23:19.206: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 14:23:19.221: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-qmwhq" for this suite.
Aug 16 14:23:25.239: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 14:23:25.274: INFO: namespace: e2e-tests-statefulset-qmwhq, resource: bindings, ignored listing per whitelist
Aug 16 14:23:25.352: INFO: namespace e2e-tests-statefulset-qmwhq deletion completed in 6.126624696s

• [SLOW TEST:24.721 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 14:23:25.352: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-68b59785-c031-11e9-99f6-8a077000b195
STEP: Creating a pod to test consume secrets
Aug 16 14:23:25.430: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-68b671f2-c031-11e9-99f6-8a077000b195" in namespace "e2e-tests-projected-pxqtl" to be "success or failure"
Aug 16 14:23:25.434: INFO: Pod "pod-projected-secrets-68b671f2-c031-11e9-99f6-8a077000b195": Phase="Pending", Reason="", readiness=false. Elapsed: 3.730484ms
Aug 16 14:23:27.438: INFO: Pod "pod-projected-secrets-68b671f2-c031-11e9-99f6-8a077000b195": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007487727s
STEP: Saw pod success
Aug 16 14:23:27.438: INFO: Pod "pod-projected-secrets-68b671f2-c031-11e9-99f6-8a077000b195" satisfied condition "success or failure"
Aug 16 14:23:27.441: INFO: Trying to get logs from node worker-eab92000-c026-11e9-bfed-069795ba99e0 pod pod-projected-secrets-68b671f2-c031-11e9-99f6-8a077000b195 container secret-volume-test: <nil>
STEP: delete the pod
Aug 16 14:23:27.464: INFO: Waiting for pod pod-projected-secrets-68b671f2-c031-11e9-99f6-8a077000b195 to disappear
Aug 16 14:23:27.479: INFO: Pod pod-projected-secrets-68b671f2-c031-11e9-99f6-8a077000b195 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 14:23:27.479: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-pxqtl" for this suite.
Aug 16 14:23:33.499: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 14:23:33.514: INFO: namespace: e2e-tests-projected-pxqtl, resource: bindings, ignored listing per whitelist
Aug 16 14:23:33.616: INFO: namespace e2e-tests-projected-pxqtl deletion completed in 6.131685133s

• [SLOW TEST:8.264 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 14:23:33.616: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 14:23:35.693: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-8g87k" for this suite.
Aug 16 14:24:13.713: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 14:24:13.813: INFO: namespace: e2e-tests-kubelet-test-8g87k, resource: bindings, ignored listing per whitelist
Aug 16 14:24:13.833: INFO: namespace e2e-tests-kubelet-test-8g87k deletion completed in 38.135187736s

• [SLOW TEST:40.216 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a read only busybox container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:186
    should not write to root filesystem [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 14:24:13.833: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-85a03f3e-c031-11e9-99f6-8a077000b195
STEP: Creating a pod to test consume secrets
Aug 16 14:24:13.943: INFO: Waiting up to 5m0s for pod "pod-secrets-85a0ef5f-c031-11e9-99f6-8a077000b195" in namespace "e2e-tests-secrets-nhn8c" to be "success or failure"
Aug 16 14:24:13.948: INFO: Pod "pod-secrets-85a0ef5f-c031-11e9-99f6-8a077000b195": Phase="Pending", Reason="", readiness=false. Elapsed: 5.167548ms
Aug 16 14:24:15.952: INFO: Pod "pod-secrets-85a0ef5f-c031-11e9-99f6-8a077000b195": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009146027s
STEP: Saw pod success
Aug 16 14:24:15.952: INFO: Pod "pod-secrets-85a0ef5f-c031-11e9-99f6-8a077000b195" satisfied condition "success or failure"
Aug 16 14:24:15.955: INFO: Trying to get logs from node worker-eab92000-c026-11e9-bfed-069795ba99e0 pod pod-secrets-85a0ef5f-c031-11e9-99f6-8a077000b195 container secret-env-test: <nil>
STEP: delete the pod
Aug 16 14:24:15.978: INFO: Waiting for pod pod-secrets-85a0ef5f-c031-11e9-99f6-8a077000b195 to disappear
Aug 16 14:24:15.984: INFO: Pod pod-secrets-85a0ef5f-c031-11e9-99f6-8a077000b195 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 14:24:15.984: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-nhn8c" for this suite.
Aug 16 14:24:22.001: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 14:24:22.077: INFO: namespace: e2e-tests-secrets-nhn8c, resource: bindings, ignored listing per whitelist
Aug 16 14:24:22.112: INFO: namespace e2e-tests-secrets-nhn8c deletion completed in 6.123384111s

• [SLOW TEST:8.279 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 14:24:22.112: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Aug 16 14:24:24.706: INFO: Successfully updated pod "labelsupdate8a880521-c031-11e9-99f6-8a077000b195"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 14:24:26.726: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-xh2r8" for this suite.
Aug 16 14:24:48.744: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 14:24:48.753: INFO: namespace: e2e-tests-downward-api-xh2r8, resource: bindings, ignored listing per whitelist
Aug 16 14:24:48.859: INFO: namespace e2e-tests-downward-api-xh2r8 deletion completed in 22.128521119s

• [SLOW TEST:26.747 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 14:24:48.859: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-9hgld
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-9hgld
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-9hgld
Aug 16 14:24:48.931: INFO: Found 0 stateful pods, waiting for 1
Aug 16 14:24:58.942: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Aug 16 14:24:58.945: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 exec --namespace=e2e-tests-statefulset-9hgld ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 16 14:24:59.088: INFO: stderr: ""
Aug 16 14:24:59.088: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 16 14:24:59.088: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 16 14:24:59.092: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Aug 16 14:25:09.107: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug 16 14:25:09.107: INFO: Waiting for statefulset status.replicas updated to 0
Aug 16 14:25:09.123: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999741s
Aug 16 14:25:10.127: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.994192103s
Aug 16 14:25:11.131: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.990216314s
Aug 16 14:25:12.135: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.986273832s
Aug 16 14:25:13.139: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.982450215s
Aug 16 14:25:14.143: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.97863269s
Aug 16 14:25:15.147: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.974475869s
Aug 16 14:25:16.151: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.970503098s
Aug 16 14:25:17.154: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.966503565s
Aug 16 14:25:18.158: INFO: Verifying statefulset ss doesn't scale past 1 for another 962.80064ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-9hgld
Aug 16 14:25:19.169: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 exec --namespace=e2e-tests-statefulset-9hgld ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 16 14:25:19.314: INFO: stderr: ""
Aug 16 14:25:19.314: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 16 14:25:19.314: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 16 14:25:19.318: INFO: Found 1 stateful pods, waiting for 3
Aug 16 14:25:29.329: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 16 14:25:29.329: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 16 14:25:29.329: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Aug 16 14:25:29.333: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 exec --namespace=e2e-tests-statefulset-9hgld ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 16 14:25:29.463: INFO: stderr: ""
Aug 16 14:25:29.463: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 16 14:25:29.463: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 16 14:25:29.463: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 exec --namespace=e2e-tests-statefulset-9hgld ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 16 14:25:29.591: INFO: stderr: ""
Aug 16 14:25:29.591: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 16 14:25:29.591: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 16 14:25:29.591: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 exec --namespace=e2e-tests-statefulset-9hgld ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 16 14:25:29.770: INFO: stderr: ""
Aug 16 14:25:29.770: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 16 14:25:29.770: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 16 14:25:29.770: INFO: Waiting for statefulset status.replicas updated to 0
Aug 16 14:25:29.773: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Aug 16 14:25:39.787: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug 16 14:25:39.787: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Aug 16 14:25:39.787: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Aug 16 14:25:39.798: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999815s
Aug 16 14:25:40.802: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.996398374s
Aug 16 14:25:41.806: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.992274001s
Aug 16 14:25:42.810: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.988215117s
Aug 16 14:25:43.814: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.984006697s
Aug 16 14:25:44.818: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.980207096s
Aug 16 14:25:45.822: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.976150504s
Aug 16 14:25:46.827: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.972145473s
Aug 16 14:25:47.831: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.967964211s
Aug 16 14:25:48.835: INFO: Verifying statefulset ss doesn't scale past 3 for another 963.8561ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-9hgld
Aug 16 14:25:49.845: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 exec --namespace=e2e-tests-statefulset-9hgld ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 16 14:25:49.982: INFO: stderr: ""
Aug 16 14:25:49.982: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 16 14:25:49.982: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 16 14:25:49.982: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 exec --namespace=e2e-tests-statefulset-9hgld ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 16 14:25:50.125: INFO: stderr: ""
Aug 16 14:25:50.125: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 16 14:25:50.125: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 16 14:25:50.125: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 exec --namespace=e2e-tests-statefulset-9hgld ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 16 14:25:50.262: INFO: stderr: ""
Aug 16 14:25:50.262: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 16 14:25:50.262: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 16 14:25:50.262: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Aug 16 14:26:30.276: INFO: Deleting all statefulset in ns e2e-tests-statefulset-9hgld
Aug 16 14:26:30.279: INFO: Scaling statefulset ss to 0
Aug 16 14:26:30.295: INFO: Waiting for statefulset status.replicas updated to 0
Aug 16 14:26:30.298: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 14:26:30.313: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-9hgld" for this suite.
Aug 16 14:26:36.331: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 14:26:36.394: INFO: namespace: e2e-tests-statefulset-9hgld, resource: bindings, ignored listing per whitelist
Aug 16 14:26:36.455: INFO: namespace e2e-tests-statefulset-9hgld deletion completed in 6.137718827s

• [SLOW TEST:107.596 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 14:26:36.456: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-cbwrr
Aug 16 14:26:38.520: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-cbwrr
STEP: checking the pod's current state and verifying that restartCount is present
Aug 16 14:26:38.523: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 14:30:39.171: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-cbwrr" for this suite.
Aug 16 14:30:45.199: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 14:30:45.310: INFO: namespace: e2e-tests-container-probe-cbwrr, resource: bindings, ignored listing per whitelist
Aug 16 14:30:45.315: INFO: namespace e2e-tests-container-probe-cbwrr deletion completed in 6.140183508s

• [SLOW TEST:248.860 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 14:30:45.316: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Aug 16 14:30:47.908: INFO: Successfully updated pod "annotationupdate6eefe3f0-c032-11e9-99f6-8a077000b195"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 14:30:49.926: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-6sv5g" for this suite.
Aug 16 14:31:11.943: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 14:31:12.018: INFO: namespace: e2e-tests-downward-api-6sv5g, resource: bindings, ignored listing per whitelist
Aug 16 14:31:12.056: INFO: namespace e2e-tests-downward-api-6sv5g deletion completed in 22.126900347s

• [SLOW TEST:26.741 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 14:31:12.056: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug 16 14:31:12.115: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7ee0ce1a-c032-11e9-99f6-8a077000b195" in namespace "e2e-tests-projected-nwmgj" to be "success or failure"
Aug 16 14:31:12.119: INFO: Pod "downwardapi-volume-7ee0ce1a-c032-11e9-99f6-8a077000b195": Phase="Pending", Reason="", readiness=false. Elapsed: 4.283153ms
Aug 16 14:31:14.129: INFO: Pod "downwardapi-volume-7ee0ce1a-c032-11e9-99f6-8a077000b195": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014275384s
STEP: Saw pod success
Aug 16 14:31:14.129: INFO: Pod "downwardapi-volume-7ee0ce1a-c032-11e9-99f6-8a077000b195" satisfied condition "success or failure"
Aug 16 14:31:14.132: INFO: Trying to get logs from node worker-eab92000-c026-11e9-bfed-069795ba99e0 pod downwardapi-volume-7ee0ce1a-c032-11e9-99f6-8a077000b195 container client-container: <nil>
STEP: delete the pod
Aug 16 14:31:14.157: INFO: Waiting for pod downwardapi-volume-7ee0ce1a-c032-11e9-99f6-8a077000b195 to disappear
Aug 16 14:31:14.163: INFO: Pod downwardapi-volume-7ee0ce1a-c032-11e9-99f6-8a077000b195 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 14:31:14.163: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-nwmgj" for this suite.
Aug 16 14:31:20.179: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 14:31:20.243: INFO: namespace: e2e-tests-projected-nwmgj, resource: bindings, ignored listing per whitelist
Aug 16 14:31:20.287: INFO: namespace e2e-tests-projected-nwmgj deletion completed in 6.120904301s

• [SLOW TEST:8.231 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 14:31:20.287: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug 16 14:31:20.347: INFO: Waiting up to 5m0s for pod "downwardapi-volume-83c90050-c032-11e9-99f6-8a077000b195" in namespace "e2e-tests-downward-api-8ws69" to be "success or failure"
Aug 16 14:31:20.351: INFO: Pod "downwardapi-volume-83c90050-c032-11e9-99f6-8a077000b195": Phase="Pending", Reason="", readiness=false. Elapsed: 4.331439ms
Aug 16 14:31:22.355: INFO: Pod "downwardapi-volume-83c90050-c032-11e9-99f6-8a077000b195": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008172731s
STEP: Saw pod success
Aug 16 14:31:22.355: INFO: Pod "downwardapi-volume-83c90050-c032-11e9-99f6-8a077000b195" satisfied condition "success or failure"
Aug 16 14:31:22.358: INFO: Trying to get logs from node worker-eab92000-c026-11e9-bfed-069795ba99e0 pod downwardapi-volume-83c90050-c032-11e9-99f6-8a077000b195 container client-container: <nil>
STEP: delete the pod
Aug 16 14:31:22.384: INFO: Waiting for pod downwardapi-volume-83c90050-c032-11e9-99f6-8a077000b195 to disappear
Aug 16 14:31:22.388: INFO: Pod downwardapi-volume-83c90050-c032-11e9-99f6-8a077000b195 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 14:31:22.388: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-8ws69" for this suite.
Aug 16 14:31:28.405: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 14:31:28.418: INFO: namespace: e2e-tests-downward-api-8ws69, resource: bindings, ignored listing per whitelist
Aug 16 14:31:28.518: INFO: namespace e2e-tests-downward-api-8ws69 deletion completed in 6.126480521s

• [SLOW TEST:8.231 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 14:31:28.519: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-88b0a02d-c032-11e9-99f6-8a077000b195
Aug 16 14:31:28.577: INFO: Pod name my-hostname-basic-88b0a02d-c032-11e9-99f6-8a077000b195: Found 0 pods out of 1
Aug 16 14:31:33.581: INFO: Pod name my-hostname-basic-88b0a02d-c032-11e9-99f6-8a077000b195: Found 1 pods out of 1
Aug 16 14:31:33.581: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-88b0a02d-c032-11e9-99f6-8a077000b195" are running
Aug 16 14:31:33.584: INFO: Pod "my-hostname-basic-88b0a02d-c032-11e9-99f6-8a077000b195-ntt64" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-16 14:31:28 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-16 14:31:30 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-16 14:31:30 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-16 14:31:28 +0000 UTC Reason: Message:}])
Aug 16 14:31:33.584: INFO: Trying to dial the pod
Aug 16 14:31:38.602: INFO: Controller my-hostname-basic-88b0a02d-c032-11e9-99f6-8a077000b195: Got expected result from replica 1 [my-hostname-basic-88b0a02d-c032-11e9-99f6-8a077000b195-ntt64]: "my-hostname-basic-88b0a02d-c032-11e9-99f6-8a077000b195-ntt64", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 14:31:38.602: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-x4j9c" for this suite.
Aug 16 14:31:44.621: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 14:31:44.639: INFO: namespace: e2e-tests-replication-controller-x4j9c, resource: bindings, ignored listing per whitelist
Aug 16 14:31:44.733: INFO: namespace e2e-tests-replication-controller-x4j9c deletion completed in 6.1263421s

• [SLOW TEST:16.214 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 14:31:44.733: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0816 14:31:50.821883      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Aug 16 14:31:50.821: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 14:31:50.821: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-w2qxk" for this suite.
Aug 16 14:31:56.839: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 14:31:56.932: INFO: namespace: e2e-tests-gc-w2qxk, resource: bindings, ignored listing per whitelist
Aug 16 14:31:56.952: INFO: namespace e2e-tests-gc-w2qxk deletion completed in 6.127353472s

• [SLOW TEST:12.219 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 14:31:56.952: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Aug 16 14:31:57.010: INFO: Waiting up to 5m0s for pod "downwardapi-volume-99a2f7cb-c032-11e9-99f6-8a077000b195" in namespace "e2e-tests-downward-api-7xkdt" to be "success or failure"
Aug 16 14:31:57.013: INFO: Pod "downwardapi-volume-99a2f7cb-c032-11e9-99f6-8a077000b195": Phase="Pending", Reason="", readiness=false. Elapsed: 3.457936ms
Aug 16 14:31:59.017: INFO: Pod "downwardapi-volume-99a2f7cb-c032-11e9-99f6-8a077000b195": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00729732s
STEP: Saw pod success
Aug 16 14:31:59.017: INFO: Pod "downwardapi-volume-99a2f7cb-c032-11e9-99f6-8a077000b195" satisfied condition "success or failure"
Aug 16 14:31:59.020: INFO: Trying to get logs from node worker-eab92000-c026-11e9-bfed-069795ba99e0 pod downwardapi-volume-99a2f7cb-c032-11e9-99f6-8a077000b195 container client-container: <nil>
STEP: delete the pod
Aug 16 14:31:59.046: INFO: Waiting for pod downwardapi-volume-99a2f7cb-c032-11e9-99f6-8a077000b195 to disappear
Aug 16 14:31:59.052: INFO: Pod downwardapi-volume-99a2f7cb-c032-11e9-99f6-8a077000b195 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 14:31:59.052: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-7xkdt" for this suite.
Aug 16 14:32:05.075: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 14:32:05.123: INFO: namespace: e2e-tests-downward-api-7xkdt, resource: bindings, ignored listing per whitelist
Aug 16 14:32:05.189: INFO: namespace e2e-tests-downward-api-7xkdt deletion completed in 6.133000216s

• [SLOW TEST:8.236 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 14:32:05.189: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-tmq5k
Aug 16 14:32:07.253: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-tmq5k
STEP: checking the pod's current state and verifying that restartCount is present
Aug 16 14:32:07.256: INFO: Initial restart count of pod liveness-exec is 0
Aug 16 14:32:55.383: INFO: Restart count of pod e2e-tests-container-probe-tmq5k/liveness-exec is now 1 (48.127307699s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 14:32:55.400: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-tmq5k" for this suite.
Aug 16 14:33:01.430: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 14:33:01.436: INFO: namespace: e2e-tests-container-probe-tmq5k, resource: bindings, ignored listing per whitelist
Aug 16 14:33:01.542: INFO: namespace e2e-tests-container-probe-tmq5k deletion completed in 6.134276876s

• [SLOW TEST:56.353 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 14:33:01.542: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
Aug 16 14:33:01.598: INFO: Waiting up to 5m0s for pod "client-containers-c022d1cf-c032-11e9-99f6-8a077000b195" in namespace "e2e-tests-containers-wbk96" to be "success or failure"
Aug 16 14:33:01.610: INFO: Pod "client-containers-c022d1cf-c032-11e9-99f6-8a077000b195": Phase="Pending", Reason="", readiness=false. Elapsed: 11.554497ms
Aug 16 14:33:03.614: INFO: Pod "client-containers-c022d1cf-c032-11e9-99f6-8a077000b195": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015656496s
STEP: Saw pod success
Aug 16 14:33:03.614: INFO: Pod "client-containers-c022d1cf-c032-11e9-99f6-8a077000b195" satisfied condition "success or failure"
Aug 16 14:33:03.617: INFO: Trying to get logs from node worker-eab92000-c026-11e9-bfed-069795ba99e0 pod client-containers-c022d1cf-c032-11e9-99f6-8a077000b195 container test-container: <nil>
STEP: delete the pod
Aug 16 14:33:03.640: INFO: Waiting for pod client-containers-c022d1cf-c032-11e9-99f6-8a077000b195 to disappear
Aug 16 14:33:03.645: INFO: Pod client-containers-c022d1cf-c032-11e9-99f6-8a077000b195 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 14:33:03.646: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-wbk96" for this suite.
Aug 16 14:33:09.663: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 14:33:09.682: INFO: namespace: e2e-tests-containers-wbk96, resource: bindings, ignored listing per whitelist
Aug 16 14:33:09.777: INFO: namespace e2e-tests-containers-wbk96 deletion completed in 6.127203583s

• [SLOW TEST:8.235 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 14:33:09.777: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
Aug 16 14:33:09.837: INFO: Waiting up to 5m0s for pod "pod-c50b7207-c032-11e9-99f6-8a077000b195" in namespace "e2e-tests-emptydir-c9nn8" to be "success or failure"
Aug 16 14:33:09.842: INFO: Pod "pod-c50b7207-c032-11e9-99f6-8a077000b195": Phase="Pending", Reason="", readiness=false. Elapsed: 4.419952ms
Aug 16 14:33:11.852: INFO: Pod "pod-c50b7207-c032-11e9-99f6-8a077000b195": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014649673s
STEP: Saw pod success
Aug 16 14:33:11.852: INFO: Pod "pod-c50b7207-c032-11e9-99f6-8a077000b195" satisfied condition "success or failure"
Aug 16 14:33:11.855: INFO: Trying to get logs from node worker-eab92000-c026-11e9-bfed-069795ba99e0 pod pod-c50b7207-c032-11e9-99f6-8a077000b195 container test-container: <nil>
STEP: delete the pod
Aug 16 14:33:11.881: INFO: Waiting for pod pod-c50b7207-c032-11e9-99f6-8a077000b195 to disappear
Aug 16 14:33:11.884: INFO: Pod pod-c50b7207-c032-11e9-99f6-8a077000b195 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 14:33:11.884: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-c9nn8" for this suite.
Aug 16 14:33:17.901: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 14:33:17.933: INFO: namespace: e2e-tests-emptydir-c9nn8, resource: bindings, ignored listing per whitelist
Aug 16 14:33:18.013: INFO: namespace e2e-tests-emptydir-c9nn8 deletion completed in 6.124710552s

• [SLOW TEST:8.236 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 14:33:18.013: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
Aug 16 14:33:18.072: INFO: Waiting up to 5m0s for pod "var-expansion-c9f4374b-c032-11e9-99f6-8a077000b195" in namespace "e2e-tests-var-expansion-mgz4x" to be "success or failure"
Aug 16 14:33:18.080: INFO: Pod "var-expansion-c9f4374b-c032-11e9-99f6-8a077000b195": Phase="Pending", Reason="", readiness=false. Elapsed: 7.746755ms
Aug 16 14:33:20.084: INFO: Pod "var-expansion-c9f4374b-c032-11e9-99f6-8a077000b195": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011283392s
STEP: Saw pod success
Aug 16 14:33:20.084: INFO: Pod "var-expansion-c9f4374b-c032-11e9-99f6-8a077000b195" satisfied condition "success or failure"
Aug 16 14:33:20.087: INFO: Trying to get logs from node worker-eab92000-c026-11e9-bfed-069795ba99e0 pod var-expansion-c9f4374b-c032-11e9-99f6-8a077000b195 container dapi-container: <nil>
STEP: delete the pod
Aug 16 14:33:20.111: INFO: Waiting for pod var-expansion-c9f4374b-c032-11e9-99f6-8a077000b195 to disappear
Aug 16 14:33:20.117: INFO: Pod var-expansion-c9f4374b-c032-11e9-99f6-8a077000b195 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 14:33:20.117: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-mgz4x" for this suite.
Aug 16 14:33:26.134: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 14:33:26.193: INFO: namespace: e2e-tests-var-expansion-mgz4x, resource: bindings, ignored listing per whitelist
Aug 16 14:33:26.246: INFO: namespace e2e-tests-var-expansion-mgz4x deletion completed in 6.125248014s

• [SLOW TEST:8.234 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 14:33:26.247: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-cedd3ba8-c032-11e9-99f6-8a077000b195
STEP: Creating configMap with name cm-test-opt-upd-cedd3bdc-c032-11e9-99f6-8a077000b195
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-cedd3ba8-c032-11e9-99f6-8a077000b195
STEP: Updating configmap cm-test-opt-upd-cedd3bdc-c032-11e9-99f6-8a077000b195
STEP: Creating configMap with name cm-test-opt-create-cedd3bec-c032-11e9-99f6-8a077000b195
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 14:35:00.869: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-vdvrd" for this suite.
Aug 16 14:35:22.887: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 14:35:22.942: INFO: namespace: e2e-tests-configmap-vdvrd, resource: bindings, ignored listing per whitelist
Aug 16 14:35:23.121: INFO: namespace e2e-tests-configmap-vdvrd deletion completed in 22.247605504s

• [SLOW TEST:116.873 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 14:35:23.121: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1563
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug 16 14:35:23.185: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-mdqjw'
Aug 16 14:35:23.397: INFO: stderr: ""
Aug 16 14:35:23.398: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Aug 16 14:35:28.448: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-mdqjw -o json'
Aug 16 14:35:28.505: INFO: stderr: ""
Aug 16 14:35:28.505: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/podIP\": \"10.2.4.232/32\"\n        },\n        \"creationTimestamp\": \"2019-08-16T14:35:23Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-mdqjw\",\n        \"resourceVersion\": \"42730\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-mdqjw/pods/e2e-test-nginx-pod\",\n        \"uid\": \"14a1d4a9-c033-11e9-ae7d-02d5aa9cbbca\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-sgprc\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"worker-eab92000-c026-11e9-bfed-069795ba99e0\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-sgprc\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-sgprc\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-08-16T14:35:23Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-08-16T14:35:24Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-08-16T14:35:24Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-08-16T14:35:23Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://c349af0022ec7011b3734c03e4c6e0f4e2bb16cca90cd2de5e0df1107038f59a\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-08-16T14:35:24Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.1.161.42\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.2.4.232\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-08-16T14:35:23Z\"\n    }\n}\n"
STEP: replace the image in the pod
Aug 16 14:35:28.505: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 replace -f - --namespace=e2e-tests-kubectl-mdqjw'
Aug 16 14:35:28.637: INFO: stderr: ""
Aug 16 14:35:28.637: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1568
Aug 16 14:35:28.640: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-mdqjw'
Aug 16 14:35:32.192: INFO: stderr: ""
Aug 16 14:35:32.192: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 14:35:32.192: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-mdqjw" for this suite.
Aug 16 14:35:38.215: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 14:35:38.292: INFO: namespace: e2e-tests-kubectl-mdqjw, resource: bindings, ignored listing per whitelist
Aug 16 14:35:38.352: INFO: namespace e2e-tests-kubectl-mdqjw deletion completed in 6.155156956s

• [SLOW TEST:15.231 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 14:35:38.352: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug 16 14:35:38.408: INFO: (0) /api/v1/nodes/worker-72b80c6a-c026-11e9-bfed-069795ba99e0:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a href="... (200; 3.633661ms)
Aug 16 14:35:38.412: INFO: (1) /api/v1/nodes/worker-72b80c6a-c026-11e9-bfed-069795ba99e0:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a href="... (200; 3.34874ms)
Aug 16 14:35:38.415: INFO: (2) /api/v1/nodes/worker-72b80c6a-c026-11e9-bfed-069795ba99e0:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a href="... (200; 3.359502ms)
Aug 16 14:35:38.419: INFO: (3) /api/v1/nodes/worker-72b80c6a-c026-11e9-bfed-069795ba99e0:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a href="... (200; 3.465355ms)
Aug 16 14:35:38.424: INFO: (4) /api/v1/nodes/worker-72b80c6a-c026-11e9-bfed-069795ba99e0:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a href="... (200; 5.093274ms)
Aug 16 14:35:38.427: INFO: (5) /api/v1/nodes/worker-72b80c6a-c026-11e9-bfed-069795ba99e0:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a href="... (200; 3.351059ms)
Aug 16 14:35:38.430: INFO: (6) /api/v1/nodes/worker-72b80c6a-c026-11e9-bfed-069795ba99e0:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a href="... (200; 3.248393ms)
Aug 16 14:35:38.434: INFO: (7) /api/v1/nodes/worker-72b80c6a-c026-11e9-bfed-069795ba99e0:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a href="... (200; 3.38203ms)
Aug 16 14:35:38.437: INFO: (8) /api/v1/nodes/worker-72b80c6a-c026-11e9-bfed-069795ba99e0:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a href="... (200; 3.401914ms)
Aug 16 14:35:38.440: INFO: (9) /api/v1/nodes/worker-72b80c6a-c026-11e9-bfed-069795ba99e0:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a href="... (200; 3.381617ms)
Aug 16 14:35:38.444: INFO: (10) /api/v1/nodes/worker-72b80c6a-c026-11e9-bfed-069795ba99e0:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a href="... (200; 3.281753ms)
Aug 16 14:35:38.447: INFO: (11) /api/v1/nodes/worker-72b80c6a-c026-11e9-bfed-069795ba99e0:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a href="... (200; 3.342591ms)
Aug 16 14:35:38.451: INFO: (12) /api/v1/nodes/worker-72b80c6a-c026-11e9-bfed-069795ba99e0:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a href="... (200; 3.343036ms)
Aug 16 14:35:38.454: INFO: (13) /api/v1/nodes/worker-72b80c6a-c026-11e9-bfed-069795ba99e0:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a href="... (200; 3.371016ms)
Aug 16 14:35:38.457: INFO: (14) /api/v1/nodes/worker-72b80c6a-c026-11e9-bfed-069795ba99e0:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a href="... (200; 3.283443ms)
Aug 16 14:35:38.461: INFO: (15) /api/v1/nodes/worker-72b80c6a-c026-11e9-bfed-069795ba99e0:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a href="... (200; 3.304807ms)
Aug 16 14:35:38.464: INFO: (16) /api/v1/nodes/worker-72b80c6a-c026-11e9-bfed-069795ba99e0:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a href="... (200; 3.252362ms)
Aug 16 14:35:38.467: INFO: (17) /api/v1/nodes/worker-72b80c6a-c026-11e9-bfed-069795ba99e0:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a href="... (200; 3.261517ms)
Aug 16 14:35:38.470: INFO: (18) /api/v1/nodes/worker-72b80c6a-c026-11e9-bfed-069795ba99e0:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a href="... (200; 3.325354ms)
Aug 16 14:35:38.474: INFO: (19) /api/v1/nodes/worker-72b80c6a-c026-11e9-bfed-069795ba99e0:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a href="... (200; 3.355247ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 14:35:38.474: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-rl8c5" for this suite.
Aug 16 14:35:44.490: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 14:35:44.530: INFO: namespace: e2e-tests-proxy-rl8c5, resource: bindings, ignored listing per whitelist
Aug 16 14:35:44.605: INFO: namespace e2e-tests-proxy-rl8c5 deletion completed in 6.127092735s

• [SLOW TEST:6.252 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 14:35:44.605: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-2154367c-c033-11e9-99f6-8a077000b195
STEP: Creating a pod to test consume secrets
Aug 16 14:35:44.666: INFO: Waiting up to 5m0s for pod "pod-secrets-2154ddb9-c033-11e9-99f6-8a077000b195" in namespace "e2e-tests-secrets-pvh9l" to be "success or failure"
Aug 16 14:35:44.670: INFO: Pod "pod-secrets-2154ddb9-c033-11e9-99f6-8a077000b195": Phase="Pending", Reason="", readiness=false. Elapsed: 4.117997ms
Aug 16 14:35:46.674: INFO: Pod "pod-secrets-2154ddb9-c033-11e9-99f6-8a077000b195": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007791607s
STEP: Saw pod success
Aug 16 14:35:46.674: INFO: Pod "pod-secrets-2154ddb9-c033-11e9-99f6-8a077000b195" satisfied condition "success or failure"
Aug 16 14:35:46.677: INFO: Trying to get logs from node worker-eab92000-c026-11e9-bfed-069795ba99e0 pod pod-secrets-2154ddb9-c033-11e9-99f6-8a077000b195 container secret-volume-test: <nil>
STEP: delete the pod
Aug 16 14:35:46.704: INFO: Waiting for pod pod-secrets-2154ddb9-c033-11e9-99f6-8a077000b195 to disappear
Aug 16 14:35:46.712: INFO: Pod pod-secrets-2154ddb9-c033-11e9-99f6-8a077000b195 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 14:35:46.712: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-pvh9l" for this suite.
Aug 16 14:35:52.728: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 14:35:52.788: INFO: namespace: e2e-tests-secrets-pvh9l, resource: bindings, ignored listing per whitelist
Aug 16 14:35:52.838: INFO: namespace e2e-tests-secrets-pvh9l deletion completed in 6.122371579s

• [SLOW TEST:8.233 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 14:35:52.838: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0816 14:36:32.935110      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Aug 16 14:36:32.935: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 14:36:32.935: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-6wtd7" for this suite.
Aug 16 14:36:38.957: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 14:36:39.049: INFO: namespace: e2e-tests-gc-6wtd7, resource: bindings, ignored listing per whitelist
Aug 16 14:36:39.108: INFO: namespace e2e-tests-gc-6wtd7 deletion completed in 6.1696594s

• [SLOW TEST:46.270 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 14:36:39.108: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
Aug 16 14:36:39.178: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-739526127 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 14:36:39.237: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-j55jx" for this suite.
Aug 16 14:36:45.255: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 14:36:45.277: INFO: namespace: e2e-tests-kubectl-j55jx, resource: bindings, ignored listing per whitelist
Aug 16 14:36:45.366: INFO: namespace e2e-tests-kubectl-j55jx deletion completed in 6.124253196s

• [SLOW TEST:6.258 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 14:36:45.366: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-458b7eaf-c033-11e9-99f6-8a077000b195
STEP: Creating a pod to test consume configMaps
Aug 16 14:36:45.429: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-458c3c7f-c033-11e9-99f6-8a077000b195" in namespace "e2e-tests-projected-fd5m6" to be "success or failure"
Aug 16 14:36:45.433: INFO: Pod "pod-projected-configmaps-458c3c7f-c033-11e9-99f6-8a077000b195": Phase="Pending", Reason="", readiness=false. Elapsed: 3.772324ms
Aug 16 14:36:47.437: INFO: Pod "pod-projected-configmaps-458c3c7f-c033-11e9-99f6-8a077000b195": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007663545s
STEP: Saw pod success
Aug 16 14:36:47.437: INFO: Pod "pod-projected-configmaps-458c3c7f-c033-11e9-99f6-8a077000b195" satisfied condition "success or failure"
Aug 16 14:36:47.440: INFO: Trying to get logs from node worker-eab92000-c026-11e9-bfed-069795ba99e0 pod pod-projected-configmaps-458c3c7f-c033-11e9-99f6-8a077000b195 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 16 14:36:47.468: INFO: Waiting for pod pod-projected-configmaps-458c3c7f-c033-11e9-99f6-8a077000b195 to disappear
Aug 16 14:36:47.475: INFO: Pod pod-projected-configmaps-458c3c7f-c033-11e9-99f6-8a077000b195 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 14:36:47.475: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-fd5m6" for this suite.
Aug 16 14:36:53.499: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 14:36:53.601: INFO: namespace: e2e-tests-projected-fd5m6, resource: bindings, ignored listing per whitelist
Aug 16 14:36:53.614: INFO: namespace e2e-tests-projected-fd5m6 deletion completed in 6.134182516s

• [SLOW TEST:8.247 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 14:36:53.614: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-ghmfg
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Aug 16 14:36:53.661: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Aug 16 14:37:15.748: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.2.4.242:8080/dial?request=hostName&protocol=udp&host=10.2.4.241&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-ghmfg PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 16 14:37:15.748: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
Aug 16 14:37:15.826: INFO: Waiting for endpoints: map[]
Aug 16 14:37:15.830: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.2.4.242:8080/dial?request=hostName&protocol=udp&host=10.2.3.87&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-ghmfg PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 16 14:37:15.830: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
Aug 16 14:37:15.905: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 14:37:15.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-ghmfg" for this suite.
Aug 16 14:37:37.923: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 14:37:37.937: INFO: namespace: e2e-tests-pod-network-test-ghmfg, resource: bindings, ignored listing per whitelist
Aug 16 14:37:38.038: INFO: namespace e2e-tests-pod-network-test-ghmfg deletion completed in 22.128567055s

• [SLOW TEST:44.424 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 14:37:38.038: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1454
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug 16 14:37:38.089: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-sxgbt'
Aug 16 14:37:38.157: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Aug 16 14:37:38.157: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1459
Aug 16 14:37:38.161: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-sxgbt'
Aug 16 14:37:38.225: INFO: stderr: ""
Aug 16 14:37:38.225: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 14:37:38.225: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-sxgbt" for this suite.
Aug 16 14:38:00.260: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 14:38:00.327: INFO: namespace: e2e-tests-kubectl-sxgbt, resource: bindings, ignored listing per whitelist
Aug 16 14:38:00.372: INFO: namespace e2e-tests-kubectl-sxgbt deletion completed in 22.14130405s

• [SLOW TEST:22.333 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 14:38:00.372: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Aug 16 14:38:00.427: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 version --client'
Aug 16 14:38:00.467: INFO: stderr: ""
Aug 16 14:38:00.467: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Aug 16 14:38:00.468: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 create -f - --namespace=e2e-tests-kubectl-cdcr8'
Aug 16 14:38:00.742: INFO: stderr: ""
Aug 16 14:38:00.742: INFO: stdout: "replicationcontroller/redis-master created\n"
Aug 16 14:38:00.743: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 create -f - --namespace=e2e-tests-kubectl-cdcr8'
Aug 16 14:38:00.879: INFO: stderr: ""
Aug 16 14:38:00.879: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Aug 16 14:38:01.883: INFO: Selector matched 1 pods for map[app:redis]
Aug 16 14:38:01.883: INFO: Found 1 / 1
Aug 16 14:38:01.883: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Aug 16 14:38:01.886: INFO: Selector matched 1 pods for map[app:redis]
Aug 16 14:38:01.886: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Aug 16 14:38:01.886: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 describe pod redis-master-cz4wv --namespace=e2e-tests-kubectl-cdcr8'
Aug 16 14:38:01.955: INFO: stderr: ""
Aug 16 14:38:01.955: INFO: stdout: "Name:               redis-master-cz4wv\nNamespace:          e2e-tests-kubectl-cdcr8\nPriority:           0\nPriorityClassName:  <none>\nNode:               worker-eab92000-c026-11e9-bfed-069795ba99e0/10.1.161.42\nStart Time:         Fri, 16 Aug 2019 14:38:00 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        cni.projectcalico.org/podIP: 10.2.4.244/32\nStatus:             Running\nIP:                 10.2.4.244\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://329f71b0c6301295d3910ae3ac8b0eb239bd534f8d331b32e71c36ebb9be14d6\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Fri, 16 Aug 2019 14:38:01 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-dfnhq (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-dfnhq:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-dfnhq\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                                                  Message\n  ----    ------     ----  ----                                                  -------\n  Normal  Scheduled  1s    default-scheduler                                     Successfully assigned e2e-tests-kubectl-cdcr8/redis-master-cz4wv to worker-eab92000-c026-11e9-bfed-069795ba99e0\n  Normal  Pulled     0s    kubelet, worker-eab92000-c026-11e9-bfed-069795ba99e0  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    0s    kubelet, worker-eab92000-c026-11e9-bfed-069795ba99e0  Created container\n  Normal  Started    0s    kubelet, worker-eab92000-c026-11e9-bfed-069795ba99e0  Started container\n"
Aug 16 14:38:01.955: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 describe rc redis-master --namespace=e2e-tests-kubectl-cdcr8'
Aug 16 14:38:02.035: INFO: stderr: ""
Aug 16 14:38:02.035: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-cdcr8\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: redis-master-cz4wv\n"
Aug 16 14:38:02.035: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 describe service redis-master --namespace=e2e-tests-kubectl-cdcr8'
Aug 16 14:38:02.106: INFO: stderr: ""
Aug 16 14:38:02.106: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-cdcr8\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.0.0.50\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.2.4.244:6379\nSession Affinity:  None\nEvents:            <none>\n"
Aug 16 14:38:02.110: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 describe node master-6164ec76-c01c-11e9-bfed-069795ba99e0'
Aug 16 14:38:02.187: INFO: stderr: ""
Aug 16 14:38:02.187: INFO: stdout: "Name:               master-6164ec76-c01c-11e9-bfed-069795ba99e0\nRoles:              master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=us-west-2\n                    failure-domain.beta.kubernetes.io/zone=zone-1\n                    kubeVersion=1-13-6\n                    kubernetes.io/hostname=master-6164ec76-c01c-11e9-bfed-069795ba99e0\n                    kubernetes.io/role=master\n                    node-role.kubernetes.io/master=master\n                    rebootstate=reboot-not-needed\n                    vke/autoscaler-nodegroup=master-zone1-m5large\nAnnotations:        flannel.alpha.coreos.com/backend-data: {\"VtepMAC\":\"62:14:38:c9:dd:f7\"}\n                    flannel.alpha.coreos.com/backend-type: vxlan\n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 10.1.79.38\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Fri, 16 Aug 2019 11:55:34 +0000\nTaints:             Dedicated=Master:NoSchedule\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Fri, 16 Aug 2019 14:37:56 +0000   Fri, 16 Aug 2019 11:55:34 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Fri, 16 Aug 2019 14:37:56 +0000   Fri, 16 Aug 2019 11:55:34 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Fri, 16 Aug 2019 14:37:56 +0000   Fri, 16 Aug 2019 11:55:34 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Fri, 16 Aug 2019 14:37:56 +0000   Fri, 16 Aug 2019 11:55:54 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:   10.1.79.38\n  InternalDNS:  master-6164ec76-c01c-11e9-bfed-069795ba99e0.usahai-prod-a4d3138a-c01b-11e9-bfed-069795ba99e0.a4d3138a-c01b-11e9-bfed-069795ba99e0.us-west-2.cloud.test\nCapacity:\n cpu:                2\n ephemeral-storage:  20507240Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             7870684Ki\n pods:               110\nAllocatable:\n cpu:                1500m\n ephemeral-storage:  18899472353\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             6719708Ki\n pods:               110\nSystem Info:\n Machine ID:                 d8e8c7fe733e46d1b10b706786d861a5\n System UUID:                EC2BA5BA-C469-1D34-AC9B-1F54FF127732\n Boot ID:                    58a44ac6-0661-4a72-b248-a306761f9087\n Kernel Version:             4.9.182-3.ph2\n OS Image:                   VMware Photon OS/Linux\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.6.2\n Kubelet Version:            v1.13.6\n Kube-Proxy Version:         v1.13.6\nPodCIDR:                     10.2.2.0/24\nProviderID:                  vke://6164ec76-c01c-11e9-bfed-069795ba99e0\nNon-terminated Pods:         (3 in total)\n  Namespace                  Name                                            CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                            ------------  ----------  ---------------  -------------  ---\n  vke-system                 canal-node-1-13-6-hnnfh                         250m (16%)    0 (0%)      0 (0%)           0 (0%)         162m\n  vke-system                 kubernetes-dashboard-1-13-6-57479877bd-gn6nk    100m (6%)     100m (6%)   50Mi (0%)        50Mi (0%)      162m\n  vke-system                 update-controller-ds-1-13-6-b4wbk               0 (0%)        0 (0%)      0 (0%)           0 (0%)         162m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                350m (23%)  100m (6%)\n  memory             50Mi (0%)   50Mi (0%)\n  ephemeral-storage  0 (0%)      0 (0%)\nEvents:              <none>\n"
Aug 16 14:38:02.188: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 describe namespace e2e-tests-kubectl-cdcr8'
Aug 16 14:38:02.259: INFO: stderr: ""
Aug 16 14:38:02.259: INFO: stdout: "Name:         e2e-tests-kubectl-cdcr8\nLabels:       e2e-framework=kubectl\n              e2e-run=dde9b4dc-c026-11e9-99f6-8a077000b195\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 14:38:02.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-cdcr8" for this suite.
Aug 16 14:38:24.277: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 14:38:24.354: INFO: namespace: e2e-tests-kubectl-cdcr8, resource: bindings, ignored listing per whitelist
Aug 16 14:38:24.388: INFO: namespace e2e-tests-kubectl-cdcr8 deletion completed in 22.125051195s

• [SLOW TEST:24.016 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 14:38:24.389: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Aug 16 14:38:28.480: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug 16 14:38:28.486: INFO: Pod pod-with-prestop-http-hook still exists
Aug 16 14:38:30.487: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug 16 14:38:30.497: INFO: Pod pod-with-prestop-http-hook still exists
Aug 16 14:38:32.487: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug 16 14:38:32.490: INFO: Pod pod-with-prestop-http-hook still exists
Aug 16 14:38:34.487: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug 16 14:38:34.490: INFO: Pod pod-with-prestop-http-hook still exists
Aug 16 14:38:36.487: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug 16 14:38:36.490: INFO: Pod pod-with-prestop-http-hook still exists
Aug 16 14:38:38.487: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug 16 14:38:38.490: INFO: Pod pod-with-prestop-http-hook still exists
Aug 16 14:38:40.487: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug 16 14:38:40.491: INFO: Pod pod-with-prestop-http-hook still exists
Aug 16 14:38:42.487: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug 16 14:38:42.497: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 14:38:42.505: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-mgljd" for this suite.
Aug 16 14:39:04.533: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 14:39:04.557: INFO: namespace: e2e-tests-container-lifecycle-hook-mgljd, resource: bindings, ignored listing per whitelist
Aug 16 14:39:04.647: INFO: namespace e2e-tests-container-lifecycle-hook-mgljd deletion completed in 22.138597674s

• [SLOW TEST:40.258 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 14:39:04.647: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-sk9js
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-sk9js
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-sk9js
Aug 16 14:39:04.718: INFO: Found 0 stateful pods, waiting for 1
Aug 16 14:39:14.728: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Aug 16 14:39:14.732: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 exec --namespace=e2e-tests-statefulset-sk9js ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 16 14:39:14.874: INFO: stderr: ""
Aug 16 14:39:14.874: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 16 14:39:14.874: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 16 14:39:14.878: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Aug 16 14:39:24.889: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug 16 14:39:24.889: INFO: Waiting for statefulset status.replicas updated to 0
Aug 16 14:39:24.904: INFO: POD   NODE                                         PHASE    GRACE  CONDITIONS
Aug 16 14:39:24.904: INFO: ss-0  worker-eab92000-c026-11e9-bfed-069795ba99e0  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 14:39:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-16 14:39:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-16 14:39:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 14:39:04 +0000 UTC  }]
Aug 16 14:39:24.904: INFO: 
Aug 16 14:39:24.904: INFO: StatefulSet ss has not reached scale 3, at 1
Aug 16 14:39:25.908: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.995846389s
Aug 16 14:39:26.912: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.991787059s
Aug 16 14:39:27.916: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.987207095s
Aug 16 14:39:28.920: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.983343726s
Aug 16 14:39:29.924: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.979133417s
Aug 16 14:39:30.928: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.975169405s
Aug 16 14:39:31.932: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.971336889s
Aug 16 14:39:32.936: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.96756125s
Aug 16 14:39:33.940: INFO: Verifying statefulset ss doesn't scale past 3 for another 963.492679ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-sk9js
Aug 16 14:39:34.951: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 exec --namespace=e2e-tests-statefulset-sk9js ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 16 14:39:35.075: INFO: stderr: ""
Aug 16 14:39:35.075: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 16 14:39:35.075: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 16 14:39:35.075: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 exec --namespace=e2e-tests-statefulset-sk9js ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 16 14:39:35.209: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Aug 16 14:39:35.209: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 16 14:39:35.209: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 16 14:39:35.209: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 exec --namespace=e2e-tests-statefulset-sk9js ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 16 14:39:35.353: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Aug 16 14:39:35.353: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 16 14:39:35.353: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 16 14:39:35.357: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Aug 16 14:39:45.367: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 16 14:39:45.367: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 16 14:39:45.367: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Aug 16 14:39:45.371: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 exec --namespace=e2e-tests-statefulset-sk9js ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 16 14:39:45.508: INFO: stderr: ""
Aug 16 14:39:45.508: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 16 14:39:45.508: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 16 14:39:45.508: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 exec --namespace=e2e-tests-statefulset-sk9js ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 16 14:39:45.638: INFO: stderr: ""
Aug 16 14:39:45.638: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 16 14:39:45.638: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 16 14:39:45.638: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-739526127 exec --namespace=e2e-tests-statefulset-sk9js ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 16 14:39:45.774: INFO: stderr: ""
Aug 16 14:39:45.774: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 16 14:39:45.774: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 16 14:39:45.775: INFO: Waiting for statefulset status.replicas updated to 0
Aug 16 14:39:45.778: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Aug 16 14:39:55.791: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug 16 14:39:55.791: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Aug 16 14:39:55.791: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Aug 16 14:39:55.805: INFO: POD   NODE                                         PHASE    GRACE  CONDITIONS
Aug 16 14:39:55.805: INFO: ss-0  worker-eab92000-c026-11e9-bfed-069795ba99e0  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 14:39:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-16 14:39:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-16 14:39:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 14:39:04 +0000 UTC  }]
Aug 16 14:39:55.805: INFO: ss-1  worker-72b80c6a-c026-11e9-bfed-069795ba99e0  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 14:39:24 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-16 14:39:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-16 14:39:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 14:39:24 +0000 UTC  }]
Aug 16 14:39:55.805: INFO: ss-2  worker-eab92000-c026-11e9-bfed-069795ba99e0  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 14:39:24 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-16 14:39:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-16 14:39:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 14:39:24 +0000 UTC  }]
Aug 16 14:39:55.805: INFO: 
Aug 16 14:39:55.805: INFO: StatefulSet ss has not reached scale 0, at 3
Aug 16 14:39:56.809: INFO: POD   NODE                                         PHASE    GRACE  CONDITIONS
Aug 16 14:39:56.809: INFO: ss-0  worker-eab92000-c026-11e9-bfed-069795ba99e0  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 14:39:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-16 14:39:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-16 14:39:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 14:39:04 +0000 UTC  }]
Aug 16 14:39:56.809: INFO: ss-1  worker-72b80c6a-c026-11e9-bfed-069795ba99e0  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 14:39:24 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-16 14:39:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-16 14:39:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 14:39:24 +0000 UTC  }]
Aug 16 14:39:56.809: INFO: ss-2  worker-eab92000-c026-11e9-bfed-069795ba99e0  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 14:39:24 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-16 14:39:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-16 14:39:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 14:39:24 +0000 UTC  }]
Aug 16 14:39:56.809: INFO: 
Aug 16 14:39:56.809: INFO: StatefulSet ss has not reached scale 0, at 3
Aug 16 14:39:57.813: INFO: POD   NODE                                         PHASE    GRACE  CONDITIONS
Aug 16 14:39:57.813: INFO: ss-0  worker-eab92000-c026-11e9-bfed-069795ba99e0  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 14:39:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-16 14:39:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-16 14:39:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 14:39:04 +0000 UTC  }]
Aug 16 14:39:57.813: INFO: ss-1  worker-72b80c6a-c026-11e9-bfed-069795ba99e0  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 14:39:24 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-16 14:39:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-16 14:39:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 14:39:24 +0000 UTC  }]
Aug 16 14:39:57.813: INFO: ss-2  worker-eab92000-c026-11e9-bfed-069795ba99e0  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 14:39:24 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-16 14:39:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-16 14:39:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 14:39:24 +0000 UTC  }]
Aug 16 14:39:57.813: INFO: 
Aug 16 14:39:57.813: INFO: StatefulSet ss has not reached scale 0, at 3
Aug 16 14:39:58.817: INFO: POD   NODE                                         PHASE    GRACE  CONDITIONS
Aug 16 14:39:58.817: INFO: ss-0  worker-eab92000-c026-11e9-bfed-069795ba99e0  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 14:39:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-16 14:39:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-16 14:39:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 14:39:04 +0000 UTC  }]
Aug 16 14:39:58.817: INFO: ss-2  worker-eab92000-c026-11e9-bfed-069795ba99e0  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 14:39:24 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-16 14:39:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-16 14:39:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 14:39:24 +0000 UTC  }]
Aug 16 14:39:58.817: INFO: 
Aug 16 14:39:58.817: INFO: StatefulSet ss has not reached scale 0, at 2
Aug 16 14:39:59.821: INFO: POD   NODE                                         PHASE    GRACE  CONDITIONS
Aug 16 14:39:59.821: INFO: ss-0  worker-eab92000-c026-11e9-bfed-069795ba99e0  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 14:39:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-16 14:39:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-16 14:39:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 14:39:04 +0000 UTC  }]
Aug 16 14:39:59.821: INFO: ss-2  worker-eab92000-c026-11e9-bfed-069795ba99e0  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 14:39:24 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-16 14:39:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-16 14:39:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 14:39:24 +0000 UTC  }]
Aug 16 14:39:59.821: INFO: 
Aug 16 14:39:59.821: INFO: StatefulSet ss has not reached scale 0, at 2
Aug 16 14:40:00.825: INFO: POD   NODE                                         PHASE    GRACE  CONDITIONS
Aug 16 14:40:00.825: INFO: ss-0  worker-eab92000-c026-11e9-bfed-069795ba99e0  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 14:39:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-16 14:39:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-16 14:39:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 14:39:04 +0000 UTC  }]
Aug 16 14:40:00.825: INFO: ss-2  worker-eab92000-c026-11e9-bfed-069795ba99e0  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 14:39:24 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-16 14:39:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-16 14:39:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 14:39:24 +0000 UTC  }]
Aug 16 14:40:00.825: INFO: 
Aug 16 14:40:00.825: INFO: StatefulSet ss has not reached scale 0, at 2
Aug 16 14:40:01.829: INFO: POD   NODE                                         PHASE    GRACE  CONDITIONS
Aug 16 14:40:01.829: INFO: ss-0  worker-eab92000-c026-11e9-bfed-069795ba99e0  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 14:39:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-16 14:39:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-16 14:39:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 14:39:04 +0000 UTC  }]
Aug 16 14:40:01.829: INFO: ss-2  worker-eab92000-c026-11e9-bfed-069795ba99e0  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 14:39:24 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-16 14:39:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-16 14:39:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-16 14:39:24 +0000 UTC  }]
Aug 16 14:40:01.829: INFO: 
Aug 16 14:40:01.829: INFO: StatefulSet ss has not reached scale 0, at 2
Aug 16 14:40:02.833: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.969579272s
Aug 16 14:40:03.837: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.965657543s
Aug 16 14:40:04.841: INFO: Verifying statefulset ss doesn't scale past 0 for another 961.758386ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-sk9js
Aug 16 14:40:05.851: INFO: Scaling statefulset ss to 0
Aug 16 14:40:05.861: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Aug 16 14:40:05.863: INFO: Deleting all statefulset in ns e2e-tests-statefulset-sk9js
Aug 16 14:40:05.866: INFO: Scaling statefulset ss to 0
Aug 16 14:40:05.875: INFO: Waiting for statefulset status.replicas updated to 0
Aug 16 14:40:05.878: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 14:40:05.893: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-sk9js" for this suite.
Aug 16 14:40:11.911: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 14:40:11.960: INFO: namespace: e2e-tests-statefulset-sk9js, resource: bindings, ignored listing per whitelist
Aug 16 14:40:12.024: INFO: namespace e2e-tests-statefulset-sk9js deletion completed in 6.126630628s

• [SLOW TEST:67.377 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 14:40:12.024: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-b7lfz
Aug 16 14:40:14.095: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-b7lfz
STEP: checking the pod's current state and verifying that restartCount is present
Aug 16 14:40:14.098: INFO: Initial restart count of pod liveness-http is 0
Aug 16 14:40:32.161: INFO: Restart count of pod e2e-tests-container-probe-b7lfz/liveness-http is now 1 (18.062909637s elapsed)
Aug 16 14:40:52.215: INFO: Restart count of pod e2e-tests-container-probe-b7lfz/liveness-http is now 2 (38.117011667s elapsed)
Aug 16 14:41:12.266: INFO: Restart count of pod e2e-tests-container-probe-b7lfz/liveness-http is now 3 (58.168098158s elapsed)
Aug 16 14:41:32.319: INFO: Restart count of pod e2e-tests-container-probe-b7lfz/liveness-http is now 4 (1m18.220471686s elapsed)
Aug 16 14:42:42.520: INFO: Restart count of pod e2e-tests-container-probe-b7lfz/liveness-http is now 5 (2m28.421302923s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 14:42:42.540: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-b7lfz" for this suite.
Aug 16 14:42:48.565: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 14:42:48.616: INFO: namespace: e2e-tests-container-probe-b7lfz, resource: bindings, ignored listing per whitelist
Aug 16 14:42:48.686: INFO: namespace e2e-tests-container-probe-b7lfz deletion completed in 6.138677197s

• [SLOW TEST:156.662 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Aug 16 14:42:48.686: INFO: >>> kubeConfig: /tmp/kubeconfig-739526127
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
Aug 16 14:42:48.743: INFO: Waiting up to 5m0s for pod "var-expansion-1e19ca25-c034-11e9-99f6-8a077000b195" in namespace "e2e-tests-var-expansion-zdx8h" to be "success or failure"
Aug 16 14:42:48.747: INFO: Pod "var-expansion-1e19ca25-c034-11e9-99f6-8a077000b195": Phase="Pending", Reason="", readiness=false. Elapsed: 3.955954ms
Aug 16 14:42:50.750: INFO: Pod "var-expansion-1e19ca25-c034-11e9-99f6-8a077000b195": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007636814s
STEP: Saw pod success
Aug 16 14:42:50.750: INFO: Pod "var-expansion-1e19ca25-c034-11e9-99f6-8a077000b195" satisfied condition "success or failure"
Aug 16 14:42:50.753: INFO: Trying to get logs from node worker-eab92000-c026-11e9-bfed-069795ba99e0 pod var-expansion-1e19ca25-c034-11e9-99f6-8a077000b195 container dapi-container: <nil>
STEP: delete the pod
Aug 16 14:42:50.781: INFO: Waiting for pod var-expansion-1e19ca25-c034-11e9-99f6-8a077000b195 to disappear
Aug 16 14:42:50.786: INFO: Pod var-expansion-1e19ca25-c034-11e9-99f6-8a077000b195 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Aug 16 14:42:50.786: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-zdx8h" for this suite.
Aug 16 14:42:56.810: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 16 14:42:56.919: INFO: namespace: e2e-tests-var-expansion-zdx8h, resource: bindings, ignored listing per whitelist
Aug 16 14:42:56.922: INFO: namespace e2e-tests-var-expansion-zdx8h deletion completed in 6.13138154s

• [SLOW TEST:8.236 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSAug 16 14:42:56.922: INFO: Running AfterSuite actions on all nodes
Aug 16 14:42:56.922: INFO: Running AfterSuite actions on node 1
Aug 16 14:42:56.922: INFO: Skipping dumping logs from cluster

Ran 200 of 1946 Specs in 5698.683 seconds
SUCCESS! -- 200 Passed | 0 Failed | 0 Pending | 1746 Skipped PASS

Ginkgo ran 1 suite in 1h34m59.401936841s
Test Suite Passed
